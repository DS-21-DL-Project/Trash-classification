{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from glob import glob \n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "import ultralytics\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Îç∞Ïù¥ÌÑ∞ ÏàòÏßë"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.196 is required but found version=8.1.27, to fix: `pip install ultralytics==8.0.196`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Î∂ÑÎ¶¨ÏàòÍ±∞-ÌîÑÎ°úÏ†ùÌä∏-8 to yolov8:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 220011/220011 [00:11<00:00, 18827.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to Î∂ÑÎ¶¨ÏàòÍ±∞-ÌîÑÎ°úÏ†ùÌä∏-8 in yolov8:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13436/13436 [00:05<00:00, 2534.28it/s]\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"\")\n",
    "project = rf.workspace(\"detection-6zqm5\").project(\"-ix50o\")\n",
    "version = project.version(8)\n",
    "dataset = version.download(\"yolov8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Î°úÎ≥¥ÌîåÎ°úÏö∞ÏóêÏÑú ÏûëÏóÖÏùÑ ÏßÑÌñâÌïòÏó¨ ÏïΩ 2300Ïû•Ïùò ÏÇ¨ÏßÑÏóê ÎåÄÌï¥ÏÑú ÎùºÎ≤®ÎßÅ ÏûëÏóÖÏùÑ ÏàòÌñâ ÌïòÏòÄÏäµÎãàÎã§.\n",
    "\n",
    "- Î°úÎ≥¥ÌîåÎ°úÏö∞ÏóêÏÑú ÏÇ¨ÏßÑ Îç∞Ïù¥ÌÑ∞Ïùò ÌîΩÏÖÄ ÌÅ¨Í∏∞ÏôÄ ÏÇ¨Ïù¥Ï¶àÎ•º ÎßûÏ∂∞ÏÑú ÏßÑÌñâ\n",
    "- 90ÎèÑ 180ÎèÑ 360ÎèÑÎ°ú ÌöåÏ†ÑÏùÑ Í∞ÄÌïòÏó¨ Ï∂îÍ∞ÄÏ†ÅÏù∏ Îç∞Ïù¥ÌÑ∞ ÏàòÏßë\n",
    "- Ï±ÑÎèÑ +-30%, ÎÖ∏Ïù¥Ï¶à Î∞úÏÉùÏùò Ï°∞Í±¥ÏùÑ Ï∂îÍ∞ÄÏ†ÅÏúºÎ°ú Í∞ÄÌïòÏó¨\n",
    "\n",
    "Ï¥ù 5300Ïû•Ïùò Îç∞Ïù¥ÌÑ∞Î•º ÌïôÏäµ ÏãúÌÇ§ÎäîÎç∞ ÏÇ¨Ïö© ÌïòÏòÄÏäµÎãàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ïª§ÎÑê Ï∂©Îèå Î∞©ÏßÄ ÏΩîÎìú\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # yolo ÌÖåÏä§Ìä∏ ÌååÏùº Îã§Ïö¥Î°úÎìú Î∞è Î™®Îç∏ Îã§Ïö¥Î°úÎìú ÏΩîÎìú\n",
    "# from ultralytics import YOLO\n",
    "\n",
    "# ultralytics.checks()\n",
    "# model = YOLO('yolov8n.pt')\n",
    "# # model.predict(\n",
    "# #    source='https://media.roboflow.com/notebooks/examples/dog.jpeg',\n",
    "# #    conf=0.25\n",
    "# # )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Î™®Îç∏ ÌïôÏäµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'> 80\n"
     ]
    }
   ],
   "source": [
    "model = YOLO('yolov8n.pt')\n",
    "print(type(model.names), len(model.names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Dependency ultralytics==8.0.196 is required but found version=8.1.27, to fix: `pip install ultralytics==8.0.196`\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"TP8PbdzFturXX4hloYwF\")\n",
    "project = rf.workspace(\"detection-6zqm5\").project(\"-ix50o\")\n",
    "version = project.version(4)\n",
    "dataset = version.download(\"yolov8\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ÌïòÏù¥Ìçº ÌååÎùºÎ©îÌÑ∞ Ï∞æÍ∏∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mTuner: \u001b[0mInitialized Tuner instance with 'tune_dir=runs\\detect\\tune'\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0müí° Learn about tuning at https://docs.ultralytics.com/guides/hyperparameter-tuning\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 1/100 with hyperparameters: {'lr0': 0.01, 'lrf': 0.01, 'momentum': 0.937, 'weight_decay': 0.0005, 'warmup_epochs': 3.0, 'warmup_momentum': 0.8, 'box': 7.5, 'cls': 0.5, 'dfl': 1.5, 'hsv_h': 0.015, 'hsv_s': 0.7, 'hsv_v': 0.4, 'degrees': 0.0, 'translate': 0.1, 'scale': 0.5, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.5, 'mosaic': 1.0, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m1/100 iterations complete ‚úÖ (553.63s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.31936 observed at iteration 1\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.30909, 'metrics/recall(B)': 0.52553, 'metrics/mAP50(B)': 0.38295, 'metrics/mAP50-95(B)': 0.31229, 'val/box_loss': 0.7958, 'val/cls_loss': 1.59948, 'val/dfl_loss': 1.21455, 'fitness': 0.31936}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.01\n",
      "lrf: 0.01\n",
      "momentum: 0.937\n",
      "weight_decay: 0.0005\n",
      "warmup_epochs: 3.0\n",
      "warmup_momentum: 0.8\n",
      "box: 7.5\n",
      "cls: 0.5\n",
      "dfl: 1.5\n",
      "hsv_h: 0.015\n",
      "hsv_s: 0.7\n",
      "hsv_v: 0.4\n",
      "degrees: 0.0\n",
      "translate: 0.1\n",
      "scale: 0.5\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.5\n",
      "mosaic: 1.0\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 2/100 with hyperparameters: {'lr0': 0.01, 'lrf': 0.00925, 'momentum': 0.91068, 'weight_decay': 0.00067, 'warmup_epochs': 3.39684, 'warmup_momentum': 0.822, 'box': 7.15314, 'cls': 0.44488, 'dfl': 1.35901, 'hsv_h': 0.01323, 'hsv_s': 0.53159, 'hsv_v': 0.4, 'degrees': 0.0, 'translate': 0.07869, 'scale': 0.5, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.5, 'mosaic': 0.91604, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m2/100 iterations complete ‚úÖ (1109.82s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.33887 observed at iteration 2\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.41705, 'metrics/recall(B)': 0.48209, 'metrics/mAP50(B)': 0.41446, 'metrics/mAP50-95(B)': 0.33047, 'val/box_loss': 0.77854, 'val/cls_loss': 1.38281, 'val/dfl_loss': 1.13663, 'fitness': 0.33887}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train2\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.01\n",
      "lrf: 0.00925\n",
      "momentum: 0.91068\n",
      "weight_decay: 0.00067\n",
      "warmup_epochs: 3.39684\n",
      "warmup_momentum: 0.822\n",
      "box: 7.15314\n",
      "cls: 0.44488\n",
      "dfl: 1.35901\n",
      "hsv_h: 0.01323\n",
      "hsv_s: 0.53159\n",
      "hsv_v: 0.4\n",
      "degrees: 0.0\n",
      "translate: 0.07869\n",
      "scale: 0.5\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.5\n",
      "mosaic: 0.91604\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 3/100 with hyperparameters: {'lr0': 0.00896, 'lrf': 0.00911, 'momentum': 0.90707, 'weight_decay': 0.00078, 'warmup_epochs': 3.60602, 'warmup_momentum': 0.85719, 'box': 7.15314, 'cls': 0.49771, 'dfl': 1.2637, 'hsv_h': 0.01323, 'hsv_s': 0.47255, 'hsv_v': 0.38751, 'degrees': 0.0, 'translate': 0.07869, 'scale': 0.48224, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.50514, 'mosaic': 0.86824, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m3/100 iterations complete ‚úÖ (1657.87s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.39993 observed at iteration 3\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.50122, 'metrics/recall(B)': 0.46702, 'metrics/mAP50(B)': 0.47686, 'metrics/mAP50-95(B)': 0.39138, 'val/box_loss': 0.75417, 'val/cls_loss': 1.47214, 'val/dfl_loss': 1.02596, 'fitness': 0.39993}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train3\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00896\n",
      "lrf: 0.00911\n",
      "momentum: 0.90707\n",
      "weight_decay: 0.00078\n",
      "warmup_epochs: 3.60602\n",
      "warmup_momentum: 0.85719\n",
      "box: 7.15314\n",
      "cls: 0.49771\n",
      "dfl: 1.2637\n",
      "hsv_h: 0.01323\n",
      "hsv_s: 0.47255\n",
      "hsv_v: 0.38751\n",
      "degrees: 0.0\n",
      "translate: 0.07869\n",
      "scale: 0.48224\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.50514\n",
      "mosaic: 0.86824\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 4/100 with hyperparameters: {'lr0': 0.00841, 'lrf': 0.00943, 'momentum': 0.90707, 'weight_decay': 0.00077, 'warmup_epochs': 3.60602, 'warmup_momentum': 0.95, 'box': 7.15314, 'cls': 0.44692, 'dfl': 1.22897, 'hsv_h': 0.01323, 'hsv_s': 0.35501, 'hsv_v': 0.42975, 'degrees': 0.0, 'translate': 0.08771, 'scale': 0.53189, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.69287, 'mosaic': 0.86824, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m4/100 iterations complete ‚úÖ (2207.49s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.4033 observed at iteration 4\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.49287, 'metrics/recall(B)': 0.49239, 'metrics/mAP50(B)': 0.48481, 'metrics/mAP50-95(B)': 0.39424, 'val/box_loss': 0.73031, 'val/cls_loss': 1.28541, 'val/dfl_loss': 0.97815, 'fitness': 0.4033}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train4\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00841\n",
      "lrf: 0.00943\n",
      "momentum: 0.90707\n",
      "weight_decay: 0.00077\n",
      "warmup_epochs: 3.60602\n",
      "warmup_momentum: 0.95\n",
      "box: 7.15314\n",
      "cls: 0.44692\n",
      "dfl: 1.22897\n",
      "hsv_h: 0.01323\n",
      "hsv_s: 0.35501\n",
      "hsv_v: 0.42975\n",
      "degrees: 0.0\n",
      "translate: 0.08771\n",
      "scale: 0.53189\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.69287\n",
      "mosaic: 0.86824\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 5/100 with hyperparameters: {'lr0': 0.00881, 'lrf': 0.00966, 'momentum': 0.96545, 'weight_decay': 0.00079, 'warmup_epochs': 3.93093, 'warmup_momentum': 0.91013, 'box': 7.09772, 'cls': 0.48617, 'dfl': 1.29975, 'hsv_h': 0.01273, 'hsv_s': 0.43653, 'hsv_v': 0.36349, 'degrees': 0.0, 'translate': 0.07162, 'scale': 0.43247, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.52265, 'mosaic': 1.0, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m5/100 iterations complete ‚úÖ (2754.73s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.4033 observed at iteration 4\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.49287, 'metrics/recall(B)': 0.49239, 'metrics/mAP50(B)': 0.48481, 'metrics/mAP50-95(B)': 0.39424, 'val/box_loss': 0.73031, 'val/cls_loss': 1.28541, 'val/dfl_loss': 0.97815, 'fitness': 0.4033}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train4\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00841\n",
      "lrf: 0.00943\n",
      "momentum: 0.90707\n",
      "weight_decay: 0.00077\n",
      "warmup_epochs: 3.60602\n",
      "warmup_momentum: 0.95\n",
      "box: 7.15314\n",
      "cls: 0.44692\n",
      "dfl: 1.22897\n",
      "hsv_h: 0.01323\n",
      "hsv_s: 0.35501\n",
      "hsv_v: 0.42975\n",
      "degrees: 0.0\n",
      "translate: 0.08771\n",
      "scale: 0.53189\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.69287\n",
      "mosaic: 0.86824\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 6/100 with hyperparameters: {'lr0': 0.00846, 'lrf': 0.00846, 'momentum': 0.91527, 'weight_decay': 0.00075, 'warmup_epochs': 3.6015, 'warmup_momentum': 0.84747, 'box': 7.6624, 'cls': 0.45966, 'dfl': 1.08186, 'hsv_h': 0.01323, 'hsv_s': 0.47255, 'hsv_v': 0.41231, 'degrees': 0.0, 'translate': 0.07869, 'scale': 0.53651, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.46912, 'mosaic': 0.93735, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m6/100 iterations complete ‚úÖ (3299.67s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.4033 observed at iteration 4\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.49287, 'metrics/recall(B)': 0.49239, 'metrics/mAP50(B)': 0.48481, 'metrics/mAP50-95(B)': 0.39424, 'val/box_loss': 0.73031, 'val/cls_loss': 1.28541, 'val/dfl_loss': 0.97815, 'fitness': 0.4033}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train4\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00841\n",
      "lrf: 0.00943\n",
      "momentum: 0.90707\n",
      "weight_decay: 0.00077\n",
      "warmup_epochs: 3.60602\n",
      "warmup_momentum: 0.95\n",
      "box: 7.15314\n",
      "cls: 0.44692\n",
      "dfl: 1.22897\n",
      "hsv_h: 0.01323\n",
      "hsv_s: 0.35501\n",
      "hsv_v: 0.42975\n",
      "degrees: 0.0\n",
      "translate: 0.08771\n",
      "scale: 0.53189\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.69287\n",
      "mosaic: 0.86824\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 7/100 with hyperparameters: {'lr0': 0.00802, 'lrf': 0.00937, 'momentum': 0.89528, 'weight_decay': 0.00077, 'warmup_epochs': 3.70103, 'warmup_momentum': 0.92507, 'box': 7.13256, 'cls': 0.45489, 'dfl': 1.22897, 'hsv_h': 0.01323, 'hsv_s': 0.35281, 'hsv_v': 0.42769, 'degrees': 0.0, 'translate': 0.08908, 'scale': 0.53189, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.70872, 'mosaic': 0.92253, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m7/100 iterations complete ‚úÖ (3847.29s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.4033 observed at iteration 4\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.49287, 'metrics/recall(B)': 0.49239, 'metrics/mAP50(B)': 0.48481, 'metrics/mAP50-95(B)': 0.39424, 'val/box_loss': 0.73031, 'val/cls_loss': 1.28541, 'val/dfl_loss': 0.97815, 'fitness': 0.4033}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train4\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00841\n",
      "lrf: 0.00943\n",
      "momentum: 0.90707\n",
      "weight_decay: 0.00077\n",
      "warmup_epochs: 3.60602\n",
      "warmup_momentum: 0.95\n",
      "box: 7.15314\n",
      "cls: 0.44692\n",
      "dfl: 1.22897\n",
      "hsv_h: 0.01323\n",
      "hsv_s: 0.35501\n",
      "hsv_v: 0.42975\n",
      "degrees: 0.0\n",
      "translate: 0.08771\n",
      "scale: 0.53189\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.69287\n",
      "mosaic: 0.86824\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 8/100 with hyperparameters: {'lr0': 0.008, 'lrf': 0.00933, 'momentum': 0.89528, 'weight_decay': 0.00076, 'warmup_epochs': 3.67, 'warmup_momentum': 0.91455, 'box': 7.06376, 'cls': 0.45535, 'dfl': 1.22527, 'hsv_h': 0.01329, 'hsv_s': 0.35277, 'hsv_v': 0.42302, 'degrees': 0.0, 'translate': 0.08961, 'scale': 0.53661, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.70872, 'mosaic': 0.91456, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m8/100 iterations complete ‚úÖ (4392.40s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.4033 observed at iteration 4\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.49287, 'metrics/recall(B)': 0.49239, 'metrics/mAP50(B)': 0.48481, 'metrics/mAP50-95(B)': 0.39424, 'val/box_loss': 0.73031, 'val/cls_loss': 1.28541, 'val/dfl_loss': 0.97815, 'fitness': 0.4033}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train4\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00841\n",
      "lrf: 0.00943\n",
      "momentum: 0.90707\n",
      "weight_decay: 0.00077\n",
      "warmup_epochs: 3.60602\n",
      "warmup_momentum: 0.95\n",
      "box: 7.15314\n",
      "cls: 0.44692\n",
      "dfl: 1.22897\n",
      "hsv_h: 0.01323\n",
      "hsv_s: 0.35501\n",
      "hsv_v: 0.42975\n",
      "degrees: 0.0\n",
      "translate: 0.08771\n",
      "scale: 0.53189\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.69287\n",
      "mosaic: 0.86824\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 9/100 with hyperparameters: {'lr0': 0.00797, 'lrf': 0.00949, 'momentum': 0.90707, 'weight_decay': 0.00074, 'warmup_epochs': 3.47304, 'warmup_momentum': 0.95, 'box': 6.87115, 'cls': 0.44852, 'dfl': 1.22897, 'hsv_h': 0.01323, 'hsv_s': 0.37085, 'hsv_v': 0.42975, 'degrees': 0.0, 'translate': 0.08204, 'scale': 0.53189, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.64579, 'mosaic': 0.85665, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m9/100 iterations complete ‚úÖ (4942.19s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.4033 observed at iteration 4\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.49287, 'metrics/recall(B)': 0.49239, 'metrics/mAP50(B)': 0.48481, 'metrics/mAP50-95(B)': 0.39424, 'val/box_loss': 0.73031, 'val/cls_loss': 1.28541, 'val/dfl_loss': 0.97815, 'fitness': 0.4033}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train4\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00841\n",
      "lrf: 0.00943\n",
      "momentum: 0.90707\n",
      "weight_decay: 0.00077\n",
      "warmup_epochs: 3.60602\n",
      "warmup_momentum: 0.95\n",
      "box: 7.15314\n",
      "cls: 0.44692\n",
      "dfl: 1.22897\n",
      "hsv_h: 0.01323\n",
      "hsv_s: 0.35501\n",
      "hsv_v: 0.42975\n",
      "degrees: 0.0\n",
      "translate: 0.08771\n",
      "scale: 0.53189\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.69287\n",
      "mosaic: 0.86824\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 10/100 with hyperparameters: {'lr0': 0.01092, 'lrf': 0.01111, 'momentum': 0.87338, 'weight_decay': 0.00097, 'warmup_epochs': 4.6967, 'warmup_momentum': 0.79974, 'box': 6.24127, 'cls': 0.46662, 'dfl': 1.15462, 'hsv_h': 0.00996, 'hsv_s': 0.48392, 'hsv_v': 0.38116, 'degrees': 0.0, 'translate': 0.07869, 'scale': 0.38231, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.37748, 'mosaic': 0.75883, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m10/100 iterations complete ‚úÖ (5489.99s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.4033 observed at iteration 4\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.49287, 'metrics/recall(B)': 0.49239, 'metrics/mAP50(B)': 0.48481, 'metrics/mAP50-95(B)': 0.39424, 'val/box_loss': 0.73031, 'val/cls_loss': 1.28541, 'val/dfl_loss': 0.97815, 'fitness': 0.4033}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train4\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00841\n",
      "lrf: 0.00943\n",
      "momentum: 0.90707\n",
      "weight_decay: 0.00077\n",
      "warmup_epochs: 3.60602\n",
      "warmup_momentum: 0.95\n",
      "box: 7.15314\n",
      "cls: 0.44692\n",
      "dfl: 1.22897\n",
      "hsv_h: 0.01323\n",
      "hsv_s: 0.35501\n",
      "hsv_v: 0.42975\n",
      "degrees: 0.0\n",
      "translate: 0.08771\n",
      "scale: 0.53189\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.69287\n",
      "mosaic: 0.86824\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 11/100 with hyperparameters: {'lr0': 0.00831, 'lrf': 0.00954, 'momentum': 0.90542, 'weight_decay': 0.00077, 'warmup_epochs': 3.6198, 'warmup_momentum': 0.95, 'box': 7.23293, 'cls': 0.4474, 'dfl': 1.26074, 'hsv_h': 0.01323, 'hsv_s': 0.35501, 'hsv_v': 0.42877, 'degrees': 0.0, 'translate': 0.08814, 'scale': 0.54094, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.69069, 'mosaic': 0.86037, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m11/100 iterations complete ‚úÖ (6039.19s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.4033 observed at iteration 4\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.49287, 'metrics/recall(B)': 0.49239, 'metrics/mAP50(B)': 0.48481, 'metrics/mAP50-95(B)': 0.39424, 'val/box_loss': 0.73031, 'val/cls_loss': 1.28541, 'val/dfl_loss': 0.97815, 'fitness': 0.4033}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train4\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00841\n",
      "lrf: 0.00943\n",
      "momentum: 0.90707\n",
      "weight_decay: 0.00077\n",
      "warmup_epochs: 3.60602\n",
      "warmup_momentum: 0.95\n",
      "box: 7.15314\n",
      "cls: 0.44692\n",
      "dfl: 1.22897\n",
      "hsv_h: 0.01323\n",
      "hsv_s: 0.35501\n",
      "hsv_v: 0.42975\n",
      "degrees: 0.0\n",
      "translate: 0.08771\n",
      "scale: 0.53189\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.69287\n",
      "mosaic: 0.86824\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 12/100 with hyperparameters: {'lr0': 0.00965, 'lrf': 0.00967, 'momentum': 0.88276, 'weight_decay': 0.00074, 'warmup_epochs': 3.60602, 'warmup_momentum': 0.87073, 'box': 7.15314, 'cls': 0.49608, 'dfl': 1.30923, 'hsv_h': 0.01344, 'hsv_s': 0.47255, 'hsv_v': 0.35031, 'degrees': 0.0, 'translate': 0.08217, 'scale': 0.45587, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.48837, 'mosaic': 0.86336, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m12/100 iterations complete ‚úÖ (6586.56s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.4033 observed at iteration 4\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.49287, 'metrics/recall(B)': 0.49239, 'metrics/mAP50(B)': 0.48481, 'metrics/mAP50-95(B)': 0.39424, 'val/box_loss': 0.73031, 'val/cls_loss': 1.28541, 'val/dfl_loss': 0.97815, 'fitness': 0.4033}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train4\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00841\n",
      "lrf: 0.00943\n",
      "momentum: 0.90707\n",
      "weight_decay: 0.00077\n",
      "warmup_epochs: 3.60602\n",
      "warmup_momentum: 0.95\n",
      "box: 7.15314\n",
      "cls: 0.44692\n",
      "dfl: 1.22897\n",
      "hsv_h: 0.01323\n",
      "hsv_s: 0.35501\n",
      "hsv_v: 0.42975\n",
      "degrees: 0.0\n",
      "translate: 0.08771\n",
      "scale: 0.53189\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.69287\n",
      "mosaic: 0.86824\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 13/100 with hyperparameters: {'lr0': 0.00742, 'lrf': 0.00937, 'momentum': 0.92613, 'weight_decay': 0.00074, 'warmup_epochs': 5.0, 'warmup_momentum': 0.92507, 'box': 8.33236, 'cls': 0.33676, 'dfl': 1.22897, 'hsv_h': 0.00866, 'hsv_s': 0.28693, 'hsv_v': 0.42769, 'degrees': 0.0, 'translate': 0.1003, 'scale': 0.53189, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.77127, 'mosaic': 0.92253, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m13/100 iterations complete ‚úÖ (7132.47s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.4033 observed at iteration 4\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.49287, 'metrics/recall(B)': 0.49239, 'metrics/mAP50(B)': 0.48481, 'metrics/mAP50-95(B)': 0.39424, 'val/box_loss': 0.73031, 'val/cls_loss': 1.28541, 'val/dfl_loss': 0.97815, 'fitness': 0.4033}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train4\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00841\n",
      "lrf: 0.00943\n",
      "momentum: 0.90707\n",
      "weight_decay: 0.00077\n",
      "warmup_epochs: 3.60602\n",
      "warmup_momentum: 0.95\n",
      "box: 7.15314\n",
      "cls: 0.44692\n",
      "dfl: 1.22897\n",
      "hsv_h: 0.01323\n",
      "hsv_s: 0.35501\n",
      "hsv_v: 0.42975\n",
      "degrees: 0.0\n",
      "translate: 0.08771\n",
      "scale: 0.53189\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.69287\n",
      "mosaic: 0.86824\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 14/100 with hyperparameters: {'lr0': 0.00693, 'lrf': 0.00911, 'momentum': 0.90707, 'weight_decay': 0.00052, 'warmup_epochs': 3.24161, 'warmup_momentum': 0.90457, 'box': 6.12784, 'cls': 0.35087, 'dfl': 1.23389, 'hsv_h': 0.01233, 'hsv_s': 0.43717, 'hsv_v': 0.37599, 'degrees': 0.0, 'translate': 0.06731, 'scale': 0.48224, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.51977, 'mosaic': 0.86941, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m14/100 iterations complete ‚úÖ (7680.21s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.4033 observed at iteration 4\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.49287, 'metrics/recall(B)': 0.49239, 'metrics/mAP50(B)': 0.48481, 'metrics/mAP50-95(B)': 0.39424, 'val/box_loss': 0.73031, 'val/cls_loss': 1.28541, 'val/dfl_loss': 0.97815, 'fitness': 0.4033}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train4\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00841\n",
      "lrf: 0.00943\n",
      "momentum: 0.90707\n",
      "weight_decay: 0.00077\n",
      "warmup_epochs: 3.60602\n",
      "warmup_momentum: 0.95\n",
      "box: 7.15314\n",
      "cls: 0.44692\n",
      "dfl: 1.22897\n",
      "hsv_h: 0.01323\n",
      "hsv_s: 0.35501\n",
      "hsv_v: 0.42975\n",
      "degrees: 0.0\n",
      "translate: 0.08771\n",
      "scale: 0.53189\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.69287\n",
      "mosaic: 0.86824\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 15/100 with hyperparameters: {'lr0': 0.00792, 'lrf': 0.00869, 'momentum': 0.89634, 'weight_decay': 0.00077, 'warmup_epochs': 3.71148, 'warmup_momentum': 0.95, 'box': 7.10214, 'cls': 0.44998, 'dfl': 1.20917, 'hsv_h': 0.01243, 'hsv_s': 0.33797, 'hsv_v': 0.43683, 'degrees': 0.0, 'translate': 0.08622, 'scale': 0.58532, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.64831, 'mosaic': 0.95751, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m15/100 iterations complete ‚úÖ (8228.22s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.4033 observed at iteration 4\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.49287, 'metrics/recall(B)': 0.49239, 'metrics/mAP50(B)': 0.48481, 'metrics/mAP50-95(B)': 0.39424, 'val/box_loss': 0.73031, 'val/cls_loss': 1.28541, 'val/dfl_loss': 0.97815, 'fitness': 0.4033}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train4\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00841\n",
      "lrf: 0.00943\n",
      "momentum: 0.90707\n",
      "weight_decay: 0.00077\n",
      "warmup_epochs: 3.60602\n",
      "warmup_momentum: 0.95\n",
      "box: 7.15314\n",
      "cls: 0.44692\n",
      "dfl: 1.22897\n",
      "hsv_h: 0.01323\n",
      "hsv_s: 0.35501\n",
      "hsv_v: 0.42975\n",
      "degrees: 0.0\n",
      "translate: 0.08771\n",
      "scale: 0.53189\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.69287\n",
      "mosaic: 0.86824\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 16/100 with hyperparameters: {'lr0': 0.00693, 'lrf': 0.00803, 'momentum': 0.94262, 'weight_decay': 0.00055, 'warmup_epochs': 2.0778, 'warmup_momentum': 0.95, 'box': 5.10576, 'cls': 0.36976, 'dfl': 1.12487, 'hsv_h': 0.01564, 'hsv_s': 0.38983, 'hsv_v': 0.30051, 'degrees': 0.0, 'translate': 0.09259, 'scale': 0.44917, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.54724, 'mosaic': 1.0, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m16/100 iterations complete ‚úÖ (8772.40s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.42934 observed at iteration 16\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.54794, 'metrics/recall(B)': 0.51745, 'metrics/mAP50(B)': 0.50928, 'metrics/mAP50-95(B)': 0.42046, 'val/box_loss': 0.52684, 'val/cls_loss': 1.03716, 'val/dfl_loss': 0.89297, 'fitness': 0.42934}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train16\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00693\n",
      "lrf: 0.00803\n",
      "momentum: 0.94262\n",
      "weight_decay: 0.00055\n",
      "warmup_epochs: 2.0778\n",
      "warmup_momentum: 0.95\n",
      "box: 5.10576\n",
      "cls: 0.36976\n",
      "dfl: 1.12487\n",
      "hsv_h: 0.01564\n",
      "hsv_s: 0.38983\n",
      "hsv_v: 0.30051\n",
      "degrees: 0.0\n",
      "translate: 0.09259\n",
      "scale: 0.44917\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.54724\n",
      "mosaic: 1.0\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 17/100 with hyperparameters: {'lr0': 0.00693, 'lrf': 0.00803, 'momentum': 0.93517, 'weight_decay': 0.00056, 'warmup_epochs': 1.96847, 'warmup_momentum': 0.95, 'box': 5.17751, 'cls': 0.38568, 'dfl': 1.06917, 'hsv_h': 0.01564, 'hsv_s': 0.41583, 'hsv_v': 0.29005, 'degrees': 0.0, 'translate': 0.09011, 'scale': 0.46153, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.5655, 'mosaic': 1.0, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m17/100 iterations complete ‚úÖ (9318.78s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.42934 observed at iteration 16\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.54794, 'metrics/recall(B)': 0.51745, 'metrics/mAP50(B)': 0.50928, 'metrics/mAP50-95(B)': 0.42046, 'val/box_loss': 0.52684, 'val/cls_loss': 1.03716, 'val/dfl_loss': 0.89297, 'fitness': 0.42934}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train16\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00693\n",
      "lrf: 0.00803\n",
      "momentum: 0.94262\n",
      "weight_decay: 0.00055\n",
      "warmup_epochs: 2.0778\n",
      "warmup_momentum: 0.95\n",
      "box: 5.10576\n",
      "cls: 0.36976\n",
      "dfl: 1.12487\n",
      "hsv_h: 0.01564\n",
      "hsv_s: 0.38983\n",
      "hsv_v: 0.30051\n",
      "degrees: 0.0\n",
      "translate: 0.09259\n",
      "scale: 0.44917\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.54724\n",
      "mosaic: 1.0\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 18/100 with hyperparameters: {'lr0': 0.00691, 'lrf': 0.00811, 'momentum': 0.94368, 'weight_decay': 0.00055, 'warmup_epochs': 2.0778, 'warmup_momentum': 0.94333, 'box': 5.08372, 'cls': 0.36877, 'dfl': 1.12441, 'hsv_h': 0.01564, 'hsv_s': 0.38983, 'hsv_v': 0.30232, 'degrees': 0.0, 'translate': 0.09158, 'scale': 0.44635, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.54935, 'mosaic': 1.0, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m18/100 iterations complete ‚úÖ (9862.83s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.42934 observed at iteration 16\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.54794, 'metrics/recall(B)': 0.51745, 'metrics/mAP50(B)': 0.50928, 'metrics/mAP50-95(B)': 0.42046, 'val/box_loss': 0.52684, 'val/cls_loss': 1.03716, 'val/dfl_loss': 0.89297, 'fitness': 0.42934}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train16\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00693\n",
      "lrf: 0.00803\n",
      "momentum: 0.94262\n",
      "weight_decay: 0.00055\n",
      "warmup_epochs: 2.0778\n",
      "warmup_momentum: 0.95\n",
      "box: 5.10576\n",
      "cls: 0.36976\n",
      "dfl: 1.12487\n",
      "hsv_h: 0.01564\n",
      "hsv_s: 0.38983\n",
      "hsv_v: 0.30051\n",
      "degrees: 0.0\n",
      "translate: 0.09259\n",
      "scale: 0.44917\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.54724\n",
      "mosaic: 1.0\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 19/100 with hyperparameters: {'lr0': 0.00693, 'lrf': 0.00727, 'momentum': 0.96127, 'weight_decay': 0.00055, 'warmup_epochs': 2.02325, 'warmup_momentum': 0.95, 'box': 4.63544, 'cls': 0.36807, 'dfl': 0.93184, 'hsv_h': 0.01307, 'hsv_s': 0.38983, 'hsv_v': 0.24403, 'degrees': 0.0, 'translate': 0.08489, 'scale': 0.36666, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.467, 'mosaic': 0.81253, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m19/100 iterations complete ‚úÖ (10406.61s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.44638 observed at iteration 19\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.54414, 'metrics/recall(B)': 0.51481, 'metrics/mAP50(B)': 0.53223, 'metrics/mAP50-95(B)': 0.43684, 'val/box_loss': 0.4753, 'val/cls_loss': 1.01982, 'val/dfl_loss': 0.74086, 'fitness': 0.44638}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train19\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00693\n",
      "lrf: 0.00727\n",
      "momentum: 0.96127\n",
      "weight_decay: 0.00055\n",
      "warmup_epochs: 2.02325\n",
      "warmup_momentum: 0.95\n",
      "box: 4.63544\n",
      "cls: 0.36807\n",
      "dfl: 0.93184\n",
      "hsv_h: 0.01307\n",
      "hsv_s: 0.38983\n",
      "hsv_v: 0.24403\n",
      "degrees: 0.0\n",
      "translate: 0.08489\n",
      "scale: 0.36666\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.467\n",
      "mosaic: 0.81253\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 20/100 with hyperparameters: {'lr0': 0.00769, 'lrf': 0.00875, 'momentum': 0.89802, 'weight_decay': 0.00065, 'warmup_epochs': 2.36494, 'warmup_momentum': 0.81539, 'box': 5.37043, 'cls': 0.40207, 'dfl': 0.98758, 'hsv_h': 0.01488, 'hsv_s': 0.3726, 'hsv_v': 0.30051, 'degrees': 0.0, 'translate': 0.08336, 'scale': 0.44917, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.64194, 'mosaic': 1.0, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m20/100 iterations complete ‚úÖ (10954.93s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.44638 observed at iteration 19\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.54414, 'metrics/recall(B)': 0.51481, 'metrics/mAP50(B)': 0.53223, 'metrics/mAP50-95(B)': 0.43684, 'val/box_loss': 0.4753, 'val/cls_loss': 1.01982, 'val/dfl_loss': 0.74086, 'fitness': 0.44638}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train19\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00693\n",
      "lrf: 0.00727\n",
      "momentum: 0.96127\n",
      "weight_decay: 0.00055\n",
      "warmup_epochs: 2.02325\n",
      "warmup_momentum: 0.95\n",
      "box: 4.63544\n",
      "cls: 0.36807\n",
      "dfl: 0.93184\n",
      "hsv_h: 0.01307\n",
      "hsv_s: 0.38983\n",
      "hsv_v: 0.24403\n",
      "degrees: 0.0\n",
      "translate: 0.08489\n",
      "scale: 0.36666\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.467\n",
      "mosaic: 0.81253\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 21/100 with hyperparameters: {'lr0': 0.00801, 'lrf': 0.00727, 'momentum': 0.97367, 'weight_decay': 0.00057, 'warmup_epochs': 1.89595, 'warmup_momentum': 0.95, 'box': 5.25244, 'cls': 0.37904, 'dfl': 0.93695, 'hsv_h': 0.01475, 'hsv_s': 0.3491, 'hsv_v': 0.26595, 'degrees': 0.0, 'translate': 0.06803, 'scale': 0.35291, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.467, 'mosaic': 0.72642, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m21/100 iterations complete ‚úÖ (11498.76s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.44638 observed at iteration 19\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.54414, 'metrics/recall(B)': 0.51481, 'metrics/mAP50(B)': 0.53223, 'metrics/mAP50-95(B)': 0.43684, 'val/box_loss': 0.4753, 'val/cls_loss': 1.01982, 'val/dfl_loss': 0.74086, 'fitness': 0.44638}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train19\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00693\n",
      "lrf: 0.00727\n",
      "momentum: 0.96127\n",
      "weight_decay: 0.00055\n",
      "warmup_epochs: 2.02325\n",
      "warmup_momentum: 0.95\n",
      "box: 4.63544\n",
      "cls: 0.36807\n",
      "dfl: 0.93184\n",
      "hsv_h: 0.01307\n",
      "hsv_s: 0.38983\n",
      "hsv_v: 0.24403\n",
      "degrees: 0.0\n",
      "translate: 0.08489\n",
      "scale: 0.36666\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.467\n",
      "mosaic: 0.81253\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 22/100 with hyperparameters: {'lr0': 0.01062, 'lrf': 0.00757, 'momentum': 0.97279, 'weight_decay': 0.00056, 'warmup_epochs': 1.76, 'warmup_momentum': 0.79317, 'box': 4.3822, 'cls': 0.36647, 'dfl': 1.02011, 'hsv_h': 0.01475, 'hsv_s': 0.35168, 'hsv_v': 0.26595, 'degrees': 0.0, 'translate': 0.06995, 'scale': 0.37215, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.51804, 'mosaic': 0.77119, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m22/100 iterations complete ‚úÖ (12044.45s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.44638 observed at iteration 19\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.54414, 'metrics/recall(B)': 0.51481, 'metrics/mAP50(B)': 0.53223, 'metrics/mAP50-95(B)': 0.43684, 'val/box_loss': 0.4753, 'val/cls_loss': 1.01982, 'val/dfl_loss': 0.74086, 'fitness': 0.44638}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train19\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00693\n",
      "lrf: 0.00727\n",
      "momentum: 0.96127\n",
      "weight_decay: 0.00055\n",
      "warmup_epochs: 2.02325\n",
      "warmup_momentum: 0.95\n",
      "box: 4.63544\n",
      "cls: 0.36807\n",
      "dfl: 0.93184\n",
      "hsv_h: 0.01307\n",
      "hsv_s: 0.38983\n",
      "hsv_v: 0.24403\n",
      "degrees: 0.0\n",
      "translate: 0.08489\n",
      "scale: 0.36666\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.467\n",
      "mosaic: 0.81253\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 23/100 with hyperparameters: {'lr0': 0.00882, 'lrf': 0.00886, 'momentum': 0.94262, 'weight_decay': 0.0006, 'warmup_epochs': 2.30607, 'warmup_momentum': 0.95, 'box': 5.09192, 'cls': 0.3249, 'dfl': 0.86934, 'hsv_h': 0.01617, 'hsv_s': 0.4125, 'hsv_v': 0.32281, 'degrees': 0.0, 'translate': 0.12177, 'scale': 0.4675, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.63252, 'mosaic': 0.99912, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m23/100 iterations complete ‚úÖ (12591.55s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.44638 observed at iteration 19\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.54414, 'metrics/recall(B)': 0.51481, 'metrics/mAP50(B)': 0.53223, 'metrics/mAP50-95(B)': 0.43684, 'val/box_loss': 0.4753, 'val/cls_loss': 1.01982, 'val/dfl_loss': 0.74086, 'fitness': 0.44638}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train19\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00693\n",
      "lrf: 0.00727\n",
      "momentum: 0.96127\n",
      "weight_decay: 0.00055\n",
      "warmup_epochs: 2.02325\n",
      "warmup_momentum: 0.95\n",
      "box: 4.63544\n",
      "cls: 0.36807\n",
      "dfl: 0.93184\n",
      "hsv_h: 0.01307\n",
      "hsv_s: 0.38983\n",
      "hsv_v: 0.24403\n",
      "degrees: 0.0\n",
      "translate: 0.08489\n",
      "scale: 0.36666\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.467\n",
      "mosaic: 0.81253\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 24/100 with hyperparameters: {'lr0': 0.00784, 'lrf': 0.00754, 'momentum': 0.90309, 'weight_decay': 0.00053, 'warmup_epochs': 2.06702, 'warmup_momentum': 0.95, 'box': 5.17751, 'cls': 0.41164, 'dfl': 1.00309, 'hsv_h': 0.01504, 'hsv_s': 0.46375, 'hsv_v': 0.29005, 'degrees': 0.0, 'translate': 0.09011, 'scale': 0.45558, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.54747, 'mosaic': 1.0, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m24/100 iterations complete ‚úÖ (13136.65s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.44638 observed at iteration 19\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.54414, 'metrics/recall(B)': 0.51481, 'metrics/mAP50(B)': 0.53223, 'metrics/mAP50-95(B)': 0.43684, 'val/box_loss': 0.4753, 'val/cls_loss': 1.01982, 'val/dfl_loss': 0.74086, 'fitness': 0.44638}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train19\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00693\n",
      "lrf: 0.00727\n",
      "momentum: 0.96127\n",
      "weight_decay: 0.00055\n",
      "warmup_epochs: 2.02325\n",
      "warmup_momentum: 0.95\n",
      "box: 4.63544\n",
      "cls: 0.36807\n",
      "dfl: 0.93184\n",
      "hsv_h: 0.01307\n",
      "hsv_s: 0.38983\n",
      "hsv_v: 0.24403\n",
      "degrees: 0.0\n",
      "translate: 0.08489\n",
      "scale: 0.36666\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.467\n",
      "mosaic: 0.81253\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 25/100 with hyperparameters: {'lr0': 0.00686, 'lrf': 0.00721, 'momentum': 0.95688, 'weight_decay': 0.00055, 'warmup_epochs': 2.02325, 'warmup_momentum': 0.95, 'box': 4.66495, 'cls': 0.36807, 'dfl': 0.93184, 'hsv_h': 0.01269, 'hsv_s': 0.41242, 'hsv_v': 0.24403, 'degrees': 0.0, 'translate': 0.08196, 'scale': 0.35697, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.4708, 'mosaic': 0.76575, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m25/100 iterations complete ‚úÖ (13680.71s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.45349 observed at iteration 25\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.53101, 'metrics/recall(B)': 0.51953, 'metrics/mAP50(B)': 0.5448, 'metrics/mAP50-95(B)': 0.44334, 'val/box_loss': 0.47406, 'val/cls_loss': 1.0023, 'val/dfl_loss': 0.72854, 'fitness': 0.45349}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train25\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00686\n",
      "lrf: 0.00721\n",
      "momentum: 0.95688\n",
      "weight_decay: 0.00055\n",
      "warmup_epochs: 2.02325\n",
      "warmup_momentum: 0.95\n",
      "box: 4.66495\n",
      "cls: 0.36807\n",
      "dfl: 0.93184\n",
      "hsv_h: 0.01269\n",
      "hsv_s: 0.41242\n",
      "hsv_v: 0.24403\n",
      "degrees: 0.0\n",
      "translate: 0.08196\n",
      "scale: 0.35697\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.4708\n",
      "mosaic: 0.76575\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 26/100 with hyperparameters: {'lr0': 0.0081, 'lrf': 0.00928, 'momentum': 0.98, 'weight_decay': 0.0004, 'warmup_epochs': 2.27936, 'warmup_momentum': 0.88732, 'box': 5.02595, 'cls': 0.33523, 'dfl': 1.15341, 'hsv_h': 0.01337, 'hsv_s': 0.56941, 'hsv_v': 0.30114, 'degrees': 0.0, 'translate': 0.09496, 'scale': 0.57772, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.41669, 'mosaic': 0.88767, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m26/100 iterations complete ‚úÖ (14226.10s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.45349 observed at iteration 25\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.53101, 'metrics/recall(B)': 0.51953, 'metrics/mAP50(B)': 0.5448, 'metrics/mAP50-95(B)': 0.44334, 'val/box_loss': 0.47406, 'val/cls_loss': 1.0023, 'val/dfl_loss': 0.72854, 'fitness': 0.45349}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train25\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00686\n",
      "lrf: 0.00721\n",
      "momentum: 0.95688\n",
      "weight_decay: 0.00055\n",
      "warmup_epochs: 2.02325\n",
      "warmup_momentum: 0.95\n",
      "box: 4.66495\n",
      "cls: 0.36807\n",
      "dfl: 0.93184\n",
      "hsv_h: 0.01269\n",
      "hsv_s: 0.41242\n",
      "hsv_v: 0.24403\n",
      "degrees: 0.0\n",
      "translate: 0.08196\n",
      "scale: 0.35697\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.4708\n",
      "mosaic: 0.76575\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 27/100 with hyperparameters: {'lr0': 0.00686, 'lrf': 0.00721, 'momentum': 0.95688, 'weight_decay': 0.00054, 'warmup_epochs': 1.61798, 'warmup_momentum': 0.95, 'box': 5.55032, 'cls': 0.34032, 'dfl': 0.99377, 'hsv_h': 0.01019, 'hsv_s': 0.41242, 'hsv_v': 0.24403, 'degrees': 0.0, 'translate': 0.08196, 'scale': 0.3868, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.48358, 'mosaic': 0.77047, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m27/100 iterations complete ‚úÖ (14773.09s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.45349 observed at iteration 25\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.53101, 'metrics/recall(B)': 0.51953, 'metrics/mAP50(B)': 0.5448, 'metrics/mAP50-95(B)': 0.44334, 'val/box_loss': 0.47406, 'val/cls_loss': 1.0023, 'val/dfl_loss': 0.72854, 'fitness': 0.45349}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train25\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00686\n",
      "lrf: 0.00721\n",
      "momentum: 0.95688\n",
      "weight_decay: 0.00055\n",
      "warmup_epochs: 2.02325\n",
      "warmup_momentum: 0.95\n",
      "box: 4.66495\n",
      "cls: 0.36807\n",
      "dfl: 0.93184\n",
      "hsv_h: 0.01269\n",
      "hsv_s: 0.41242\n",
      "hsv_v: 0.24403\n",
      "degrees: 0.0\n",
      "translate: 0.08196\n",
      "scale: 0.35697\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.4708\n",
      "mosaic: 0.76575\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 28/100 with hyperparameters: {'lr0': 0.00766, 'lrf': 0.00744, 'momentum': 0.93082, 'weight_decay': 0.00067, 'warmup_epochs': 2.14872, 'warmup_momentum': 0.95, 'box': 4.51241, 'cls': 0.32624, 'dfl': 1.02044, 'hsv_h': 0.01227, 'hsv_s': 0.35939, 'hsv_v': 0.26583, 'degrees': 0.0, 'translate': 0.0737, 'scale': 0.25148, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.44605, 'mosaic': 0.72371, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m28/100 iterations complete ‚úÖ (15319.56s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.45451 observed at iteration 28\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.55442, 'metrics/recall(B)': 0.50522, 'metrics/mAP50(B)': 0.55492, 'metrics/mAP50-95(B)': 0.44335, 'val/box_loss': 0.46634, 'val/cls_loss': 0.90144, 'val/dfl_loss': 0.81239, 'fitness': 0.45451}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train28\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00766\n",
      "lrf: 0.00744\n",
      "momentum: 0.93082\n",
      "weight_decay: 0.00067\n",
      "warmup_epochs: 2.14872\n",
      "warmup_momentum: 0.95\n",
      "box: 4.51241\n",
      "cls: 0.32624\n",
      "dfl: 1.02044\n",
      "hsv_h: 0.01227\n",
      "hsv_s: 0.35939\n",
      "hsv_v: 0.26583\n",
      "degrees: 0.0\n",
      "translate: 0.0737\n",
      "scale: 0.25148\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.44605\n",
      "mosaic: 0.72371\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 29/100 with hyperparameters: {'lr0': 0.00737, 'lrf': 0.00776, 'momentum': 0.9328, 'weight_decay': 0.00071, 'warmup_epochs': 1.8105, 'warmup_momentum': 0.90959, 'box': 4.51241, 'cls': 0.35289, 'dfl': 1.02044, 'hsv_h': 0.0124, 'hsv_s': 0.35939, 'hsv_v': 0.26583, 'degrees': 0.0, 'translate': 0.0737, 'scale': 0.29327, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.48475, 'mosaic': 0.73303, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m29/100 iterations complete ‚úÖ (15861.81s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.45723 observed at iteration 29\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.57941, 'metrics/recall(B)': 0.53013, 'metrics/mAP50(B)': 0.55393, 'metrics/mAP50-95(B)': 0.44649, 'val/box_loss': 0.46231, 'val/cls_loss': 0.98142, 'val/dfl_loss': 0.80135, 'fitness': 0.45723}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train29\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00737\n",
      "lrf: 0.00776\n",
      "momentum: 0.9328\n",
      "weight_decay: 0.00071\n",
      "warmup_epochs: 1.8105\n",
      "warmup_momentum: 0.90959\n",
      "box: 4.51241\n",
      "cls: 0.35289\n",
      "dfl: 1.02044\n",
      "hsv_h: 0.0124\n",
      "hsv_s: 0.35939\n",
      "hsv_v: 0.26583\n",
      "degrees: 0.0\n",
      "translate: 0.0737\n",
      "scale: 0.29327\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.48475\n",
      "mosaic: 0.73303\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 30/100 with hyperparameters: {'lr0': 0.00579, 'lrf': 0.00744, 'momentum': 0.89644, 'weight_decay': 0.00067, 'warmup_epochs': 2.56599, 'warmup_momentum': 0.95, 'box': 4.32505, 'cls': 0.28642, 'dfl': 1.09117, 'hsv_h': 0.01227, 'hsv_s': 0.41098, 'hsv_v': 0.24283, 'degrees': 0.0, 'translate': 0.0662, 'scale': 0.25148, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.51777, 'mosaic': 0.59703, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m30/100 iterations complete ‚úÖ (16408.22s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.51353 observed at iteration 30\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.58279, 'metrics/recall(B)': 0.57174, 'metrics/mAP50(B)': 0.6018, 'metrics/mAP50-95(B)': 0.50372, 'val/box_loss': 0.42161, 'val/cls_loss': 0.74725, 'val/dfl_loss': 0.82944, 'fitness': 0.51353}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train30\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00579\n",
      "lrf: 0.00744\n",
      "momentum: 0.89644\n",
      "weight_decay: 0.00067\n",
      "warmup_epochs: 2.56599\n",
      "warmup_momentum: 0.95\n",
      "box: 4.32505\n",
      "cls: 0.28642\n",
      "dfl: 1.09117\n",
      "hsv_h: 0.01227\n",
      "hsv_s: 0.41098\n",
      "hsv_v: 0.24283\n",
      "degrees: 0.0\n",
      "translate: 0.0662\n",
      "scale: 0.25148\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.51777\n",
      "mosaic: 0.59703\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 31/100 with hyperparameters: {'lr0': 0.00579, 'lrf': 0.00684, 'momentum': 0.88962, 'weight_decay': 0.0005, 'warmup_epochs': 1.97644, 'warmup_momentum': 0.92206, 'box': 4.42653, 'cls': 0.371, 'dfl': 1.15884, 'hsv_h': 0.01289, 'hsv_s': 0.46863, 'hsv_v': 0.26843, 'degrees': 0.0, 'translate': 0.06774, 'scale': 0.24788, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.59994, 'mosaic': 0.58384, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m31/100 iterations complete ‚úÖ (16951.37s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.51353 observed at iteration 30\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.58279, 'metrics/recall(B)': 0.57174, 'metrics/mAP50(B)': 0.6018, 'metrics/mAP50-95(B)': 0.50372, 'val/box_loss': 0.42161, 'val/cls_loss': 0.74725, 'val/dfl_loss': 0.82944, 'fitness': 0.51353}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train30\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00579\n",
      "lrf: 0.00744\n",
      "momentum: 0.89644\n",
      "weight_decay: 0.00067\n",
      "warmup_epochs: 2.56599\n",
      "warmup_momentum: 0.95\n",
      "box: 4.32505\n",
      "cls: 0.28642\n",
      "dfl: 1.09117\n",
      "hsv_h: 0.01227\n",
      "hsv_s: 0.41098\n",
      "hsv_v: 0.24283\n",
      "degrees: 0.0\n",
      "translate: 0.0662\n",
      "scale: 0.25148\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.51777\n",
      "mosaic: 0.59703\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 32/100 with hyperparameters: {'lr0': 0.00603, 'lrf': 0.00729, 'momentum': 0.88296, 'weight_decay': 0.0005, 'warmup_epochs': 2.00949, 'warmup_momentum': 0.91432, 'box': 4.44766, 'cls': 0.371, 'dfl': 1.15884, 'hsv_h': 0.0133, 'hsv_s': 0.46863, 'hsv_v': 0.26946, 'degrees': 0.0, 'translate': 0.06445, 'scale': 0.25328, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.59994, 'mosaic': 0.56766, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m32/100 iterations complete ‚úÖ (17493.31s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.51353 observed at iteration 30\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.58279, 'metrics/recall(B)': 0.57174, 'metrics/mAP50(B)': 0.6018, 'metrics/mAP50-95(B)': 0.50372, 'val/box_loss': 0.42161, 'val/cls_loss': 0.74725, 'val/dfl_loss': 0.82944, 'fitness': 0.51353}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train30\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00579\n",
      "lrf: 0.00744\n",
      "momentum: 0.89644\n",
      "weight_decay: 0.00067\n",
      "warmup_epochs: 2.56599\n",
      "warmup_momentum: 0.95\n",
      "box: 4.32505\n",
      "cls: 0.28642\n",
      "dfl: 1.09117\n",
      "hsv_h: 0.01227\n",
      "hsv_s: 0.41098\n",
      "hsv_v: 0.24283\n",
      "degrees: 0.0\n",
      "translate: 0.0662\n",
      "scale: 0.25148\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.51777\n",
      "mosaic: 0.59703\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 33/100 with hyperparameters: {'lr0': 0.00552, 'lrf': 0.0073, 'momentum': 0.87772, 'weight_decay': 0.0006, 'warmup_epochs': 2.59922, 'warmup_momentum': 0.95, 'box': 4.11207, 'cls': 0.28642, 'dfl': 1.07501, 'hsv_h': 0.01343, 'hsv_s': 0.41502, 'hsv_v': 0.24283, 'degrees': 0.0, 'translate': 0.0662, 'scale': 0.24821, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.51902, 'mosaic': 0.70337, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m33/100 iterations complete ‚úÖ (18039.14s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.51465 observed at iteration 33\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.62695, 'metrics/recall(B)': 0.55873, 'metrics/mAP50(B)': 0.61052, 'metrics/mAP50-95(B)': 0.504, 'val/box_loss': 0.39464, 'val/cls_loss': 0.73483, 'val/dfl_loss': 0.81113, 'fitness': 0.51465}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train33\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00552\n",
      "lrf: 0.0073\n",
      "momentum: 0.87772\n",
      "weight_decay: 0.0006\n",
      "warmup_epochs: 2.59922\n",
      "warmup_momentum: 0.95\n",
      "box: 4.11207\n",
      "cls: 0.28642\n",
      "dfl: 1.07501\n",
      "hsv_h: 0.01343\n",
      "hsv_s: 0.41502\n",
      "hsv_v: 0.24283\n",
      "degrees: 0.0\n",
      "translate: 0.0662\n",
      "scale: 0.24821\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.51902\n",
      "mosaic: 0.70337\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 34/100 with hyperparameters: {'lr0': 0.00654, 'lrf': 0.00759, 'momentum': 0.85124, 'weight_decay': 0.00053, 'warmup_epochs': 2.22643, 'warmup_momentum': 0.92124, 'box': 4.44766, 'cls': 0.371, 'dfl': 1.20416, 'hsv_h': 0.01462, 'hsv_s': 0.46863, 'hsv_v': 0.28868, 'degrees': 0.0, 'translate': 0.07715, 'scale': 0.25328, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.65867, 'mosaic': 0.52932, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m34/100 iterations complete ‚úÖ (18582.69s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.51465 observed at iteration 33\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.62695, 'metrics/recall(B)': 0.55873, 'metrics/mAP50(B)': 0.61052, 'metrics/mAP50-95(B)': 0.504, 'val/box_loss': 0.39464, 'val/cls_loss': 0.73483, 'val/dfl_loss': 0.81113, 'fitness': 0.51465}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train33\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00552\n",
      "lrf: 0.0073\n",
      "momentum: 0.87772\n",
      "weight_decay: 0.0006\n",
      "warmup_epochs: 2.59922\n",
      "warmup_momentum: 0.95\n",
      "box: 4.11207\n",
      "cls: 0.28642\n",
      "dfl: 1.07501\n",
      "hsv_h: 0.01343\n",
      "hsv_s: 0.41502\n",
      "hsv_v: 0.24283\n",
      "degrees: 0.0\n",
      "translate: 0.0662\n",
      "scale: 0.24821\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.51902\n",
      "mosaic: 0.70337\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 35/100 with hyperparameters: {'lr0': 0.00514, 'lrf': 0.00601, 'momentum': 0.94849, 'weight_decay': 0.00066, 'warmup_epochs': 2.56599, 'warmup_momentum': 0.90691, 'box': 3.87012, 'cls': 0.34982, 'dfl': 0.98973, 'hsv_h': 0.01227, 'hsv_s': 0.47714, 'hsv_v': 0.2596, 'degrees': 0.0, 'translate': 0.0662, 'scale': 0.26416, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.50004, 'mosaic': 0.62943, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m35/100 iterations complete ‚úÖ (19127.94s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.53255 observed at iteration 35\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.63313, 'metrics/recall(B)': 0.61134, 'metrics/mAP50(B)': 0.63908, 'metrics/mAP50-95(B)': 0.52072, 'val/box_loss': 0.37489, 'val/cls_loss': 0.83474, 'val/dfl_loss': 0.74182, 'fitness': 0.53255}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train35\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00514\n",
      "lrf: 0.00601\n",
      "momentum: 0.94849\n",
      "weight_decay: 0.00066\n",
      "warmup_epochs: 2.56599\n",
      "warmup_momentum: 0.90691\n",
      "box: 3.87012\n",
      "cls: 0.34982\n",
      "dfl: 0.98973\n",
      "hsv_h: 0.01227\n",
      "hsv_s: 0.47714\n",
      "hsv_v: 0.2596\n",
      "degrees: 0.0\n",
      "translate: 0.0662\n",
      "scale: 0.26416\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.50004\n",
      "mosaic: 0.62943\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 36/100 with hyperparameters: {'lr0': 0.00479, 'lrf': 0.00596, 'momentum': 0.97159, 'weight_decay': 0.0006, 'warmup_epochs': 2.38143, 'warmup_momentum': 0.91017, 'box': 4.08711, 'cls': 0.34982, 'dfl': 0.98973, 'hsv_h': 0.01292, 'hsv_s': 0.47422, 'hsv_v': 0.25266, 'degrees': 0.0, 'translate': 0.07031, 'scale': 0.24175, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.50004, 'mosaic': 0.67919, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m36/100 iterations complete ‚úÖ (19674.93s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.55876 observed at iteration 36\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.67427, 'metrics/recall(B)': 0.58936, 'metrics/mAP50(B)': 0.65811, 'metrics/mAP50-95(B)': 0.54772, 'val/box_loss': 0.39827, 'val/cls_loss': 0.81431, 'val/dfl_loss': 0.75373, 'fitness': 0.55876}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train36\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00479\n",
      "lrf: 0.00596\n",
      "momentum: 0.97159\n",
      "weight_decay: 0.0006\n",
      "warmup_epochs: 2.38143\n",
      "warmup_momentum: 0.91017\n",
      "box: 4.08711\n",
      "cls: 0.34982\n",
      "dfl: 0.98973\n",
      "hsv_h: 0.01292\n",
      "hsv_s: 0.47422\n",
      "hsv_v: 0.25266\n",
      "degrees: 0.0\n",
      "translate: 0.07031\n",
      "scale: 0.24175\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.50004\n",
      "mosaic: 0.67919\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 37/100 with hyperparameters: {'lr0': 0.00522, 'lrf': 0.00589, 'momentum': 0.95114, 'weight_decay': 0.00066, 'warmup_epochs': 2.59816, 'warmup_momentum': 0.90587, 'box': 3.80946, 'cls': 0.35016, 'dfl': 0.99708, 'hsv_h': 0.01244, 'hsv_s': 0.47997, 'hsv_v': 0.25999, 'degrees': 0.0, 'translate': 0.06615, 'scale': 0.26416, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.50045, 'mosaic': 0.62943, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m37/100 iterations complete ‚úÖ (20221.06s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.55876 observed at iteration 36\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.67427, 'metrics/recall(B)': 0.58936, 'metrics/mAP50(B)': 0.65811, 'metrics/mAP50-95(B)': 0.54772, 'val/box_loss': 0.39827, 'val/cls_loss': 0.81431, 'val/dfl_loss': 0.75373, 'fitness': 0.55876}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train36\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00479\n",
      "lrf: 0.00596\n",
      "momentum: 0.97159\n",
      "weight_decay: 0.0006\n",
      "warmup_epochs: 2.38143\n",
      "warmup_momentum: 0.91017\n",
      "box: 4.08711\n",
      "cls: 0.34982\n",
      "dfl: 0.98973\n",
      "hsv_h: 0.01292\n",
      "hsv_s: 0.47422\n",
      "hsv_v: 0.25266\n",
      "degrees: 0.0\n",
      "translate: 0.07031\n",
      "scale: 0.24175\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.50004\n",
      "mosaic: 0.67919\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 38/100 with hyperparameters: {'lr0': 0.00532, 'lrf': 0.00611, 'momentum': 0.92035, 'weight_decay': 0.00062, 'warmup_epochs': 2.56599, 'warmup_momentum': 0.77877, 'box': 4.08856, 'cls': 0.38569, 'dfl': 0.7539, 'hsv_h': 0.01258, 'hsv_s': 0.40469, 'hsv_v': 0.2596, 'degrees': 0.0, 'translate': 0.0662, 'scale': 0.26416, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.44783, 'mosaic': 0.62102, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m38/100 iterations complete ‚úÖ (20767.06s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.55876 observed at iteration 36\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.67427, 'metrics/recall(B)': 0.58936, 'metrics/mAP50(B)': 0.65811, 'metrics/mAP50-95(B)': 0.54772, 'val/box_loss': 0.39827, 'val/cls_loss': 0.81431, 'val/dfl_loss': 0.75373, 'fitness': 0.55876}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train36\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00479\n",
      "lrf: 0.00596\n",
      "momentum: 0.97159\n",
      "weight_decay: 0.0006\n",
      "warmup_epochs: 2.38143\n",
      "warmup_momentum: 0.91017\n",
      "box: 4.08711\n",
      "cls: 0.34982\n",
      "dfl: 0.98973\n",
      "hsv_h: 0.01292\n",
      "hsv_s: 0.47422\n",
      "hsv_v: 0.25266\n",
      "degrees: 0.0\n",
      "translate: 0.07031\n",
      "scale: 0.24175\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.50004\n",
      "mosaic: 0.67919\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 39/100 with hyperparameters: {'lr0': 0.00522, 'lrf': 0.00441, 'momentum': 0.93422, 'weight_decay': 0.00071, 'warmup_epochs': 1.85269, 'warmup_momentum': 0.95, 'box': 4.9879, 'cls': 0.35016, 'dfl': 0.99708, 'hsv_h': 0.00991, 'hsv_s': 0.59798, 'hsv_v': 0.31296, 'degrees': 0.0, 'translate': 0.07858, 'scale': 0.26416, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.50045, 'mosaic': 0.63654, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m39/100 iterations complete ‚úÖ (21309.74s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.55876 observed at iteration 36\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.67427, 'metrics/recall(B)': 0.58936, 'metrics/mAP50(B)': 0.65811, 'metrics/mAP50-95(B)': 0.54772, 'val/box_loss': 0.39827, 'val/cls_loss': 0.81431, 'val/dfl_loss': 0.75373, 'fitness': 0.55876}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train36\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00479\n",
      "lrf: 0.00596\n",
      "momentum: 0.97159\n",
      "weight_decay: 0.0006\n",
      "warmup_epochs: 2.38143\n",
      "warmup_momentum: 0.91017\n",
      "box: 4.08711\n",
      "cls: 0.34982\n",
      "dfl: 0.98973\n",
      "hsv_h: 0.01292\n",
      "hsv_s: 0.47422\n",
      "hsv_v: 0.25266\n",
      "degrees: 0.0\n",
      "translate: 0.07031\n",
      "scale: 0.24175\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.50004\n",
      "mosaic: 0.67919\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 40/100 with hyperparameters: {'lr0': 0.00625, 'lrf': 0.00589, 'momentum': 0.97089, 'weight_decay': 0.00048, 'warmup_epochs': 2.59816, 'warmup_momentum': 0.90661, 'box': 2.87975, 'cls': 0.38461, 'dfl': 1.05888, 'hsv_h': 0.01355, 'hsv_s': 0.45088, 'hsv_v': 0.20262, 'degrees': 0.0, 'translate': 0.06615, 'scale': 0.21134, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.45701, 'mosaic': 0.61371, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m40/100 iterations complete ‚úÖ (21854.93s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.55876 observed at iteration 36\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.67427, 'metrics/recall(B)': 0.58936, 'metrics/mAP50(B)': 0.65811, 'metrics/mAP50-95(B)': 0.54772, 'val/box_loss': 0.39827, 'val/cls_loss': 0.81431, 'val/dfl_loss': 0.75373, 'fitness': 0.55876}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train36\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00479\n",
      "lrf: 0.00596\n",
      "momentum: 0.97159\n",
      "weight_decay: 0.0006\n",
      "warmup_epochs: 2.38143\n",
      "warmup_momentum: 0.91017\n",
      "box: 4.08711\n",
      "cls: 0.34982\n",
      "dfl: 0.98973\n",
      "hsv_h: 0.01292\n",
      "hsv_s: 0.47422\n",
      "hsv_v: 0.25266\n",
      "degrees: 0.0\n",
      "translate: 0.07031\n",
      "scale: 0.24175\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.50004\n",
      "mosaic: 0.67919\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 41/100 with hyperparameters: {'lr0': 0.00516, 'lrf': 0.00596, 'momentum': 0.96885, 'weight_decay': 0.00061, 'warmup_epochs': 2.38143, 'warmup_momentum': 0.93936, 'box': 4.20355, 'cls': 0.34982, 'dfl': 0.94841, 'hsv_h': 0.01292, 'hsv_s': 0.47422, 'hsv_v': 0.25266, 'degrees': 0.0, 'translate': 0.0723, 'scale': 0.24624, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.51608, 'mosaic': 0.66429, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m41/100 iterations complete ‚úÖ (22399.12s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.55876 observed at iteration 36\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.67427, 'metrics/recall(B)': 0.58936, 'metrics/mAP50(B)': 0.65811, 'metrics/mAP50-95(B)': 0.54772, 'val/box_loss': 0.39827, 'val/cls_loss': 0.81431, 'val/dfl_loss': 0.75373, 'fitness': 0.55876}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train36\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00479\n",
      "lrf: 0.00596\n",
      "momentum: 0.97159\n",
      "weight_decay: 0.0006\n",
      "warmup_epochs: 2.38143\n",
      "warmup_momentum: 0.91017\n",
      "box: 4.08711\n",
      "cls: 0.34982\n",
      "dfl: 0.98973\n",
      "hsv_h: 0.01292\n",
      "hsv_s: 0.47422\n",
      "hsv_v: 0.25266\n",
      "degrees: 0.0\n",
      "translate: 0.07031\n",
      "scale: 0.24175\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.50004\n",
      "mosaic: 0.67919\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 42/100 with hyperparameters: {'lr0': 0.00502, 'lrf': 0.00659, 'momentum': 0.97256, 'weight_decay': 0.00052, 'warmup_epochs': 2.48617, 'warmup_momentum': 0.83605, 'box': 4.08711, 'cls': 0.34027, 'dfl': 0.98973, 'hsv_h': 0.0129, 'hsv_s': 0.43774, 'hsv_v': 0.27603, 'degrees': 0.0, 'translate': 0.06459, 'scale': 0.23162, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.54838, 'mosaic': 0.67919, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m42/100 iterations complete ‚úÖ (22945.30s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.55876 observed at iteration 36\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.67427, 'metrics/recall(B)': 0.58936, 'metrics/mAP50(B)': 0.65811, 'metrics/mAP50-95(B)': 0.54772, 'val/box_loss': 0.39827, 'val/cls_loss': 0.81431, 'val/dfl_loss': 0.75373, 'fitness': 0.55876}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train36\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00479\n",
      "lrf: 0.00596\n",
      "momentum: 0.97159\n",
      "weight_decay: 0.0006\n",
      "warmup_epochs: 2.38143\n",
      "warmup_momentum: 0.91017\n",
      "box: 4.08711\n",
      "cls: 0.34982\n",
      "dfl: 0.98973\n",
      "hsv_h: 0.01292\n",
      "hsv_s: 0.47422\n",
      "hsv_v: 0.25266\n",
      "degrees: 0.0\n",
      "translate: 0.07031\n",
      "scale: 0.24175\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.50004\n",
      "mosaic: 0.67919\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 43/100 with hyperparameters: {'lr0': 0.00486, 'lrf': 0.00619, 'momentum': 0.98, 'weight_decay': 0.00064, 'warmup_epochs': 2.41036, 'warmup_momentum': 0.95, 'box': 4.47757, 'cls': 0.34982, 'dfl': 0.92044, 'hsv_h': 0.0119, 'hsv_s': 0.47422, 'hsv_v': 0.24305, 'degrees': 0.0, 'translate': 0.06538, 'scale': 0.23849, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.42363, 'mosaic': 0.69098, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m43/100 iterations complete ‚úÖ (23488.08s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.55876 observed at iteration 36\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.67427, 'metrics/recall(B)': 0.58936, 'metrics/mAP50(B)': 0.65811, 'metrics/mAP50-95(B)': 0.54772, 'val/box_loss': 0.39827, 'val/cls_loss': 0.81431, 'val/dfl_loss': 0.75373, 'fitness': 0.55876}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train36\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00479\n",
      "lrf: 0.00596\n",
      "momentum: 0.97159\n",
      "weight_decay: 0.0006\n",
      "warmup_epochs: 2.38143\n",
      "warmup_momentum: 0.91017\n",
      "box: 4.08711\n",
      "cls: 0.34982\n",
      "dfl: 0.98973\n",
      "hsv_h: 0.01292\n",
      "hsv_s: 0.47422\n",
      "hsv_v: 0.25266\n",
      "degrees: 0.0\n",
      "translate: 0.07031\n",
      "scale: 0.24175\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.50004\n",
      "mosaic: 0.67919\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 44/100 with hyperparameters: {'lr0': 0.00547, 'lrf': 0.00508, 'momentum': 0.97159, 'weight_decay': 0.00062, 'warmup_epochs': 2.38143, 'warmup_momentum': 0.91017, 'box': 4.26908, 'cls': 0.35153, 'dfl': 1.06953, 'hsv_h': 0.01194, 'hsv_s': 0.47422, 'hsv_v': 0.23436, 'degrees': 0.0, 'translate': 0.07138, 'scale': 0.24175, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.48799, 'mosaic': 0.54645, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m44/100 iterations complete ‚úÖ (24032.07s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.55876 observed at iteration 36\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.67427, 'metrics/recall(B)': 0.58936, 'metrics/mAP50(B)': 0.65811, 'metrics/mAP50-95(B)': 0.54772, 'val/box_loss': 0.39827, 'val/cls_loss': 0.81431, 'val/dfl_loss': 0.75373, 'fitness': 0.55876}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train36\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00479\n",
      "lrf: 0.00596\n",
      "momentum: 0.97159\n",
      "weight_decay: 0.0006\n",
      "warmup_epochs: 2.38143\n",
      "warmup_momentum: 0.91017\n",
      "box: 4.08711\n",
      "cls: 0.34982\n",
      "dfl: 0.98973\n",
      "hsv_h: 0.01292\n",
      "hsv_s: 0.47422\n",
      "hsv_v: 0.25266\n",
      "degrees: 0.0\n",
      "translate: 0.07031\n",
      "scale: 0.24175\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.50004\n",
      "mosaic: 0.67919\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 45/100 with hyperparameters: {'lr0': 0.00464, 'lrf': 0.0059, 'momentum': 0.98, 'weight_decay': 0.00061, 'warmup_epochs': 2.43037, 'warmup_momentum': 0.88454, 'box': 4.06754, 'cls': 0.36826, 'dfl': 0.97244, 'hsv_h': 0.01205, 'hsv_s': 0.52071, 'hsv_v': 0.24266, 'degrees': 0.0, 'translate': 0.06507, 'scale': 0.24175, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.50004, 'mosaic': 0.67919, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m45/100 iterations complete ‚úÖ (24577.81s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.55876 observed at iteration 36\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.67427, 'metrics/recall(B)': 0.58936, 'metrics/mAP50(B)': 0.65811, 'metrics/mAP50-95(B)': 0.54772, 'val/box_loss': 0.39827, 'val/cls_loss': 0.81431, 'val/dfl_loss': 0.75373, 'fitness': 0.55876}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train36\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00479\n",
      "lrf: 0.00596\n",
      "momentum: 0.97159\n",
      "weight_decay: 0.0006\n",
      "warmup_epochs: 2.38143\n",
      "warmup_momentum: 0.91017\n",
      "box: 4.08711\n",
      "cls: 0.34982\n",
      "dfl: 0.98973\n",
      "hsv_h: 0.01292\n",
      "hsv_s: 0.47422\n",
      "hsv_v: 0.25266\n",
      "degrees: 0.0\n",
      "translate: 0.07031\n",
      "scale: 0.24175\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.50004\n",
      "mosaic: 0.67919\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 46/100 with hyperparameters: {'lr0': 0.00479, 'lrf': 0.00631, 'momentum': 0.98, 'weight_decay': 0.0006, 'warmup_epochs': 2.43275, 'warmup_momentum': 0.90659, 'box': 3.74091, 'cls': 0.34904, 'dfl': 0.97356, 'hsv_h': 0.01295, 'hsv_s': 0.47547, 'hsv_v': 0.2275, 'degrees': 0.0, 'translate': 0.07524, 'scale': 0.24689, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.50004, 'mosaic': 0.66874, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m46/100 iterations complete ‚úÖ (25122.12s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.56074 observed at iteration 46\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.76019, 'metrics/recall(B)': 0.57066, 'metrics/mAP50(B)': 0.66887, 'metrics/mAP50-95(B)': 0.54872, 'val/box_loss': 0.36099, 'val/cls_loss': 0.81008, 'val/dfl_loss': 0.73374, 'fitness': 0.56074}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train46\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00479\n",
      "lrf: 0.00631\n",
      "momentum: 0.98\n",
      "weight_decay: 0.0006\n",
      "warmup_epochs: 2.43275\n",
      "warmup_momentum: 0.90659\n",
      "box: 3.74091\n",
      "cls: 0.34904\n",
      "dfl: 0.97356\n",
      "hsv_h: 0.01295\n",
      "hsv_s: 0.47547\n",
      "hsv_v: 0.2275\n",
      "degrees: 0.0\n",
      "translate: 0.07524\n",
      "scale: 0.24689\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.50004\n",
      "mosaic: 0.66874\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 47/100 with hyperparameters: {'lr0': 0.00489, 'lrf': 0.00596, 'momentum': 0.96014, 'weight_decay': 0.00058, 'warmup_epochs': 2.33356, 'warmup_momentum': 0.87929, 'box': 3.74267, 'cls': 0.31742, 'dfl': 0.94496, 'hsv_h': 0.01453, 'hsv_s': 0.45117, 'hsv_v': 0.24975, 'degrees': 0.0, 'translate': 0.07525, 'scale': 0.24942, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.50409, 'mosaic': 0.70119, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m47/100 iterations complete ‚úÖ (25666.37s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.56074 observed at iteration 46\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.76019, 'metrics/recall(B)': 0.57066, 'metrics/mAP50(B)': 0.66887, 'metrics/mAP50-95(B)': 0.54872, 'val/box_loss': 0.36099, 'val/cls_loss': 0.81008, 'val/dfl_loss': 0.73374, 'fitness': 0.56074}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train46\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00479\n",
      "lrf: 0.00631\n",
      "momentum: 0.98\n",
      "weight_decay: 0.0006\n",
      "warmup_epochs: 2.43275\n",
      "warmup_momentum: 0.90659\n",
      "box: 3.74091\n",
      "cls: 0.34904\n",
      "dfl: 0.97356\n",
      "hsv_h: 0.01295\n",
      "hsv_s: 0.47547\n",
      "hsv_v: 0.2275\n",
      "degrees: 0.0\n",
      "translate: 0.07524\n",
      "scale: 0.24689\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.50004\n",
      "mosaic: 0.66874\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 48/100 with hyperparameters: {'lr0': 0.00465, 'lrf': 0.00631, 'momentum': 0.96697, 'weight_decay': 0.00058, 'warmup_epochs': 2.37737, 'warmup_momentum': 0.81127, 'box': 3.78809, 'cls': 0.37505, 'dfl': 0.89959, 'hsv_h': 0.01159, 'hsv_s': 0.47887, 'hsv_v': 0.24059, 'degrees': 0.0, 'translate': 0.07524, 'scale': 0.24689, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.50004, 'mosaic': 0.67175, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m48/100 iterations complete ‚úÖ (26211.67s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.57574 observed at iteration 48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.71983, 'metrics/recall(B)': 0.61361, 'metrics/mAP50(B)': 0.6867, 'metrics/mAP50-95(B)': 0.56341, 'val/box_loss': 0.37116, 'val/cls_loss': 0.83783, 'val/dfl_loss': 0.68347, 'fitness': 0.57574}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00465\n",
      "lrf: 0.00631\n",
      "momentum: 0.96697\n",
      "weight_decay: 0.00058\n",
      "warmup_epochs: 2.37737\n",
      "warmup_momentum: 0.81127\n",
      "box: 3.78809\n",
      "cls: 0.37505\n",
      "dfl: 0.89959\n",
      "hsv_h: 0.01159\n",
      "hsv_s: 0.47887\n",
      "hsv_v: 0.24059\n",
      "degrees: 0.0\n",
      "translate: 0.07524\n",
      "scale: 0.24689\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.50004\n",
      "mosaic: 0.67175\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 49/100 with hyperparameters: {'lr0': 0.00492, 'lrf': 0.00596, 'momentum': 0.97921, 'weight_decay': 0.00049, 'warmup_epochs': 3.01892, 'warmup_momentum': 0.91017, 'box': 4.81895, 'cls': 0.37168, 'dfl': 1.04335, 'hsv_h': 0.00929, 'hsv_s': 0.42536, 'hsv_v': 0.29497, 'degrees': 0.0, 'translate': 0.08809, 'scale': 0.24175, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.5059, 'mosaic': 0.54934, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m49/100 iterations complete ‚úÖ (26756.50s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.57574 observed at iteration 48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.71983, 'metrics/recall(B)': 0.61361, 'metrics/mAP50(B)': 0.6867, 'metrics/mAP50-95(B)': 0.56341, 'val/box_loss': 0.37116, 'val/cls_loss': 0.83783, 'val/dfl_loss': 0.68347, 'fitness': 0.57574}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00465\n",
      "lrf: 0.00631\n",
      "momentum: 0.96697\n",
      "weight_decay: 0.00058\n",
      "warmup_epochs: 2.37737\n",
      "warmup_momentum: 0.81127\n",
      "box: 3.78809\n",
      "cls: 0.37505\n",
      "dfl: 0.89959\n",
      "hsv_h: 0.01159\n",
      "hsv_s: 0.47887\n",
      "hsv_v: 0.24059\n",
      "degrees: 0.0\n",
      "translate: 0.07524\n",
      "scale: 0.24689\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.50004\n",
      "mosaic: 0.67175\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 50/100 with hyperparameters: {'lr0': 0.00443, 'lrf': 0.00654, 'momentum': 0.97055, 'weight_decay': 0.00055, 'warmup_epochs': 2.37203, 'warmup_momentum': 0.77603, 'box': 3.92975, 'cls': 0.3584, 'dfl': 0.89959, 'hsv_h': 0.01171, 'hsv_s': 0.47887, 'hsv_v': 0.22439, 'degrees': 0.0, 'translate': 0.07094, 'scale': 0.25765, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.49598, 'mosaic': 0.66276, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m50/100 iterations complete ‚úÖ (27300.52s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.57574 observed at iteration 48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.71983, 'metrics/recall(B)': 0.61361, 'metrics/mAP50(B)': 0.6867, 'metrics/mAP50-95(B)': 0.56341, 'val/box_loss': 0.37116, 'val/cls_loss': 0.83783, 'val/dfl_loss': 0.68347, 'fitness': 0.57574}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00465\n",
      "lrf: 0.00631\n",
      "momentum: 0.96697\n",
      "weight_decay: 0.00058\n",
      "warmup_epochs: 2.37737\n",
      "warmup_momentum: 0.81127\n",
      "box: 3.78809\n",
      "cls: 0.37505\n",
      "dfl: 0.89959\n",
      "hsv_h: 0.01159\n",
      "hsv_s: 0.47887\n",
      "hsv_v: 0.24059\n",
      "degrees: 0.0\n",
      "translate: 0.07524\n",
      "scale: 0.24689\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.50004\n",
      "mosaic: 0.67175\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 51/100 with hyperparameters: {'lr0': 0.00443, 'lrf': 0.0066, 'momentum': 0.9769, 'weight_decay': 0.00055, 'warmup_epochs': 1.74668, 'warmup_momentum': 0.82186, 'box': 3.93123, 'cls': 0.41906, 'dfl': 0.89959, 'hsv_h': 0.01166, 'hsv_s': 0.5404, 'hsv_v': 0.20938, 'degrees': 0.0, 'translate': 0.07094, 'scale': 0.23255, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.54592, 'mosaic': 0.67885, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m51/100 iterations complete ‚úÖ (27843.25s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.57574 observed at iteration 48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.71983, 'metrics/recall(B)': 0.61361, 'metrics/mAP50(B)': 0.6867, 'metrics/mAP50-95(B)': 0.56341, 'val/box_loss': 0.37116, 'val/cls_loss': 0.83783, 'val/dfl_loss': 0.68347, 'fitness': 0.57574}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00465\n",
      "lrf: 0.00631\n",
      "momentum: 0.96697\n",
      "weight_decay: 0.00058\n",
      "warmup_epochs: 2.37737\n",
      "warmup_momentum: 0.81127\n",
      "box: 3.78809\n",
      "cls: 0.37505\n",
      "dfl: 0.89959\n",
      "hsv_h: 0.01159\n",
      "hsv_s: 0.47887\n",
      "hsv_v: 0.24059\n",
      "degrees: 0.0\n",
      "translate: 0.07524\n",
      "scale: 0.24689\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.50004\n",
      "mosaic: 0.67175\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 52/100 with hyperparameters: {'lr0': 0.00477, 'lrf': 0.0064, 'momentum': 0.97879, 'weight_decay': 0.00057, 'warmup_epochs': 2.30651, 'warmup_momentum': 0.84414, 'box': 3.83548, 'cls': 0.37505, 'dfl': 0.89959, 'hsv_h': 0.01152, 'hsv_s': 0.46608, 'hsv_v': 0.24271, 'degrees': 0.0, 'translate': 0.07524, 'scale': 0.25348, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.47732, 'mosaic': 0.67175, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m52/100 iterations complete ‚úÖ (28388.19s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.57574 observed at iteration 48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.71983, 'metrics/recall(B)': 0.61361, 'metrics/mAP50(B)': 0.6867, 'metrics/mAP50-95(B)': 0.56341, 'val/box_loss': 0.37116, 'val/cls_loss': 0.83783, 'val/dfl_loss': 0.68347, 'fitness': 0.57574}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00465\n",
      "lrf: 0.00631\n",
      "momentum: 0.96697\n",
      "weight_decay: 0.00058\n",
      "warmup_epochs: 2.37737\n",
      "warmup_momentum: 0.81127\n",
      "box: 3.78809\n",
      "cls: 0.37505\n",
      "dfl: 0.89959\n",
      "hsv_h: 0.01159\n",
      "hsv_s: 0.47887\n",
      "hsv_v: 0.24059\n",
      "degrees: 0.0\n",
      "translate: 0.07524\n",
      "scale: 0.24689\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.50004\n",
      "mosaic: 0.67175\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 53/100 with hyperparameters: {'lr0': 0.00477, 'lrf': 0.0064, 'momentum': 0.97876, 'weight_decay': 0.00057, 'warmup_epochs': 2.30581, 'warmup_momentum': 0.84447, 'box': 3.83396, 'cls': 0.37505, 'dfl': 0.89982, 'hsv_h': 0.01153, 'hsv_s': 0.46591, 'hsv_v': 0.24271, 'degrees': 0.0, 'translate': 0.07524, 'scale': 0.25348, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.47762, 'mosaic': 0.67202, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m53/100 iterations complete ‚úÖ (28933.94s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.57574 observed at iteration 48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.71983, 'metrics/recall(B)': 0.61361, 'metrics/mAP50(B)': 0.6867, 'metrics/mAP50-95(B)': 0.56341, 'val/box_loss': 0.37116, 'val/cls_loss': 0.83783, 'val/dfl_loss': 0.68347, 'fitness': 0.57574}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00465\n",
      "lrf: 0.00631\n",
      "momentum: 0.96697\n",
      "weight_decay: 0.00058\n",
      "warmup_epochs: 2.37737\n",
      "warmup_momentum: 0.81127\n",
      "box: 3.78809\n",
      "cls: 0.37505\n",
      "dfl: 0.89959\n",
      "hsv_h: 0.01159\n",
      "hsv_s: 0.47887\n",
      "hsv_v: 0.24059\n",
      "degrees: 0.0\n",
      "translate: 0.07524\n",
      "scale: 0.24689\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.50004\n",
      "mosaic: 0.67175\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 54/100 with hyperparameters: {'lr0': 0.00443, 'lrf': 0.00643, 'momentum': 0.98, 'weight_decay': 0.00065, 'warmup_epochs': 1.72599, 'warmup_momentum': 0.83484, 'box': 3.18456, 'cls': 0.45765, 'dfl': 0.86062, 'hsv_h': 0.01687, 'hsv_s': 0.32204, 'hsv_v': 0.26569, 'degrees': 0.0, 'translate': 0.05625, 'scale': 0.22964, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.5028, 'mosaic': 0.48437, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m54/100 iterations complete ‚úÖ (29478.36s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.57574 observed at iteration 48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.71983, 'metrics/recall(B)': 0.61361, 'metrics/mAP50(B)': 0.6867, 'metrics/mAP50-95(B)': 0.56341, 'val/box_loss': 0.37116, 'val/cls_loss': 0.83783, 'val/dfl_loss': 0.68347, 'fitness': 0.57574}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00465\n",
      "lrf: 0.00631\n",
      "momentum: 0.96697\n",
      "weight_decay: 0.00058\n",
      "warmup_epochs: 2.37737\n",
      "warmup_momentum: 0.81127\n",
      "box: 3.78809\n",
      "cls: 0.37505\n",
      "dfl: 0.89959\n",
      "hsv_h: 0.01159\n",
      "hsv_s: 0.47887\n",
      "hsv_v: 0.24059\n",
      "degrees: 0.0\n",
      "translate: 0.07524\n",
      "scale: 0.24689\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.50004\n",
      "mosaic: 0.67175\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 55/100 with hyperparameters: {'lr0': 0.00511, 'lrf': 0.00596, 'momentum': 0.93707, 'weight_decay': 0.00061, 'warmup_epochs': 3.01892, 'warmup_momentum': 0.95, 'box': 5.50041, 'cls': 0.37168, 'dfl': 0.93257, 'hsv_h': 0.00812, 'hsv_s': 0.42536, 'hsv_v': 0.33074, 'degrees': 0.0, 'translate': 0.05313, 'scale': 0.18328, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.49435, 'mosaic': 0.23162, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m55/100 iterations complete ‚úÖ (30026.62s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.57574 observed at iteration 48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.71983, 'metrics/recall(B)': 0.61361, 'metrics/mAP50(B)': 0.6867, 'metrics/mAP50-95(B)': 0.56341, 'val/box_loss': 0.37116, 'val/cls_loss': 0.83783, 'val/dfl_loss': 0.68347, 'fitness': 0.57574}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00465\n",
      "lrf: 0.00631\n",
      "momentum: 0.96697\n",
      "weight_decay: 0.00058\n",
      "warmup_epochs: 2.37737\n",
      "warmup_momentum: 0.81127\n",
      "box: 3.78809\n",
      "cls: 0.37505\n",
      "dfl: 0.89959\n",
      "hsv_h: 0.01159\n",
      "hsv_s: 0.47887\n",
      "hsv_v: 0.24059\n",
      "degrees: 0.0\n",
      "translate: 0.07524\n",
      "scale: 0.24689\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.50004\n",
      "mosaic: 0.67175\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 56/100 with hyperparameters: {'lr0': 0.00529, 'lrf': 0.0064, 'momentum': 0.98, 'weight_decay': 0.00044, 'warmup_epochs': 1.92384, 'warmup_momentum': 0.57557, 'box': 4.51457, 'cls': 0.38855, 'dfl': 1.04756, 'hsv_h': 0.01071, 'hsv_s': 0.46608, 'hsv_v': 0.16453, 'degrees': 0.0, 'translate': 0.07524, 'scale': 0.25348, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.41567, 'mosaic': 0.67175, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m56/100 iterations complete ‚úÖ (30572.86s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.57574 observed at iteration 48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.71983, 'metrics/recall(B)': 0.61361, 'metrics/mAP50(B)': 0.6867, 'metrics/mAP50-95(B)': 0.56341, 'val/box_loss': 0.37116, 'val/cls_loss': 0.83783, 'val/dfl_loss': 0.68347, 'fitness': 0.57574}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00465\n",
      "lrf: 0.00631\n",
      "momentum: 0.96697\n",
      "weight_decay: 0.00058\n",
      "warmup_epochs: 2.37737\n",
      "warmup_momentum: 0.81127\n",
      "box: 3.78809\n",
      "cls: 0.37505\n",
      "dfl: 0.89959\n",
      "hsv_h: 0.01159\n",
      "hsv_s: 0.47887\n",
      "hsv_v: 0.24059\n",
      "degrees: 0.0\n",
      "translate: 0.07524\n",
      "scale: 0.24689\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.50004\n",
      "mosaic: 0.67175\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 57/100 with hyperparameters: {'lr0': 0.00465, 'lrf': 0.00599, 'momentum': 0.95582, 'weight_decay': 0.0006, 'warmup_epochs': 2.28866, 'warmup_momentum': 0.81265, 'box': 3.78809, 'cls': 0.37505, 'dfl': 0.87067, 'hsv_h': 0.01159, 'hsv_s': 0.47887, 'hsv_v': 0.23642, 'degrees': 0.0, 'translate': 0.07371, 'scale': 0.24558, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.4836, 'mosaic': 0.65265, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m57/100 iterations complete ‚úÖ (31119.01s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.57574 observed at iteration 48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.71983, 'metrics/recall(B)': 0.61361, 'metrics/mAP50(B)': 0.6867, 'metrics/mAP50-95(B)': 0.56341, 'val/box_loss': 0.37116, 'val/cls_loss': 0.83783, 'val/dfl_loss': 0.68347, 'fitness': 0.57574}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00465\n",
      "lrf: 0.00631\n",
      "momentum: 0.96697\n",
      "weight_decay: 0.00058\n",
      "warmup_epochs: 2.37737\n",
      "warmup_momentum: 0.81127\n",
      "box: 3.78809\n",
      "cls: 0.37505\n",
      "dfl: 0.89959\n",
      "hsv_h: 0.01159\n",
      "hsv_s: 0.47887\n",
      "hsv_v: 0.24059\n",
      "degrees: 0.0\n",
      "translate: 0.07524\n",
      "scale: 0.24689\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.50004\n",
      "mosaic: 0.67175\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 58/100 with hyperparameters: {'lr0': 0.00477, 'lrf': 0.00645, 'momentum': 0.97943, 'weight_decay': 0.00057, 'warmup_epochs': 2.30651, 'warmup_momentum': 0.8449, 'box': 3.87479, 'cls': 0.37958, 'dfl': 0.90006, 'hsv_h': 0.01153, 'hsv_s': 0.46445, 'hsv_v': 0.24167, 'degrees': 0.0, 'translate': 0.07524, 'scale': 0.25105, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.47466, 'mosaic': 0.67608, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m58/100 iterations complete ‚úÖ (31662.08s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.57574 observed at iteration 48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.71983, 'metrics/recall(B)': 0.61361, 'metrics/mAP50(B)': 0.6867, 'metrics/mAP50-95(B)': 0.56341, 'val/box_loss': 0.37116, 'val/cls_loss': 0.83783, 'val/dfl_loss': 0.68347, 'fitness': 0.57574}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00465\n",
      "lrf: 0.00631\n",
      "momentum: 0.96697\n",
      "weight_decay: 0.00058\n",
      "warmup_epochs: 2.37737\n",
      "warmup_momentum: 0.81127\n",
      "box: 3.78809\n",
      "cls: 0.37505\n",
      "dfl: 0.89959\n",
      "hsv_h: 0.01159\n",
      "hsv_s: 0.47887\n",
      "hsv_v: 0.24059\n",
      "degrees: 0.0\n",
      "translate: 0.07524\n",
      "scale: 0.24689\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.50004\n",
      "mosaic: 0.67175\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 59/100 with hyperparameters: {'lr0': 0.00443, 'lrf': 0.00665, 'momentum': 0.95509, 'weight_decay': 0.00055, 'warmup_epochs': 2.52431, 'warmup_momentum': 0.80005, 'box': 3.92975, 'cls': 0.34883, 'dfl': 0.97567, 'hsv_h': 0.0116, 'hsv_s': 0.47887, 'hsv_v': 0.22211, 'degrees': 0.0, 'translate': 0.08935, 'scale': 0.25765, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.49598, 'mosaic': 0.69044, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m59/100 iterations complete ‚úÖ (32207.12s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.57574 observed at iteration 48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.71983, 'metrics/recall(B)': 0.61361, 'metrics/mAP50(B)': 0.6867, 'metrics/mAP50-95(B)': 0.56341, 'val/box_loss': 0.37116, 'val/cls_loss': 0.83783, 'val/dfl_loss': 0.68347, 'fitness': 0.57574}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00465\n",
      "lrf: 0.00631\n",
      "momentum: 0.96697\n",
      "weight_decay: 0.00058\n",
      "warmup_epochs: 2.37737\n",
      "warmup_momentum: 0.81127\n",
      "box: 3.78809\n",
      "cls: 0.37505\n",
      "dfl: 0.89959\n",
      "hsv_h: 0.01159\n",
      "hsv_s: 0.47887\n",
      "hsv_v: 0.24059\n",
      "degrees: 0.0\n",
      "translate: 0.07524\n",
      "scale: 0.24689\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.50004\n",
      "mosaic: 0.67175\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 60/100 with hyperparameters: {'lr0': 0.00465, 'lrf': 0.0059, 'momentum': 0.97055, 'weight_decay': 0.00058, 'warmup_epochs': 2.49792, 'warmup_momentum': 0.77603, 'box': 3.92975, 'cls': 0.37232, 'dfl': 0.84334, 'hsv_h': 0.0121, 'hsv_s': 0.47887, 'hsv_v': 0.24274, 'degrees': 0.0, 'translate': 0.06279, 'scale': 0.25735, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.5303, 'mosaic': 0.67301, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m60/100 iterations complete ‚úÖ (32763.41s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.57574 observed at iteration 48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.71983, 'metrics/recall(B)': 0.61361, 'metrics/mAP50(B)': 0.6867, 'metrics/mAP50-95(B)': 0.56341, 'val/box_loss': 0.37116, 'val/cls_loss': 0.83783, 'val/dfl_loss': 0.68347, 'fitness': 0.57574}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00465\n",
      "lrf: 0.00631\n",
      "momentum: 0.96697\n",
      "weight_decay: 0.00058\n",
      "warmup_epochs: 2.37737\n",
      "warmup_momentum: 0.81127\n",
      "box: 3.78809\n",
      "cls: 0.37505\n",
      "dfl: 0.89959\n",
      "hsv_h: 0.01159\n",
      "hsv_s: 0.47887\n",
      "hsv_v: 0.24059\n",
      "degrees: 0.0\n",
      "translate: 0.07524\n",
      "scale: 0.24689\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.50004\n",
      "mosaic: 0.67175\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 61/100 with hyperparameters: {'lr0': 0.00527, 'lrf': 0.0071, 'momentum': 0.98, 'weight_decay': 0.00061, 'warmup_epochs': 1.85729, 'warmup_momentum': 0.53699, 'box': 3.72507, 'cls': 0.3584, 'dfl': 1.07284, 'hsv_h': 0.01252, 'hsv_s': 0.5384, 'hsv_v': 0.21825, 'degrees': 0.0, 'translate': 0.07094, 'scale': 0.24174, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.50425, 'mosaic': 0.6447, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m61/100 iterations complete ‚úÖ (33301.57s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.57574 observed at iteration 48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.71983, 'metrics/recall(B)': 0.61361, 'metrics/mAP50(B)': 0.6867, 'metrics/mAP50-95(B)': 0.56341, 'val/box_loss': 0.37116, 'val/cls_loss': 0.83783, 'val/dfl_loss': 0.68347, 'fitness': 0.57574}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00465\n",
      "lrf: 0.00631\n",
      "momentum: 0.96697\n",
      "weight_decay: 0.00058\n",
      "warmup_epochs: 2.37737\n",
      "warmup_momentum: 0.81127\n",
      "box: 3.78809\n",
      "cls: 0.37505\n",
      "dfl: 0.89959\n",
      "hsv_h: 0.01159\n",
      "hsv_s: 0.47887\n",
      "hsv_v: 0.24059\n",
      "degrees: 0.0\n",
      "translate: 0.07524\n",
      "scale: 0.24689\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.50004\n",
      "mosaic: 0.67175\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 62/100 with hyperparameters: {'lr0': 0.00485, 'lrf': 0.00779, 'momentum': 0.96481, 'weight_decay': 0.00058, 'warmup_epochs': 2.2556, 'warmup_momentum': 0.77603, 'box': 4.04641, 'cls': 0.3584, 'dfl': 0.89594, 'hsv_h': 0.01171, 'hsv_s': 0.44673, 'hsv_v': 0.18901, 'degrees': 0.0, 'translate': 0.06872, 'scale': 0.27035, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.55315, 'mosaic': 0.61445, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m62/100 iterations complete ‚úÖ (33839.73s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.57574 observed at iteration 48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.71983, 'metrics/recall(B)': 0.61361, 'metrics/mAP50(B)': 0.6867, 'metrics/mAP50-95(B)': 0.56341, 'val/box_loss': 0.37116, 'val/cls_loss': 0.83783, 'val/dfl_loss': 0.68347, 'fitness': 0.57574}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00465\n",
      "lrf: 0.00631\n",
      "momentum: 0.96697\n",
      "weight_decay: 0.00058\n",
      "warmup_epochs: 2.37737\n",
      "warmup_momentum: 0.81127\n",
      "box: 3.78809\n",
      "cls: 0.37505\n",
      "dfl: 0.89959\n",
      "hsv_h: 0.01159\n",
      "hsv_s: 0.47887\n",
      "hsv_v: 0.24059\n",
      "degrees: 0.0\n",
      "translate: 0.07524\n",
      "scale: 0.24689\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.50004\n",
      "mosaic: 0.67175\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 63/100 with hyperparameters: {'lr0': 0.0044, 'lrf': 0.00713, 'momentum': 0.98, 'weight_decay': 0.00058, 'warmup_epochs': 2.51749, 'warmup_momentum': 0.91631, 'box': 3.29979, 'cls': 0.39992, 'dfl': 0.81367, 'hsv_h': 0.01197, 'hsv_s': 0.47797, 'hsv_v': 0.22005, 'degrees': 0.0, 'translate': 0.07998, 'scale': 0.2742, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.50004, 'mosaic': 0.68101, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m63/100 iterations complete ‚úÖ (34379.22s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.57574 observed at iteration 48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.71983, 'metrics/recall(B)': 0.61361, 'metrics/mAP50(B)': 0.6867, 'metrics/mAP50-95(B)': 0.56341, 'val/box_loss': 0.37116, 'val/cls_loss': 0.83783, 'val/dfl_loss': 0.68347, 'fitness': 0.57574}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00465\n",
      "lrf: 0.00631\n",
      "momentum: 0.96697\n",
      "weight_decay: 0.00058\n",
      "warmup_epochs: 2.37737\n",
      "warmup_momentum: 0.81127\n",
      "box: 3.78809\n",
      "cls: 0.37505\n",
      "dfl: 0.89959\n",
      "hsv_h: 0.01159\n",
      "hsv_s: 0.47887\n",
      "hsv_v: 0.24059\n",
      "degrees: 0.0\n",
      "translate: 0.07524\n",
      "scale: 0.24689\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.50004\n",
      "mosaic: 0.67175\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 64/100 with hyperparameters: {'lr0': 0.00477, 'lrf': 0.00749, 'momentum': 0.91556, 'weight_decay': 0.00058, 'warmup_epochs': 1.90786, 'warmup_momentum': 0.84414, 'box': 3.83548, 'cls': 0.26202, 'dfl': 0.72447, 'hsv_h': 0.00965, 'hsv_s': 0.52145, 'hsv_v': 0.24271, 'degrees': 0.0, 'translate': 0.07524, 'scale': 0.3199, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.39792, 'mosaic': 0.63494, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m64/100 iterations complete ‚úÖ (34917.63s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.57574 observed at iteration 48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.71983, 'metrics/recall(B)': 0.61361, 'metrics/mAP50(B)': 0.6867, 'metrics/mAP50-95(B)': 0.56341, 'val/box_loss': 0.37116, 'val/cls_loss': 0.83783, 'val/dfl_loss': 0.68347, 'fitness': 0.57574}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00465\n",
      "lrf: 0.00631\n",
      "momentum: 0.96697\n",
      "weight_decay: 0.00058\n",
      "warmup_epochs: 2.37737\n",
      "warmup_momentum: 0.81127\n",
      "box: 3.78809\n",
      "cls: 0.37505\n",
      "dfl: 0.89959\n",
      "hsv_h: 0.01159\n",
      "hsv_s: 0.47887\n",
      "hsv_v: 0.24059\n",
      "degrees: 0.0\n",
      "translate: 0.07524\n",
      "scale: 0.24689\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.50004\n",
      "mosaic: 0.67175\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 65/100 with hyperparameters: {'lr0': 0.00413, 'lrf': 0.00611, 'momentum': 0.95269, 'weight_decay': 0.00062, 'warmup_epochs': 2.37557, 'warmup_momentum': 0.85819, 'box': 4.1231, 'cls': 0.37505, 'dfl': 0.68381, 'hsv_h': 0.01081, 'hsv_s': 0.4886, 'hsv_v': 0.26112, 'degrees': 0.0, 'translate': 0.07498, 'scale': 0.24923, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.51607, 'mosaic': 0.70109, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m65/100 iterations complete ‚úÖ (35457.15s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.57574 observed at iteration 48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.71983, 'metrics/recall(B)': 0.61361, 'metrics/mAP50(B)': 0.6867, 'metrics/mAP50-95(B)': 0.56341, 'val/box_loss': 0.37116, 'val/cls_loss': 0.83783, 'val/dfl_loss': 0.68347, 'fitness': 0.57574}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00465\n",
      "lrf: 0.00631\n",
      "momentum: 0.96697\n",
      "weight_decay: 0.00058\n",
      "warmup_epochs: 2.37737\n",
      "warmup_momentum: 0.81127\n",
      "box: 3.78809\n",
      "cls: 0.37505\n",
      "dfl: 0.89959\n",
      "hsv_h: 0.01159\n",
      "hsv_s: 0.47887\n",
      "hsv_v: 0.24059\n",
      "degrees: 0.0\n",
      "translate: 0.07524\n",
      "scale: 0.24689\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.50004\n",
      "mosaic: 0.67175\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 66/100 with hyperparameters: {'lr0': 0.005, 'lrf': 0.00567, 'momentum': 0.96697, 'weight_decay': 0.00058, 'warmup_epochs': 2.43471, 'warmup_momentum': 0.74237, 'box': 3.90107, 'cls': 0.34061, 'dfl': 0.89627, 'hsv_h': 0.01159, 'hsv_s': 0.4924, 'hsv_v': 0.25187, 'degrees': 0.0, 'translate': 0.07524, 'scale': 0.24098, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.48427, 'mosaic': 0.66542, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m66/100 iterations complete ‚úÖ (35991.21s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.57574 observed at iteration 48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.71983, 'metrics/recall(B)': 0.61361, 'metrics/mAP50(B)': 0.6867, 'metrics/mAP50-95(B)': 0.56341, 'val/box_loss': 0.37116, 'val/cls_loss': 0.83783, 'val/dfl_loss': 0.68347, 'fitness': 0.57574}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00465\n",
      "lrf: 0.00631\n",
      "momentum: 0.96697\n",
      "weight_decay: 0.00058\n",
      "warmup_epochs: 2.37737\n",
      "warmup_momentum: 0.81127\n",
      "box: 3.78809\n",
      "cls: 0.37505\n",
      "dfl: 0.89959\n",
      "hsv_h: 0.01159\n",
      "hsv_s: 0.47887\n",
      "hsv_v: 0.24059\n",
      "degrees: 0.0\n",
      "translate: 0.07524\n",
      "scale: 0.24689\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.50004\n",
      "mosaic: 0.67175\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 67/100 with hyperparameters: {'lr0': 0.00517, 'lrf': 0.0062, 'momentum': 0.98, 'weight_decay': 0.00058, 'warmup_epochs': 2.43571, 'warmup_momentum': 0.78767, 'box': 3.78809, 'cls': 0.32331, 'dfl': 0.92878, 'hsv_h': 0.01219, 'hsv_s': 0.45926, 'hsv_v': 0.24059, 'degrees': 0.0, 'translate': 0.08645, 'scale': 0.23121, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.50004, 'mosaic': 0.66237, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m67/100 iterations complete ‚úÖ (36533.48s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.57574 observed at iteration 48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.71983, 'metrics/recall(B)': 0.61361, 'metrics/mAP50(B)': 0.6867, 'metrics/mAP50-95(B)': 0.56341, 'val/box_loss': 0.37116, 'val/cls_loss': 0.83783, 'val/dfl_loss': 0.68347, 'fitness': 0.57574}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00465\n",
      "lrf: 0.00631\n",
      "momentum: 0.96697\n",
      "weight_decay: 0.00058\n",
      "warmup_epochs: 2.37737\n",
      "warmup_momentum: 0.81127\n",
      "box: 3.78809\n",
      "cls: 0.37505\n",
      "dfl: 0.89959\n",
      "hsv_h: 0.01159\n",
      "hsv_s: 0.47887\n",
      "hsv_v: 0.24059\n",
      "degrees: 0.0\n",
      "translate: 0.07524\n",
      "scale: 0.24689\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.50004\n",
      "mosaic: 0.67175\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 68/100 with hyperparameters: {'lr0': 0.00457, 'lrf': 0.00706, 'momentum': 0.98, 'weight_decay': 0.00054, 'warmup_epochs': 2.18358, 'warmup_momentum': 0.87873, 'box': 4.07266, 'cls': 0.30689, 'dfl': 0.66426, 'hsv_h': 0.01152, 'hsv_s': 0.42888, 'hsv_v': 0.2486, 'degrees': 0.0, 'translate': 0.0838, 'scale': 0.20764, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.47732, 'mosaic': 0.74023, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m68/100 iterations complete ‚úÖ (37073.58s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.57574 observed at iteration 48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.71983, 'metrics/recall(B)': 0.61361, 'metrics/mAP50(B)': 0.6867, 'metrics/mAP50-95(B)': 0.56341, 'val/box_loss': 0.37116, 'val/cls_loss': 0.83783, 'val/dfl_loss': 0.68347, 'fitness': 0.57574}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00465\n",
      "lrf: 0.00631\n",
      "momentum: 0.96697\n",
      "weight_decay: 0.00058\n",
      "warmup_epochs: 2.37737\n",
      "warmup_momentum: 0.81127\n",
      "box: 3.78809\n",
      "cls: 0.37505\n",
      "dfl: 0.89959\n",
      "hsv_h: 0.01159\n",
      "hsv_s: 0.47887\n",
      "hsv_v: 0.24059\n",
      "degrees: 0.0\n",
      "translate: 0.07524\n",
      "scale: 0.24689\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.50004\n",
      "mosaic: 0.67175\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 69/100 with hyperparameters: {'lr0': 0.00457, 'lrf': 0.00638, 'momentum': 0.98, 'weight_decay': 0.00063, 'warmup_epochs': 2.69836, 'warmup_momentum': 0.95, 'box': 3.74076, 'cls': 0.38706, 'dfl': 0.82008, 'hsv_h': 0.01341, 'hsv_s': 0.47887, 'hsv_v': 0.27903, 'degrees': 0.0, 'translate': 0.09285, 'scale': 0.24689, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.48855, 'mosaic': 0.67175, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m69/100 iterations complete ‚úÖ (37614.97s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.57574 observed at iteration 48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.71983, 'metrics/recall(B)': 0.61361, 'metrics/mAP50(B)': 0.6867, 'metrics/mAP50-95(B)': 0.56341, 'val/box_loss': 0.37116, 'val/cls_loss': 0.83783, 'val/dfl_loss': 0.68347, 'fitness': 0.57574}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00465\n",
      "lrf: 0.00631\n",
      "momentum: 0.96697\n",
      "weight_decay: 0.00058\n",
      "warmup_epochs: 2.37737\n",
      "warmup_momentum: 0.81127\n",
      "box: 3.78809\n",
      "cls: 0.37505\n",
      "dfl: 0.89959\n",
      "hsv_h: 0.01159\n",
      "hsv_s: 0.47887\n",
      "hsv_v: 0.24059\n",
      "degrees: 0.0\n",
      "translate: 0.07524\n",
      "scale: 0.24689\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.50004\n",
      "mosaic: 0.67175\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 70/100 with hyperparameters: {'lr0': 0.00442, 'lrf': 0.00561, 'momentum': 0.96697, 'weight_decay': 0.00058, 'warmup_epochs': 2.36307, 'warmup_momentum': 0.67799, 'box': 3.86411, 'cls': 0.41766, 'dfl': 0.91816, 'hsv_h': 0.01299, 'hsv_s': 0.50675, 'hsv_v': 0.24059, 'degrees': 0.0, 'translate': 0.07524, 'scale': 0.26778, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.50004, 'mosaic': 0.69403, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m70/100 iterations complete ‚úÖ (38153.84s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.57574 observed at iteration 48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.71983, 'metrics/recall(B)': 0.61361, 'metrics/mAP50(B)': 0.6867, 'metrics/mAP50-95(B)': 0.56341, 'val/box_loss': 0.37116, 'val/cls_loss': 0.83783, 'val/dfl_loss': 0.68347, 'fitness': 0.57574}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00465\n",
      "lrf: 0.00631\n",
      "momentum: 0.96697\n",
      "weight_decay: 0.00058\n",
      "warmup_epochs: 2.37737\n",
      "warmup_momentum: 0.81127\n",
      "box: 3.78809\n",
      "cls: 0.37505\n",
      "dfl: 0.89959\n",
      "hsv_h: 0.01159\n",
      "hsv_s: 0.47887\n",
      "hsv_v: 0.24059\n",
      "degrees: 0.0\n",
      "translate: 0.07524\n",
      "scale: 0.24689\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.50004\n",
      "mosaic: 0.67175\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 71/100 with hyperparameters: {'lr0': 0.00477, 'lrf': 0.00698, 'momentum': 0.98, 'weight_decay': 0.00066, 'warmup_epochs': 2.26513, 'warmup_momentum': 0.84414, 'box': 3.95658, 'cls': 0.34837, 'dfl': 0.91939, 'hsv_h': 0.01128, 'hsv_s': 0.41186, 'hsv_v': 0.23616, 'degrees': 0.0, 'translate': 0.07245, 'scale': 0.25034, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.45863, 'mosaic': 0.59753, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m71/100 iterations complete ‚úÖ (38694.40s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.57574 observed at iteration 48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.71983, 'metrics/recall(B)': 0.61361, 'metrics/mAP50(B)': 0.6867, 'metrics/mAP50-95(B)': 0.56341, 'val/box_loss': 0.37116, 'val/cls_loss': 0.83783, 'val/dfl_loss': 0.68347, 'fitness': 0.57574}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00465\n",
      "lrf: 0.00631\n",
      "momentum: 0.96697\n",
      "weight_decay: 0.00058\n",
      "warmup_epochs: 2.37737\n",
      "warmup_momentum: 0.81127\n",
      "box: 3.78809\n",
      "cls: 0.37505\n",
      "dfl: 0.89959\n",
      "hsv_h: 0.01159\n",
      "hsv_s: 0.47887\n",
      "hsv_v: 0.24059\n",
      "degrees: 0.0\n",
      "translate: 0.07524\n",
      "scale: 0.24689\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.50004\n",
      "mosaic: 0.67175\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 72/100 with hyperparameters: {'lr0': 0.00465, 'lrf': 0.00454, 'momentum': 0.92953, 'weight_decay': 0.0005, 'warmup_epochs': 2.15601, 'warmup_momentum': 0.81127, 'box': 5.61222, 'cls': 0.34396, 'dfl': 0.86794, 'hsv_h': 0.01026, 'hsv_s': 0.5068, 'hsv_v': 0.28997, 'degrees': 0.0, 'translate': 0.06764, 'scale': 0.26946, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.50004, 'mosaic': 0.67175, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m72/100 iterations complete ‚úÖ (39233.93s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.57574 observed at iteration 48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.71983, 'metrics/recall(B)': 0.61361, 'metrics/mAP50(B)': 0.6867, 'metrics/mAP50-95(B)': 0.56341, 'val/box_loss': 0.37116, 'val/cls_loss': 0.83783, 'val/dfl_loss': 0.68347, 'fitness': 0.57574}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00465\n",
      "lrf: 0.00631\n",
      "momentum: 0.96697\n",
      "weight_decay: 0.00058\n",
      "warmup_epochs: 2.37737\n",
      "warmup_momentum: 0.81127\n",
      "box: 3.78809\n",
      "cls: 0.37505\n",
      "dfl: 0.89959\n",
      "hsv_h: 0.01159\n",
      "hsv_s: 0.47887\n",
      "hsv_v: 0.24059\n",
      "degrees: 0.0\n",
      "translate: 0.07524\n",
      "scale: 0.24689\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.50004\n",
      "mosaic: 0.67175\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 73/100 with hyperparameters: {'lr0': 0.00451, 'lrf': 0.00615, 'momentum': 0.97001, 'weight_decay': 0.00051, 'warmup_epochs': 2.37679, 'warmup_momentum': 0.86614, 'box': 3.78809, 'cls': 0.37471, 'dfl': 0.89959, 'hsv_h': 0.01121, 'hsv_s': 0.43888, 'hsv_v': 0.24059, 'degrees': 0.0, 'translate': 0.0782, 'scale': 0.26042, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.49858, 'mosaic': 0.67175, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m73/100 iterations complete ‚úÖ (39771.42s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.57574 observed at iteration 48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.71983, 'metrics/recall(B)': 0.61361, 'metrics/mAP50(B)': 0.6867, 'metrics/mAP50-95(B)': 0.56341, 'val/box_loss': 0.37116, 'val/cls_loss': 0.83783, 'val/dfl_loss': 0.68347, 'fitness': 0.57574}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train48\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00465\n",
      "lrf: 0.00631\n",
      "momentum: 0.96697\n",
      "weight_decay: 0.00058\n",
      "warmup_epochs: 2.37737\n",
      "warmup_momentum: 0.81127\n",
      "box: 3.78809\n",
      "cls: 0.37505\n",
      "dfl: 0.89959\n",
      "hsv_h: 0.01159\n",
      "hsv_s: 0.47887\n",
      "hsv_v: 0.24059\n",
      "degrees: 0.0\n",
      "translate: 0.07524\n",
      "scale: 0.24689\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.50004\n",
      "mosaic: 0.67175\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 74/100 with hyperparameters: {'lr0': 0.00456, 'lrf': 0.00629, 'momentum': 0.9653, 'weight_decay': 0.00058, 'warmup_epochs': 2.33206, 'warmup_momentum': 0.81127, 'box': 3.77711, 'cls': 0.37321, 'dfl': 0.89959, 'hsv_h': 0.01159, 'hsv_s': 0.47069, 'hsv_v': 0.24186, 'degrees': 0.0, 'translate': 0.07338, 'scale': 0.24803, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.50004, 'mosaic': 0.66201, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m74/100 iterations complete ‚úÖ (40312.62s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.58484 observed at iteration 74\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.63508, 'metrics/recall(B)': 0.67209, 'metrics/mAP50(B)': 0.69511, 'metrics/mAP50-95(B)': 0.57259, 'val/box_loss': 0.36738, 'val/cls_loss': 0.80847, 'val/dfl_loss': 0.67835, 'fitness': 0.58484}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train74\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00456\n",
      "lrf: 0.00629\n",
      "momentum: 0.9653\n",
      "weight_decay: 0.00058\n",
      "warmup_epochs: 2.33206\n",
      "warmup_momentum: 0.81127\n",
      "box: 3.77711\n",
      "cls: 0.37321\n",
      "dfl: 0.89959\n",
      "hsv_h: 0.01159\n",
      "hsv_s: 0.47069\n",
      "hsv_v: 0.24186\n",
      "degrees: 0.0\n",
      "translate: 0.07338\n",
      "scale: 0.24803\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.50004\n",
      "mosaic: 0.66201\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 75/100 with hyperparameters: {'lr0': 0.00427, 'lrf': 0.00619, 'momentum': 0.9653, 'weight_decay': 0.00052, 'warmup_epochs': 2.40637, 'warmup_momentum': 0.81127, 'box': 3.77711, 'cls': 0.358, 'dfl': 0.84057, 'hsv_h': 0.01159, 'hsv_s': 0.44219, 'hsv_v': 0.26165, 'degrees': 0.0, 'translate': 0.07793, 'scale': 0.24803, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.50004, 'mosaic': 0.76465, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m75/100 iterations complete ‚úÖ (40852.76s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.58484 observed at iteration 74\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.63508, 'metrics/recall(B)': 0.67209, 'metrics/mAP50(B)': 0.69511, 'metrics/mAP50-95(B)': 0.57259, 'val/box_loss': 0.36738, 'val/cls_loss': 0.80847, 'val/dfl_loss': 0.67835, 'fitness': 0.58484}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train74\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00456\n",
      "lrf: 0.00629\n",
      "momentum: 0.9653\n",
      "weight_decay: 0.00058\n",
      "warmup_epochs: 2.33206\n",
      "warmup_momentum: 0.81127\n",
      "box: 3.77711\n",
      "cls: 0.37321\n",
      "dfl: 0.89959\n",
      "hsv_h: 0.01159\n",
      "hsv_s: 0.47069\n",
      "hsv_v: 0.24186\n",
      "degrees: 0.0\n",
      "translate: 0.07338\n",
      "scale: 0.24803\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.50004\n",
      "mosaic: 0.66201\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 76/100 with hyperparameters: {'lr0': 0.00456, 'lrf': 0.00629, 'momentum': 0.96471, 'weight_decay': 0.00058, 'warmup_epochs': 2.32898, 'warmup_momentum': 0.81141, 'box': 3.77791, 'cls': 0.37292, 'dfl': 0.89959, 'hsv_h': 0.0116, 'hsv_s': 0.47106, 'hsv_v': 0.24193, 'degrees': 0.0, 'translate': 0.07336, 'scale': 0.24803, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.49954, 'mosaic': 0.66248, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m76/100 iterations complete ‚úÖ (41392.35s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.58484 observed at iteration 74\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.63508, 'metrics/recall(B)': 0.67209, 'metrics/mAP50(B)': 0.69511, 'metrics/mAP50-95(B)': 0.57259, 'val/box_loss': 0.36738, 'val/cls_loss': 0.80847, 'val/dfl_loss': 0.67835, 'fitness': 0.58484}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train74\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00456\n",
      "lrf: 0.00629\n",
      "momentum: 0.9653\n",
      "weight_decay: 0.00058\n",
      "warmup_epochs: 2.33206\n",
      "warmup_momentum: 0.81127\n",
      "box: 3.77711\n",
      "cls: 0.37321\n",
      "dfl: 0.89959\n",
      "hsv_h: 0.01159\n",
      "hsv_s: 0.47069\n",
      "hsv_v: 0.24186\n",
      "degrees: 0.0\n",
      "translate: 0.07338\n",
      "scale: 0.24803\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.50004\n",
      "mosaic: 0.66201\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 77/100 with hyperparameters: {'lr0': 0.00587, 'lrf': 0.00629, 'momentum': 0.96272, 'weight_decay': 0.00065, 'warmup_epochs': 2.39951, 'warmup_momentum': 0.81127, 'box': 4.49331, 'cls': 0.3638, 'dfl': 1.03425, 'hsv_h': 0.01068, 'hsv_s': 0.41741, 'hsv_v': 0.24186, 'degrees': 0.0, 'translate': 0.07338, 'scale': 0.29886, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.56895, 'mosaic': 0.64324, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m77/100 iterations complete ‚úÖ (41933.82s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.58484 observed at iteration 74\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.63508, 'metrics/recall(B)': 0.67209, 'metrics/mAP50(B)': 0.69511, 'metrics/mAP50-95(B)': 0.57259, 'val/box_loss': 0.36738, 'val/cls_loss': 0.80847, 'val/dfl_loss': 0.67835, 'fitness': 0.58484}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train74\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00456\n",
      "lrf: 0.00629\n",
      "momentum: 0.9653\n",
      "weight_decay: 0.00058\n",
      "warmup_epochs: 2.33206\n",
      "warmup_momentum: 0.81127\n",
      "box: 3.77711\n",
      "cls: 0.37321\n",
      "dfl: 0.89959\n",
      "hsv_h: 0.01159\n",
      "hsv_s: 0.47069\n",
      "hsv_v: 0.24186\n",
      "degrees: 0.0\n",
      "translate: 0.07338\n",
      "scale: 0.24803\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.50004\n",
      "mosaic: 0.66201\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 78/100 with hyperparameters: {'lr0': 0.0045, 'lrf': 0.00536, 'momentum': 0.98, 'weight_decay': 0.00057, 'warmup_epochs': 2.33206, 'warmup_momentum': 0.90031, 'box': 4.03652, 'cls': 0.36884, 'dfl': 0.79481, 'hsv_h': 0.01159, 'hsv_s': 0.48067, 'hsv_v': 0.24186, 'degrees': 0.0, 'translate': 0.07338, 'scale': 0.28415, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.51569, 'mosaic': 0.70122, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m78/100 iterations complete ‚úÖ (42472.37s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.58484 observed at iteration 74\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.63508, 'metrics/recall(B)': 0.67209, 'metrics/mAP50(B)': 0.69511, 'metrics/mAP50-95(B)': 0.57259, 'val/box_loss': 0.36738, 'val/cls_loss': 0.80847, 'val/dfl_loss': 0.67835, 'fitness': 0.58484}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train74\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00456\n",
      "lrf: 0.00629\n",
      "momentum: 0.9653\n",
      "weight_decay: 0.00058\n",
      "warmup_epochs: 2.33206\n",
      "warmup_momentum: 0.81127\n",
      "box: 3.77711\n",
      "cls: 0.37321\n",
      "dfl: 0.89959\n",
      "hsv_h: 0.01159\n",
      "hsv_s: 0.47069\n",
      "hsv_v: 0.24186\n",
      "degrees: 0.0\n",
      "translate: 0.07338\n",
      "scale: 0.24803\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.50004\n",
      "mosaic: 0.66201\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 79/100 with hyperparameters: {'lr0': 0.00412, 'lrf': 0.00529, 'momentum': 0.92559, 'weight_decay': 0.00052, 'warmup_epochs': 2.56057, 'warmup_momentum': 0.95, 'box': 3.38139, 'cls': 0.37321, 'dfl': 0.96473, 'hsv_h': 0.01169, 'hsv_s': 0.47069, 'hsv_v': 0.17651, 'degrees': 0.0, 'translate': 0.05665, 'scale': 0.22854, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.49148, 'mosaic': 0.76302, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m79/100 iterations complete ‚úÖ (43010.91s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.58484 observed at iteration 74\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.63508, 'metrics/recall(B)': 0.67209, 'metrics/mAP50(B)': 0.69511, 'metrics/mAP50-95(B)': 0.57259, 'val/box_loss': 0.36738, 'val/cls_loss': 0.80847, 'val/dfl_loss': 0.67835, 'fitness': 0.58484}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train74\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00456\n",
      "lrf: 0.00629\n",
      "momentum: 0.9653\n",
      "weight_decay: 0.00058\n",
      "warmup_epochs: 2.33206\n",
      "warmup_momentum: 0.81127\n",
      "box: 3.77711\n",
      "cls: 0.37321\n",
      "dfl: 0.89959\n",
      "hsv_h: 0.01159\n",
      "hsv_s: 0.47069\n",
      "hsv_v: 0.24186\n",
      "degrees: 0.0\n",
      "translate: 0.07338\n",
      "scale: 0.24803\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.50004\n",
      "mosaic: 0.66201\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 80/100 with hyperparameters: {'lr0': 0.00388, 'lrf': 0.00603, 'momentum': 0.9653, 'weight_decay': 0.00059, 'warmup_epochs': 2.49169, 'warmup_momentum': 0.86467, 'box': 3.72598, 'cls': 0.30342, 'dfl': 0.92924, 'hsv_h': 0.01159, 'hsv_s': 0.47069, 'hsv_v': 0.28119, 'degrees': 0.0, 'translate': 0.06835, 'scale': 0.20348, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.66036, 'mosaic': 0.77302, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m80/100 iterations complete ‚úÖ (43550.80s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.58484 observed at iteration 74\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.63508, 'metrics/recall(B)': 0.67209, 'metrics/mAP50(B)': 0.69511, 'metrics/mAP50-95(B)': 0.57259, 'val/box_loss': 0.36738, 'val/cls_loss': 0.80847, 'val/dfl_loss': 0.67835, 'fitness': 0.58484}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train74\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00456\n",
      "lrf: 0.00629\n",
      "momentum: 0.9653\n",
      "weight_decay: 0.00058\n",
      "warmup_epochs: 2.33206\n",
      "warmup_momentum: 0.81127\n",
      "box: 3.77711\n",
      "cls: 0.37321\n",
      "dfl: 0.89959\n",
      "hsv_h: 0.01159\n",
      "hsv_s: 0.47069\n",
      "hsv_v: 0.24186\n",
      "degrees: 0.0\n",
      "translate: 0.07338\n",
      "scale: 0.24803\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.50004\n",
      "mosaic: 0.66201\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 81/100 with hyperparameters: {'lr0': 0.00424, 'lrf': 0.00471, 'momentum': 0.92559, 'weight_decay': 0.00055, 'warmup_epochs': 2.70208, 'warmup_momentum': 0.84985, 'box': 3.38139, 'cls': 0.34424, 'dfl': 0.98422, 'hsv_h': 0.01345, 'hsv_s': 0.49059, 'hsv_v': 0.19847, 'degrees': 0.0, 'translate': 0.05071, 'scale': 0.22854, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.49148, 'mosaic': 0.8798, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m81/100 iterations complete ‚úÖ (44092.04s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.59603 observed at iteration 81\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.69644, 'metrics/recall(B)': 0.64108, 'metrics/mAP50(B)': 0.70589, 'metrics/mAP50-95(B)': 0.58383, 'val/box_loss': 0.32661, 'val/cls_loss': 0.73643, 'val/dfl_loss': 0.72974, 'fitness': 0.59603}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train81\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00424\n",
      "lrf: 0.00471\n",
      "momentum: 0.92559\n",
      "weight_decay: 0.00055\n",
      "warmup_epochs: 2.70208\n",
      "warmup_momentum: 0.84985\n",
      "box: 3.38139\n",
      "cls: 0.34424\n",
      "dfl: 0.98422\n",
      "hsv_h: 0.01345\n",
      "hsv_s: 0.49059\n",
      "hsv_v: 0.19847\n",
      "degrees: 0.0\n",
      "translate: 0.05071\n",
      "scale: 0.22854\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.49148\n",
      "mosaic: 0.8798\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 82/100 with hyperparameters: {'lr0': 0.00322, 'lrf': 0.00573, 'momentum': 0.8936, 'weight_decay': 0.00046, 'warmup_epochs': 2.50932, 'warmup_momentum': 0.95, 'box': 3.94326, 'cls': 0.40523, 'dfl': 0.981, 'hsv_h': 0.01475, 'hsv_s': 0.40011, 'hsv_v': 0.19894, 'degrees': 0.0, 'translate': 0.05665, 'scale': 0.30927, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.51319, 'mosaic': 0.69561, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m82/100 iterations complete ‚úÖ (44630.27s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.61322 observed at iteration 82\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.73005, 'metrics/recall(B)': 0.67478, 'metrics/mAP50(B)': 0.73448, 'metrics/mAP50-95(B)': 0.59975, 'val/box_loss': 0.36242, 'val/cls_loss': 0.86716, 'val/dfl_loss': 0.71741, 'fitness': 0.61322}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train82\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00322\n",
      "lrf: 0.00573\n",
      "momentum: 0.8936\n",
      "weight_decay: 0.00046\n",
      "warmup_epochs: 2.50932\n",
      "warmup_momentum: 0.95\n",
      "box: 3.94326\n",
      "cls: 0.40523\n",
      "dfl: 0.981\n",
      "hsv_h: 0.01475\n",
      "hsv_s: 0.40011\n",
      "hsv_v: 0.19894\n",
      "degrees: 0.0\n",
      "translate: 0.05665\n",
      "scale: 0.30927\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.51319\n",
      "mosaic: 0.69561\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 83/100 with hyperparameters: {'lr0': 0.00237, 'lrf': 0.00573, 'momentum': 0.80042, 'weight_decay': 0.00053, 'warmup_epochs': 2.0982, 'warmup_momentum': 0.95, 'box': 4.08427, 'cls': 0.43801, 'dfl': 1.02368, 'hsv_h': 0.01271, 'hsv_s': 0.43618, 'hsv_v': 0.21372, 'degrees': 0.0, 'translate': 0.05296, 'scale': 0.33831, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.59268, 'mosaic': 0.69561, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m83/100 iterations complete ‚úÖ (45173.34s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.63322 observed at iteration 83\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.73646, 'metrics/recall(B)': 0.67436, 'metrics/mAP50(B)': 0.74295, 'metrics/mAP50-95(B)': 0.62103, 'val/box_loss': 0.3567, 'val/cls_loss': 0.85347, 'val/dfl_loss': 0.72728, 'fitness': 0.63322}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train83\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00237\n",
      "lrf: 0.00573\n",
      "momentum: 0.80042\n",
      "weight_decay: 0.00053\n",
      "warmup_epochs: 2.0982\n",
      "warmup_momentum: 0.95\n",
      "box: 4.08427\n",
      "cls: 0.43801\n",
      "dfl: 1.02368\n",
      "hsv_h: 0.01271\n",
      "hsv_s: 0.43618\n",
      "hsv_v: 0.21372\n",
      "degrees: 0.0\n",
      "translate: 0.05296\n",
      "scale: 0.33831\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.59268\n",
      "mosaic: 0.69561\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 84/100 with hyperparameters: {'lr0': 0.00233, 'lrf': 0.00573, 'momentum': 0.84513, 'weight_decay': 0.00055, 'warmup_epochs': 2.33106, 'warmup_momentum': 0.95, 'box': 3.63934, 'cls': 0.387, 'dfl': 0.91911, 'hsv_h': 0.01245, 'hsv_s': 0.43618, 'hsv_v': 0.21372, 'degrees': 0.0, 'translate': 0.05902, 'scale': 0.3572, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.70328, 'mosaic': 0.69561, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m84/100 iterations complete ‚úÖ (45714.95s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.63792 observed at iteration 84\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.78828, 'metrics/recall(B)': 0.63873, 'metrics/mAP50(B)': 0.75006, 'metrics/mAP50-95(B)': 0.62546, 'val/box_loss': 0.32196, 'val/cls_loss': 0.75138, 'val/dfl_loss': 0.66035, 'fitness': 0.63792}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train84\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00233\n",
      "lrf: 0.00573\n",
      "momentum: 0.84513\n",
      "weight_decay: 0.00055\n",
      "warmup_epochs: 2.33106\n",
      "warmup_momentum: 0.95\n",
      "box: 3.63934\n",
      "cls: 0.387\n",
      "dfl: 0.91911\n",
      "hsv_h: 0.01245\n",
      "hsv_s: 0.43618\n",
      "hsv_v: 0.21372\n",
      "degrees: 0.0\n",
      "translate: 0.05902\n",
      "scale: 0.3572\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.70328\n",
      "mosaic: 0.69561\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 85/100 with hyperparameters: {'lr0': 0.0024, 'lrf': 0.0056, 'momentum': 0.85481, 'weight_decay': 0.00052, 'warmup_epochs': 2.39095, 'warmup_momentum': 0.95, 'box': 3.89426, 'cls': 0.361, 'dfl': 0.90116, 'hsv_h': 0.01154, 'hsv_s': 0.43618, 'hsv_v': 0.21557, 'degrees': 0.0, 'translate': 0.0593, 'scale': 0.38518, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.71954, 'mosaic': 0.66625, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m85/100 iterations complete ‚úÖ (46255.92s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.63792 observed at iteration 84\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.78828, 'metrics/recall(B)': 0.63873, 'metrics/mAP50(B)': 0.75006, 'metrics/mAP50-95(B)': 0.62546, 'val/box_loss': 0.32196, 'val/cls_loss': 0.75138, 'val/dfl_loss': 0.66035, 'fitness': 0.63792}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train84\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00233\n",
      "lrf: 0.00573\n",
      "momentum: 0.84513\n",
      "weight_decay: 0.00055\n",
      "warmup_epochs: 2.33106\n",
      "warmup_momentum: 0.95\n",
      "box: 3.63934\n",
      "cls: 0.387\n",
      "dfl: 0.91911\n",
      "hsv_h: 0.01245\n",
      "hsv_s: 0.43618\n",
      "hsv_v: 0.21372\n",
      "degrees: 0.0\n",
      "translate: 0.05902\n",
      "scale: 0.3572\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.70328\n",
      "mosaic: 0.69561\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 86/100 with hyperparameters: {'lr0': 0.00272, 'lrf': 0.00445, 'momentum': 0.90973, 'weight_decay': 0.00058, 'warmup_epochs': 2.92288, 'warmup_momentum': 0.86607, 'box': 3.71162, 'cls': 0.41526, 'dfl': 0.90116, 'hsv_h': 0.01381, 'hsv_s': 0.4644, 'hsv_v': 0.193, 'degrees': 0.0, 'translate': 0.07434, 'scale': 0.51841, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.5625, 'mosaic': 0.89712, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m86/100 iterations complete ‚úÖ (46797.70s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.63792 observed at iteration 84\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.78828, 'metrics/recall(B)': 0.63873, 'metrics/mAP50(B)': 0.75006, 'metrics/mAP50-95(B)': 0.62546, 'val/box_loss': 0.32196, 'val/cls_loss': 0.75138, 'val/dfl_loss': 0.66035, 'fitness': 0.63792}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train84\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00233\n",
      "lrf: 0.00573\n",
      "momentum: 0.84513\n",
      "weight_decay: 0.00055\n",
      "warmup_epochs: 2.33106\n",
      "warmup_momentum: 0.95\n",
      "box: 3.63934\n",
      "cls: 0.387\n",
      "dfl: 0.91911\n",
      "hsv_h: 0.01245\n",
      "hsv_s: 0.43618\n",
      "hsv_v: 0.21372\n",
      "degrees: 0.0\n",
      "translate: 0.05902\n",
      "scale: 0.3572\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.70328\n",
      "mosaic: 0.69561\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 87/100 with hyperparameters: {'lr0': 0.00236, 'lrf': 0.00573, 'momentum': 0.80042, 'weight_decay': 0.00052, 'warmup_epochs': 2.22367, 'warmup_momentum': 0.93732, 'box': 3.90729, 'cls': 0.42789, 'dfl': 1.02368, 'hsv_h': 0.01248, 'hsv_s': 0.47011, 'hsv_v': 0.2153, 'degrees': 0.0, 'translate': 0.0514, 'scale': 0.34602, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.59268, 'mosaic': 0.6986, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m87/100 iterations complete ‚úÖ (47335.24s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.6389 observed at iteration 87\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.73777, 'metrics/recall(B)': 0.67914, 'metrics/mAP50(B)': 0.75266, 'metrics/mAP50-95(B)': 0.62626, 'val/box_loss': 0.341, 'val/cls_loss': 0.83995, 'val/dfl_loss': 0.72143, 'fitness': 0.6389}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train87\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00236\n",
      "lrf: 0.00573\n",
      "momentum: 0.80042\n",
      "weight_decay: 0.00052\n",
      "warmup_epochs: 2.22367\n",
      "warmup_momentum: 0.93732\n",
      "box: 3.90729\n",
      "cls: 0.42789\n",
      "dfl: 1.02368\n",
      "hsv_h: 0.01248\n",
      "hsv_s: 0.47011\n",
      "hsv_v: 0.2153\n",
      "degrees: 0.0\n",
      "translate: 0.0514\n",
      "scale: 0.34602\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.59268\n",
      "mosaic: 0.6986\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 88/100 with hyperparameters: {'lr0': 0.00227, 'lrf': 0.00524, 'momentum': 0.82026, 'weight_decay': 0.00052, 'warmup_epochs': 2.22367, 'warmup_momentum': 0.95, 'box': 4.2342, 'cls': 0.39822, 'dfl': 1.07665, 'hsv_h': 0.01248, 'hsv_s': 0.47011, 'hsv_v': 0.2153, 'degrees': 0.0, 'translate': 0.05668, 'scale': 0.38908, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.54739, 'mosaic': 0.62093, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m88/100 iterations complete ‚úÖ (47874.51s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.6389 observed at iteration 87\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.73777, 'metrics/recall(B)': 0.67914, 'metrics/mAP50(B)': 0.75266, 'metrics/mAP50-95(B)': 0.62626, 'val/box_loss': 0.341, 'val/cls_loss': 0.83995, 'val/dfl_loss': 0.72143, 'fitness': 0.6389}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train87\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00236\n",
      "lrf: 0.00573\n",
      "momentum: 0.80042\n",
      "weight_decay: 0.00052\n",
      "warmup_epochs: 2.22367\n",
      "warmup_momentum: 0.93732\n",
      "box: 3.90729\n",
      "cls: 0.42789\n",
      "dfl: 1.02368\n",
      "hsv_h: 0.01248\n",
      "hsv_s: 0.47011\n",
      "hsv_v: 0.2153\n",
      "degrees: 0.0\n",
      "translate: 0.0514\n",
      "scale: 0.34602\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.59268\n",
      "mosaic: 0.6986\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 89/100 with hyperparameters: {'lr0': 0.00197, 'lrf': 0.00421, 'momentum': 0.79569, 'weight_decay': 0.00048, 'warmup_epochs': 2.58057, 'warmup_momentum': 0.95, 'box': 4.2342, 'cls': 0.43228, 'dfl': 1.04146, 'hsv_h': 0.01246, 'hsv_s': 0.52319, 'hsv_v': 0.24713, 'degrees': 0.0, 'translate': 0.05957, 'scale': 0.35954, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.54739, 'mosaic': 0.62093, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m89/100 iterations complete ‚úÖ (48413.19s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.65229 observed at iteration 89\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.72228, 'metrics/recall(B)': 0.72646, 'metrics/mAP50(B)': 0.76291, 'metrics/mAP50-95(B)': 0.64, 'val/box_loss': 0.35973, 'val/cls_loss': 0.81522, 'val/dfl_loss': 0.72756, 'fitness': 0.65229}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train89\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00197\n",
      "lrf: 0.00421\n",
      "momentum: 0.79569\n",
      "weight_decay: 0.00048\n",
      "warmup_epochs: 2.58057\n",
      "warmup_momentum: 0.95\n",
      "box: 4.2342\n",
      "cls: 0.43228\n",
      "dfl: 1.04146\n",
      "hsv_h: 0.01246\n",
      "hsv_s: 0.52319\n",
      "hsv_v: 0.24713\n",
      "degrees: 0.0\n",
      "translate: 0.05957\n",
      "scale: 0.35954\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.54739\n",
      "mosaic: 0.62093\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 90/100 with hyperparameters: {'lr0': 0.00186, 'lrf': 0.00421, 'momentum': 0.7782, 'weight_decay': 0.00051, 'warmup_epochs': 2.3629, 'warmup_momentum': 0.77937, 'box': 3.92991, 'cls': 0.43228, 'dfl': 1.14607, 'hsv_h': 0.01216, 'hsv_s': 0.45536, 'hsv_v': 0.21757, 'degrees': 0.0, 'translate': 0.05957, 'scale': 0.34356, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.54508, 'mosaic': 0.59173, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m90/100 iterations complete ‚úÖ (48949.58s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.65669 observed at iteration 90\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.75093, 'metrics/recall(B)': 0.74766, 'metrics/mAP50(B)': 0.78596, 'metrics/mAP50-95(B)': 0.64232, 'val/box_loss': 0.33131, 'val/cls_loss': 0.8047, 'val/dfl_loss': 0.79645, 'fitness': 0.65669}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train90\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00186\n",
      "lrf: 0.00421\n",
      "momentum: 0.7782\n",
      "weight_decay: 0.00051\n",
      "warmup_epochs: 2.3629\n",
      "warmup_momentum: 0.77937\n",
      "box: 3.92991\n",
      "cls: 0.43228\n",
      "dfl: 1.14607\n",
      "hsv_h: 0.01216\n",
      "hsv_s: 0.45536\n",
      "hsv_v: 0.21757\n",
      "degrees: 0.0\n",
      "translate: 0.05957\n",
      "scale: 0.34356\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.54508\n",
      "mosaic: 0.59173\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 91/100 with hyperparameters: {'lr0': 0.00186, 'lrf': 0.00416, 'momentum': 0.78554, 'weight_decay': 0.00051, 'warmup_epochs': 2.3629, 'warmup_momentum': 0.77937, 'box': 3.94507, 'cls': 0.42016, 'dfl': 1.14781, 'hsv_h': 0.01191, 'hsv_s': 0.45337, 'hsv_v': 0.23414, 'degrees': 0.0, 'translate': 0.06014, 'scale': 0.34356, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.52758, 'mosaic': 0.61516, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m91/100 iterations complete ‚úÖ (49485.55s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.66092 observed at iteration 91\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.75014, 'metrics/recall(B)': 0.74048, 'metrics/mAP50(B)': 0.77652, 'metrics/mAP50-95(B)': 0.64808, 'val/box_loss': 0.33124, 'val/cls_loss': 0.75869, 'val/dfl_loss': 0.79808, 'fitness': 0.66092}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train91\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00186\n",
      "lrf: 0.00416\n",
      "momentum: 0.78554\n",
      "weight_decay: 0.00051\n",
      "warmup_epochs: 2.3629\n",
      "warmup_momentum: 0.77937\n",
      "box: 3.94507\n",
      "cls: 0.42016\n",
      "dfl: 1.14781\n",
      "hsv_h: 0.01191\n",
      "hsv_s: 0.45337\n",
      "hsv_v: 0.23414\n",
      "degrees: 0.0\n",
      "translate: 0.06014\n",
      "scale: 0.34356\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.52758\n",
      "mosaic: 0.61516\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 92/100 with hyperparameters: {'lr0': 0.00186, 'lrf': 0.00421, 'momentum': 0.79042, 'weight_decay': 0.00051, 'warmup_epochs': 2.26255, 'warmup_momentum': 0.77937, 'box': 3.7158, 'cls': 0.42537, 'dfl': 1.07746, 'hsv_h': 0.01236, 'hsv_s': 0.45403, 'hsv_v': 0.21152, 'degrees': 0.0, 'translate': 0.05839, 'scale': 0.34356, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.55937, 'mosaic': 0.60288, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m92/100 iterations complete ‚úÖ (50026.84s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.67244 observed at iteration 92\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.83612, 'metrics/recall(B)': 0.69725, 'metrics/mAP50(B)': 0.7896, 'metrics/mAP50-95(B)': 0.65942, 'val/box_loss': 0.3126, 'val/cls_loss': 0.75108, 'val/dfl_loss': 0.7475, 'fitness': 0.67244}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train92\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00186\n",
      "lrf: 0.00421\n",
      "momentum: 0.79042\n",
      "weight_decay: 0.00051\n",
      "warmup_epochs: 2.26255\n",
      "warmup_momentum: 0.77937\n",
      "box: 3.7158\n",
      "cls: 0.42537\n",
      "dfl: 1.07746\n",
      "hsv_h: 0.01236\n",
      "hsv_s: 0.45403\n",
      "hsv_v: 0.21152\n",
      "degrees: 0.0\n",
      "translate: 0.05839\n",
      "scale: 0.34356\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.55937\n",
      "mosaic: 0.60288\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 93/100 with hyperparameters: {'lr0': 0.00145, 'lrf': 0.00444, 'momentum': 0.76895, 'weight_decay': 0.0006, 'warmup_epochs': 2.39428, 'warmup_momentum': 0.77794, 'box': 4.84507, 'cls': 0.42065, 'dfl': 1.17332, 'hsv_h': 0.01191, 'hsv_s': 0.45532, 'hsv_v': 0.28084, 'degrees': 0.0, 'translate': 0.06495, 'scale': 0.34356, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.42593, 'mosaic': 0.56935, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m93/100 iterations complete ‚úÖ (50568.52s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.67754 observed at iteration 93\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.79194, 'metrics/recall(B)': 0.74054, 'metrics/mAP50(B)': 0.7959, 'metrics/mAP50-95(B)': 0.66439, 'val/box_loss': 0.40652, 'val/cls_loss': 0.72982, 'val/dfl_loss': 0.81337, 'fitness': 0.67754}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train93\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00145\n",
      "lrf: 0.00444\n",
      "momentum: 0.76895\n",
      "weight_decay: 0.0006\n",
      "warmup_epochs: 2.39428\n",
      "warmup_momentum: 0.77794\n",
      "box: 4.84507\n",
      "cls: 0.42065\n",
      "dfl: 1.17332\n",
      "hsv_h: 0.01191\n",
      "hsv_s: 0.45532\n",
      "hsv_v: 0.28084\n",
      "degrees: 0.0\n",
      "translate: 0.06495\n",
      "scale: 0.34356\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.42593\n",
      "mosaic: 0.56935\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 94/100 with hyperparameters: {'lr0': 0.00187, 'lrf': 0.00417, 'momentum': 0.78862, 'weight_decay': 0.0005, 'warmup_epochs': 2.26265, 'warmup_momentum': 0.77815, 'box': 3.71918, 'cls': 0.42113, 'dfl': 1.07059, 'hsv_h': 0.01215, 'hsv_s': 0.45564, 'hsv_v': 0.20863, 'degrees': 0.0, 'translate': 0.05869, 'scale': 0.3488, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.56831, 'mosaic': 0.6135, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m94/100 iterations complete ‚úÖ (51107.51s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.67754 observed at iteration 93\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.79194, 'metrics/recall(B)': 0.74054, 'metrics/mAP50(B)': 0.7959, 'metrics/mAP50-95(B)': 0.66439, 'val/box_loss': 0.40652, 'val/cls_loss': 0.72982, 'val/dfl_loss': 0.81337, 'fitness': 0.67754}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train93\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00145\n",
      "lrf: 0.00444\n",
      "momentum: 0.76895\n",
      "weight_decay: 0.0006\n",
      "warmup_epochs: 2.39428\n",
      "warmup_momentum: 0.77794\n",
      "box: 4.84507\n",
      "cls: 0.42065\n",
      "dfl: 1.17332\n",
      "hsv_h: 0.01191\n",
      "hsv_s: 0.45532\n",
      "hsv_v: 0.28084\n",
      "degrees: 0.0\n",
      "translate: 0.06495\n",
      "scale: 0.34356\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.42593\n",
      "mosaic: 0.56935\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 95/100 with hyperparameters: {'lr0': 0.00206, 'lrf': 0.00431, 'momentum': 0.79042, 'weight_decay': 0.00063, 'warmup_epochs': 2.42146, 'warmup_momentum': 0.6909, 'box': 3.88193, 'cls': 0.41611, 'dfl': 1.06105, 'hsv_h': 0.01216, 'hsv_s': 0.43999, 'hsv_v': 0.19826, 'degrees': 0.0, 'translate': 0.05413, 'scale': 0.30571, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.56093, 'mosaic': 0.60288, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m95/100 iterations complete ‚úÖ (51647.10s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.67754 observed at iteration 93\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.79194, 'metrics/recall(B)': 0.74054, 'metrics/mAP50(B)': 0.7959, 'metrics/mAP50-95(B)': 0.66439, 'val/box_loss': 0.40652, 'val/cls_loss': 0.72982, 'val/dfl_loss': 0.81337, 'fitness': 0.67754}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train93\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00145\n",
      "lrf: 0.00444\n",
      "momentum: 0.76895\n",
      "weight_decay: 0.0006\n",
      "warmup_epochs: 2.39428\n",
      "warmup_momentum: 0.77794\n",
      "box: 4.84507\n",
      "cls: 0.42065\n",
      "dfl: 1.17332\n",
      "hsv_h: 0.01191\n",
      "hsv_s: 0.45532\n",
      "hsv_v: 0.28084\n",
      "degrees: 0.0\n",
      "translate: 0.06495\n",
      "scale: 0.34356\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.42593\n",
      "mosaic: 0.56935\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 96/100 with hyperparameters: {'lr0': 0.00194, 'lrf': 0.00451, 'momentum': 0.79038, 'weight_decay': 0.00044, 'warmup_epochs': 2.26255, 'warmup_momentum': 0.77937, 'box': 3.35675, 'cls': 0.44241, 'dfl': 1.05192, 'hsv_h': 0.01165, 'hsv_s': 0.38743, 'hsv_v': 0.21152, 'degrees': 0.0, 'translate': 0.05516, 'scale': 0.31352, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.54376, 'mosaic': 0.58309, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m96/100 iterations complete ‚úÖ (52186.74s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.67754 observed at iteration 93\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.79194, 'metrics/recall(B)': 0.74054, 'metrics/mAP50(B)': 0.7959, 'metrics/mAP50-95(B)': 0.66439, 'val/box_loss': 0.40652, 'val/cls_loss': 0.72982, 'val/dfl_loss': 0.81337, 'fitness': 0.67754}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train93\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00145\n",
      "lrf: 0.00444\n",
      "momentum: 0.76895\n",
      "weight_decay: 0.0006\n",
      "warmup_epochs: 2.39428\n",
      "warmup_momentum: 0.77794\n",
      "box: 4.84507\n",
      "cls: 0.42065\n",
      "dfl: 1.17332\n",
      "hsv_h: 0.01191\n",
      "hsv_s: 0.45532\n",
      "hsv_v: 0.28084\n",
      "degrees: 0.0\n",
      "translate: 0.06495\n",
      "scale: 0.34356\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.42593\n",
      "mosaic: 0.56935\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 97/100 with hyperparameters: {'lr0': 0.00136, 'lrf': 0.00444, 'momentum': 0.81667, 'weight_decay': 0.00057, 'warmup_epochs': 2.63231, 'warmup_momentum': 0.78998, 'box': 5.71264, 'cls': 0.51503, 'dfl': 1.17118, 'hsv_h': 0.01138, 'hsv_s': 0.32346, 'hsv_v': 0.27755, 'degrees': 0.0, 'translate': 0.0691, 'scale': 0.33645, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.39794, 'mosaic': 0.61276, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m97/100 iterations complete ‚úÖ (52727.75s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.67754 observed at iteration 93\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.79194, 'metrics/recall(B)': 0.74054, 'metrics/mAP50(B)': 0.7959, 'metrics/mAP50-95(B)': 0.66439, 'val/box_loss': 0.40652, 'val/cls_loss': 0.72982, 'val/dfl_loss': 0.81337, 'fitness': 0.67754}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train93\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00145\n",
      "lrf: 0.00444\n",
      "momentum: 0.76895\n",
      "weight_decay: 0.0006\n",
      "warmup_epochs: 2.39428\n",
      "warmup_momentum: 0.77794\n",
      "box: 4.84507\n",
      "cls: 0.42065\n",
      "dfl: 1.17332\n",
      "hsv_h: 0.01191\n",
      "hsv_s: 0.45532\n",
      "hsv_v: 0.28084\n",
      "degrees: 0.0\n",
      "translate: 0.06495\n",
      "scale: 0.34356\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.42593\n",
      "mosaic: 0.56935\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 98/100 with hyperparameters: {'lr0': 0.00188, 'lrf': 0.00421, 'momentum': 0.79556, 'weight_decay': 0.0005, 'warmup_epochs': 2.31999, 'warmup_momentum': 0.77227, 'box': 3.78204, 'cls': 0.42537, 'dfl': 1.13537, 'hsv_h': 0.01213, 'hsv_s': 0.45079, 'hsv_v': 0.21061, 'degrees': 0.0, 'translate': 0.0592, 'scale': 0.34044, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.55937, 'mosaic': 0.59397, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m98/100 iterations complete ‚úÖ (53267.99s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.67754 observed at iteration 93\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.79194, 'metrics/recall(B)': 0.74054, 'metrics/mAP50(B)': 0.7959, 'metrics/mAP50-95(B)': 0.66439, 'val/box_loss': 0.40652, 'val/cls_loss': 0.72982, 'val/dfl_loss': 0.81337, 'fitness': 0.67754}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train93\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00145\n",
      "lrf: 0.00444\n",
      "momentum: 0.76895\n",
      "weight_decay: 0.0006\n",
      "warmup_epochs: 2.39428\n",
      "warmup_momentum: 0.77794\n",
      "box: 4.84507\n",
      "cls: 0.42065\n",
      "dfl: 1.17332\n",
      "hsv_h: 0.01191\n",
      "hsv_s: 0.45532\n",
      "hsv_v: 0.28084\n",
      "degrees: 0.0\n",
      "translate: 0.06495\n",
      "scale: 0.34356\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.42593\n",
      "mosaic: 0.56935\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 99/100 with hyperparameters: {'lr0': 0.00139, 'lrf': 0.00451, 'momentum': 0.79574, 'weight_decay': 0.00062, 'warmup_epochs': 2.54068, 'warmup_momentum': 0.79765, 'box': 5.71264, 'cls': 0.54307, 'dfl': 1.2873, 'hsv_h': 0.01058, 'hsv_s': 0.32346, 'hsv_v': 0.27755, 'degrees': 0.0, 'translate': 0.07377, 'scale': 0.33645, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.34681, 'mosaic': 0.59517, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m99/100 iterations complete ‚úÖ (53808.63s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.67754 observed at iteration 93\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.79194, 'metrics/recall(B)': 0.74054, 'metrics/mAP50(B)': 0.7959, 'metrics/mAP50-95(B)': 0.66439, 'val/box_loss': 0.40652, 'val/cls_loss': 0.72982, 'val/dfl_loss': 0.81337, 'fitness': 0.67754}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train93\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00145\n",
      "lrf: 0.00444\n",
      "momentum: 0.76895\n",
      "weight_decay: 0.0006\n",
      "warmup_epochs: 2.39428\n",
      "warmup_momentum: 0.77794\n",
      "box: 4.84507\n",
      "cls: 0.42065\n",
      "dfl: 1.17332\n",
      "hsv_h: 0.01191\n",
      "hsv_s: 0.45532\n",
      "hsv_v: 0.28084\n",
      "degrees: 0.0\n",
      "translate: 0.06495\n",
      "scale: 0.34356\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.42593\n",
      "mosaic: 0.56935\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mStarting iteration 100/100 with hyperparameters: {'lr0': 0.0014, 'lrf': 0.00389, 'momentum': 0.86483, 'weight_decay': 0.00051, 'warmup_epochs': 2.42407, 'warmup_momentum': 0.7062, 'box': 4.8047, 'cls': 0.55176, 'dfl': 1.30247, 'hsv_h': 0.01081, 'hsv_s': 0.35795, 'hsv_v': 0.27755, 'degrees': 0.0, 'translate': 0.06503, 'scale': 0.31424, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.40367, 'mosaic': 0.67375, 'mixup': 0.0, 'copy_paste': 0.0}\n",
      "Saved runs\\detect\\tune\\tune_scatter_plots.png\n",
      "Saved runs\\detect\\tune\\tune_fitness.png\n",
      "\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0m100/100 iterations complete ‚úÖ (54348.80s)\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mResults saved to \u001b[1mruns\\detect\\tune\u001b[0m\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness=0.67754 observed at iteration 93\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness metrics are {'metrics/precision(B)': 0.79194, 'metrics/recall(B)': 0.74054, 'metrics/mAP50(B)': 0.7959, 'metrics/mAP50-95(B)': 0.66439, 'val/box_loss': 0.40652, 'val/cls_loss': 0.72982, 'val/dfl_loss': 0.81337, 'fitness': 0.67754}\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness model is runs\\detect\\train93\n",
      "\u001b[34m\u001b[1mTuner: \u001b[0mBest fitness hyperparameters are printed below.\n",
      "\n",
      "Printing '\u001b[1m\u001b[30mruns\\detect\\tune\\best_hyperparameters.yaml\u001b[0m'\n",
      "\n",
      "lr0: 0.00145\n",
      "lrf: 0.00444\n",
      "momentum: 0.76895\n",
      "weight_decay: 0.0006\n",
      "warmup_epochs: 2.39428\n",
      "warmup_momentum: 0.77794\n",
      "box: 4.84507\n",
      "cls: 0.42065\n",
      "dfl: 1.17332\n",
      "hsv_h: 0.01191\n",
      "hsv_s: 0.45532\n",
      "hsv_v: 0.28084\n",
      "degrees: 0.0\n",
      "translate: 0.06495\n",
      "scale: 0.34356\n",
      "shear: 0.0\n",
      "perspective: 0.0\n",
      "flipud: 0.0\n",
      "fliplr: 0.42593\n",
      "mosaic: 0.56935\n",
      "mixup: 0.0\n",
      "copy_paste: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Initialize the YOLO model\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "model.tune(data='data.yaml', epochs=10, iterations=100, optimizer='AdamW', plots=True, save=False, val=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.1.40 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.27 üöÄ Python-3.10.13 torch-2.2.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=data.yaml, epochs=100, time=None, patience=24, batch=24, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=AdamW, verbose=True, seed=13, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=0, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.1, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.00145, lrf=0.00444, momentum=0.76895, weight_decay=0.0006, warmup_epochs=2.39428, warmup_momentum=0.77794, warmup_bias_lr=0.1, box=4.845, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.01191, hsv_s=0.45532, hsv_v=0.28084, degrees=0.0, translate=0.06495, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=0.56935, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train\n",
      "Overriding model.yaml nc=80 with nc=7\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    752677  ultralytics.nn.modules.head.Detect           [7, [64, 128, 256]]           \n",
      "Model summary: 225 layers, 3012213 parameters, 3012197 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\train\\labels... 5868 images, 568 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5868/5868 [00:02<00:00, 2620.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\train\\labels.cache\n",
      "WARNING ‚ö†Ô∏è Box and segment counts should be equal, but got len(segments) = 8270, len(boxes) = 8576. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\valid\\labels... 565 images, 51 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 565/565 [00:00<00:00, 1362.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\valid\\labels.cache\n",
      "WARNING ‚ö†Ô∏è Box and segment counts should be equal, but got len(segments) = 779, len(boxes) = 810. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n",
      "Plotting labels to runs\\detect\\train\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00145, momentum=0.76895) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.000675), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100      3.19G     0.6285      2.294      1.446         21        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:43<00:00,  5.66it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.295      0.368      0.268      0.179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/100       3.2G     0.6424      1.854      1.459         25        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:39<00:00,  6.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.337      0.346      0.284      0.167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/100       3.2G     0.6255      1.699      1.441         23        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:39<00:00,  6.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.421      0.515      0.459      0.325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/100       3.2G     0.5814       1.54      1.389         27        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:39<00:00,  6.20it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810       0.51      0.524      0.522       0.41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/100       3.2G     0.5638      1.409      1.364         22        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:39<00:00,  6.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.694      0.588       0.63      0.482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/100       3.2G     0.5474      1.342       1.35         26        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:39<00:00,  6.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.469      0.521       0.49      0.371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/100       3.2G     0.5258      1.242      1.322         28        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.687       0.65      0.698      0.532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/100       3.2G     0.5182      1.193      1.309         36        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:39<00:00,  6.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.687      0.584      0.651      0.482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/100       3.2G     0.5028      1.137      1.291         29        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.724      0.631      0.704      0.553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/100       3.2G     0.5033      1.118      1.286         37        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.779      0.651      0.754        0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/100       3.2G     0.4912      1.059      1.274         17        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:39<00:00,  6.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.665      0.615      0.661      0.516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/100       3.2G      0.482      1.025      1.258         34        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:39<00:00,  6.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810       0.76      0.677      0.752      0.609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/100       3.2G     0.4779     0.9983      1.255         44        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.06it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.671      0.695      0.736      0.574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/100       3.2G     0.4734      0.973      1.253         30        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:39<00:00,  6.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.745      0.673      0.754      0.602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/100       3.2G     0.4657     0.9404      1.232         50        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:39<00:00,  6.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.763      0.757      0.805       0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/100       3.2G     0.4635     0.9176      1.233         18        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:39<00:00,  6.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810       0.76       0.71       0.77      0.627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/100       3.2G     0.4561     0.8923      1.224         29        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:39<00:00,  6.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.829      0.725      0.821      0.667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/100       3.2G     0.4461     0.8524      1.219         30        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.765        0.7      0.781      0.638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/100       3.2G     0.4484     0.8544       1.22         47        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.723      0.719      0.779      0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/100       3.2G     0.4407      0.831      1.209         22        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.805      0.752      0.811      0.665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/100       3.2G     0.4397     0.8233       1.21         25        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:39<00:00,  6.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.772      0.673      0.784      0.634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/100       3.2G     0.4277     0.7858      1.192         37        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:39<00:00,  6.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.853      0.735      0.834      0.689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/100       3.2G     0.4269     0.7799      1.194         43        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.741      0.647      0.705      0.557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/100       3.2G     0.4267     0.7649      1.194         26        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:39<00:00,  6.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.827      0.753      0.822      0.685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     25/100       3.2G     0.4228     0.7573      1.192         28        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:39<00:00,  6.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810       0.83      0.755      0.837      0.688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     26/100       3.2G     0.4239     0.7378      1.186         22        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.834      0.771      0.841      0.696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     27/100       3.2G     0.4182     0.7275       1.18         37        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.798      0.782      0.835      0.694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     28/100       3.2G     0.4145     0.7238      1.177         28        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.797      0.777      0.829      0.698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     29/100       3.2G     0.4163     0.7141      1.179         26        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.795      0.795      0.847      0.708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     30/100       3.2G     0.4061     0.6937      1.166         27        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.848      0.756      0.826      0.687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     31/100       3.2G     0.4033     0.6864      1.161         24        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.807      0.777      0.826      0.691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     32/100       3.2G     0.4036     0.6675      1.164         33        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.812      0.784      0.832      0.703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     33/100       3.2G     0.3999     0.6558      1.158         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.819       0.82       0.86      0.716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     34/100       3.2G     0.3954     0.6456      1.157         30        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.823      0.808      0.862       0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     35/100       3.2G     0.3914     0.6349      1.148         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.802      0.768      0.824      0.678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     36/100       3.2G     0.3927     0.6384      1.147         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.832       0.79      0.855      0.719\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     37/100       3.2G      0.387     0.6284      1.141         26        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.841      0.765      0.852       0.72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     38/100       3.2G     0.3839     0.6129      1.138         26        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810       0.86      0.777       0.86      0.726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     39/100       3.2G     0.3827     0.6103      1.136         32        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.834      0.829      0.865      0.736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     40/100       3.2G     0.3791     0.6008      1.133         29        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:39<00:00,  6.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.838      0.804      0.853      0.718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     41/100       3.2G     0.3788     0.5929      1.133         32        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.856      0.807      0.865      0.732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     42/100       3.2G     0.3811     0.5949      1.129         25        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.866      0.789      0.854       0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     43/100       3.2G     0.3725     0.5685      1.124         29        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.846      0.821      0.866      0.734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     44/100       3.2G     0.3747     0.5768      1.126         37        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:39<00:00,  6.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.861      0.782      0.864      0.731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     45/100       3.2G      0.373     0.5689      1.129         30        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.844      0.824      0.868       0.74\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     46/100       3.2G     0.3657     0.5608      1.119         40        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:39<00:00,  6.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.861        0.8      0.863      0.731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     47/100       3.2G     0.3663     0.5589      1.119         32        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.865      0.826      0.874      0.744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     48/100       3.2G     0.3622     0.5555      1.112         37        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810       0.87      0.762      0.859      0.726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     49/100       3.2G     0.3647     0.5555      1.111         35        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.868      0.797      0.865      0.738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     50/100       3.2G     0.3583     0.5454      1.106         32        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.876      0.796      0.867      0.747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     51/100       3.2G     0.3579     0.5427      1.104         26        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.05it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.873      0.783      0.867      0.744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     52/100       3.2G      0.357     0.5286        1.1         27        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810        0.9      0.793      0.868      0.746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     53/100       3.2G     0.3544      0.525      1.105         30        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.834       0.81      0.851      0.734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     54/100       3.2G     0.3498     0.5189        1.1         18        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.835      0.822      0.872      0.748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     55/100       3.2G     0.3599     0.5278      1.109         36        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:39<00:00,  6.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.862      0.828      0.869      0.742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     56/100       3.2G     0.3499     0.5149      1.099         32        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.07it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.876      0.793      0.867      0.746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     57/100       3.2G     0.3516     0.5078      1.097         30        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.878      0.798      0.873      0.756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     58/100       3.2G     0.3452     0.5087       1.09         33        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.864      0.816      0.876      0.753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     59/100       3.2G     0.3446     0.4943      1.091         38        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.04it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.871      0.833      0.884      0.759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     60/100       3.2G     0.3371     0.4911      1.087         41        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810        0.9      0.788      0.875      0.756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     61/100       3.2G     0.3459     0.4865      1.087         26        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:39<00:00,  6.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.877      0.819      0.884      0.761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     62/100       3.2G     0.3419     0.4851      1.083         31        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.868      0.827      0.883      0.764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     63/100       3.2G     0.3401     0.4796      1.088         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:39<00:00,  6.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.871      0.829      0.881      0.762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     64/100       3.2G     0.3368     0.4836      1.083         62        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.894      0.786      0.882      0.762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     65/100       3.2G     0.3371     0.4791      1.081         25        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.862      0.835       0.89      0.769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     66/100       3.2G     0.3313     0.4694      1.076         30        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:39<00:00,  6.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.894      0.787      0.871      0.758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     67/100       3.2G     0.3303     0.4661      1.074         24        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.899        0.8      0.878      0.761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     68/100       3.2G     0.3277     0.4586      1.072         16        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.897      0.818      0.886       0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     69/100       3.2G      0.328     0.4593      1.068         30        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.889      0.821      0.884      0.765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     70/100       3.2G     0.3233     0.4488       1.07         24        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.898      0.802       0.88      0.763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     71/100       3.2G     0.3194     0.4489      1.064         29        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.879      0.809       0.88      0.761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     72/100       3.2G     0.3177     0.4428      1.056         32        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.884      0.799      0.879      0.762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     73/100       3.2G     0.3203     0.4451      1.058         20        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810       0.86       0.83       0.88      0.767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     74/100       3.2G     0.3161      0.445      1.064         71        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.885      0.816      0.885      0.769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     75/100       3.2G     0.3172     0.4416      1.056         34        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:39<00:00,  6.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.892      0.801      0.873      0.762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     76/100       3.2G     0.3145     0.4349      1.056         29        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:39<00:00,  6.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.903      0.816      0.884      0.766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     77/100       3.2G     0.3134     0.4379      1.058         19        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810       0.88      0.823      0.881      0.765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     78/100       3.2G     0.3099     0.4211      1.051         33        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.864      0.818      0.876      0.761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     79/100       3.2G     0.3064     0.4168      1.047         22        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.887      0.809      0.876      0.761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     80/100       3.2G     0.3074     0.4275      1.052         24        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810       0.87      0.817      0.876      0.762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     81/100       3.2G     0.3035     0.4146      1.048         21        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:39<00:00,  6.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.891      0.801      0.875       0.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     82/100       3.2G     0.3017       0.41      1.041         21        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.11it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.842      0.856      0.878      0.766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     83/100       3.2G     0.2961     0.3992       1.04         28        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.848      0.846      0.881      0.769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     84/100       3.2G     0.2989     0.4015      1.042         32        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:39<00:00,  6.17it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.897      0.811       0.88      0.765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     85/100       3.2G     0.2995     0.4048      1.039         22        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.09it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.866      0.834       0.88      0.764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     86/100       3.2G     0.2992     0.4066      1.041         27        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.899      0.821      0.882      0.769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     87/100       3.2G     0.2957     0.4013      1.035         40        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.08it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.904      0.802      0.879      0.767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     88/100      3.21G     0.2966     0.3967      1.043         28        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.10it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.914      0.812      0.881       0.77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     89/100       3.2G     0.2939     0.3967      1.038         22        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 245/245 [00:40<00:00,  6.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.902      0.818      0.881      0.766\n",
      "Stopping training early as no improvement observed in last 24 epochs. Best results observed at epoch 65, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=24) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "89 epochs completed in 1.066 hours.\n",
      "Optimizer stripped from runs\\detect\\train\\weights\\last.pt, 6.3MB\n",
      "Optimizer stripped from runs\\detect\\train\\weights\\best.pt, 6.3MB\n",
      "\n",
      "Validating runs\\detect\\train\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.1.27 üöÄ Python-3.10.13 torch-2.2.1+cu121 CUDA:0 (NVIDIA GeForce RTX 4060 Laptop GPU, 8188MiB)\n",
      "Model summary (fused): 168 layers, 3007013 parameters, 0 gradients, 8.1 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:02<00:00,  4.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        565        810      0.863      0.835      0.891      0.771\n",
      "               General        565        165       0.73      0.656      0.727      0.541\n",
      "                 Glass        565         97      0.943      0.948      0.968      0.873\n",
      "                 Metal        565        116      0.945      0.885      0.946      0.847\n",
      "                 Paper        565        184      0.913        0.8      0.912      0.857\n",
      "               Plastic        565         95      0.939      0.863      0.951      0.845\n",
      "             Styrofoam        565         42      0.653      0.857       0.82      0.675\n",
      "                 Vinyl        565        111      0.917      0.838       0.91       0.76\n",
      "Speed: 0.3ms preprocess, 1.7ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ultralytics.utils.metrics.DetMetrics object with attributes:\n",
       "\n",
       "ap_class_index: array([0, 1, 2, 3, 4, 5, 6])\n",
       "box: ultralytics.utils.metrics.Metric object\n",
       "confusion_matrix: <ultralytics.utils.metrics.ConfusionMatrix object at 0x000002993C7EDC00>\n",
       "curves: ['Precision-Recall(B)', 'F1-Confidence(B)', 'Precision-Confidence(B)', 'Recall-Confidence(B)']\n",
       "curves_results: [[array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[          1,           1,           1, ...,   0.0011927,  0.00059634,           0],\n",
       "       [          1,           1,           1, ...,    0.068539,     0.03427,           0],\n",
       "       [          1,           1,           1, ...,    0.018885,   0.0094424,           0],\n",
       "       ...,\n",
       "       [          1,           1,           1, ...,    0.026011,    0.013006,           0],\n",
       "       [          1,           1,           1, ...,    0.003425,   0.0017125,           0],\n",
       "       [          1,           1,           1, ...,   0.0086761,    0.004338,           0]]), 'Recall', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.16317,     0.16317,     0.22711, ...,           0,           0,           0],\n",
       "       [    0.52033,     0.52033,     0.59812, ...,           0,           0,           0],\n",
       "       [    0.57069,     0.57069,     0.64285, ...,           0,           0,           0],\n",
       "       ...,\n",
       "       [    0.42759,     0.42759,     0.53019, ...,           0,           0,           0],\n",
       "       [    0.15009,     0.15009,      0.1906, ...,           0,           0,           0],\n",
       "       [    0.32416,     0.32416,     0.38706, ...,           0,           0,           0]]), 'Confidence', 'F1'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[   0.090264,    0.090264,     0.13124, ...,           1,           1,           1],\n",
       "       [    0.35294,     0.35294,     0.42856, ...,           1,           1,           1],\n",
       "       [    0.40659,     0.40659,     0.48624, ...,           1,           1,           1],\n",
       "       ...,\n",
       "       [    0.27353,     0.27353,     0.36354, ...,           1,           1,           1],\n",
       "       [   0.081466,    0.081466,      0.1059, ...,           1,           1,           1],\n",
       "       [    0.19521,     0.19521,     0.24272, ...,           1,           1,           1]]), 'Confidence', 'Precision'], [array([          0,    0.001001,    0.002002,    0.003003,    0.004004,    0.005005,    0.006006,    0.007007,    0.008008,    0.009009,     0.01001,    0.011011,    0.012012,    0.013013,    0.014014,    0.015015,    0.016016,    0.017017,    0.018018,    0.019019,     0.02002,    0.021021,    0.022022,    0.023023,\n",
       "          0.024024,    0.025025,    0.026026,    0.027027,    0.028028,    0.029029,     0.03003,    0.031031,    0.032032,    0.033033,    0.034034,    0.035035,    0.036036,    0.037037,    0.038038,    0.039039,     0.04004,    0.041041,    0.042042,    0.043043,    0.044044,    0.045045,    0.046046,    0.047047,\n",
       "          0.048048,    0.049049,     0.05005,    0.051051,    0.052052,    0.053053,    0.054054,    0.055055,    0.056056,    0.057057,    0.058058,    0.059059,     0.06006,    0.061061,    0.062062,    0.063063,    0.064064,    0.065065,    0.066066,    0.067067,    0.068068,    0.069069,     0.07007,    0.071071,\n",
       "          0.072072,    0.073073,    0.074074,    0.075075,    0.076076,    0.077077,    0.078078,    0.079079,     0.08008,    0.081081,    0.082082,    0.083083,    0.084084,    0.085085,    0.086086,    0.087087,    0.088088,    0.089089,     0.09009,    0.091091,    0.092092,    0.093093,    0.094094,    0.095095,\n",
       "          0.096096,    0.097097,    0.098098,    0.099099,      0.1001,      0.1011,      0.1021,      0.1031,      0.1041,     0.10511,     0.10611,     0.10711,     0.10811,     0.10911,     0.11011,     0.11111,     0.11211,     0.11311,     0.11411,     0.11512,     0.11612,     0.11712,     0.11812,     0.11912,\n",
       "           0.12012,     0.12112,     0.12212,     0.12312,     0.12412,     0.12513,     0.12613,     0.12713,     0.12813,     0.12913,     0.13013,     0.13113,     0.13213,     0.13313,     0.13413,     0.13514,     0.13614,     0.13714,     0.13814,     0.13914,     0.14014,     0.14114,     0.14214,     0.14314,\n",
       "           0.14414,     0.14515,     0.14615,     0.14715,     0.14815,     0.14915,     0.15015,     0.15115,     0.15215,     0.15315,     0.15415,     0.15516,     0.15616,     0.15716,     0.15816,     0.15916,     0.16016,     0.16116,     0.16216,     0.16316,     0.16416,     0.16517,     0.16617,     0.16717,\n",
       "           0.16817,     0.16917,     0.17017,     0.17117,     0.17217,     0.17317,     0.17417,     0.17518,     0.17618,     0.17718,     0.17818,     0.17918,     0.18018,     0.18118,     0.18218,     0.18318,     0.18418,     0.18519,     0.18619,     0.18719,     0.18819,     0.18919,     0.19019,     0.19119,\n",
       "           0.19219,     0.19319,     0.19419,      0.1952,      0.1962,      0.1972,      0.1982,      0.1992,      0.2002,      0.2012,      0.2022,      0.2032,      0.2042,     0.20521,     0.20621,     0.20721,     0.20821,     0.20921,     0.21021,     0.21121,     0.21221,     0.21321,     0.21421,     0.21522,\n",
       "           0.21622,     0.21722,     0.21822,     0.21922,     0.22022,     0.22122,     0.22222,     0.22322,     0.22422,     0.22523,     0.22623,     0.22723,     0.22823,     0.22923,     0.23023,     0.23123,     0.23223,     0.23323,     0.23423,     0.23524,     0.23624,     0.23724,     0.23824,     0.23924,\n",
       "           0.24024,     0.24124,     0.24224,     0.24324,     0.24424,     0.24525,     0.24625,     0.24725,     0.24825,     0.24925,     0.25025,     0.25125,     0.25225,     0.25325,     0.25425,     0.25526,     0.25626,     0.25726,     0.25826,     0.25926,     0.26026,     0.26126,     0.26226,     0.26326,\n",
       "           0.26426,     0.26527,     0.26627,     0.26727,     0.26827,     0.26927,     0.27027,     0.27127,     0.27227,     0.27327,     0.27427,     0.27528,     0.27628,     0.27728,     0.27828,     0.27928,     0.28028,     0.28128,     0.28228,     0.28328,     0.28428,     0.28529,     0.28629,     0.28729,\n",
       "           0.28829,     0.28929,     0.29029,     0.29129,     0.29229,     0.29329,     0.29429,      0.2953,      0.2963,      0.2973,      0.2983,      0.2993,      0.3003,      0.3013,      0.3023,      0.3033,      0.3043,     0.30531,     0.30631,     0.30731,     0.30831,     0.30931,     0.31031,     0.31131,\n",
       "           0.31231,     0.31331,     0.31431,     0.31532,     0.31632,     0.31732,     0.31832,     0.31932,     0.32032,     0.32132,     0.32232,     0.32332,     0.32432,     0.32533,     0.32633,     0.32733,     0.32833,     0.32933,     0.33033,     0.33133,     0.33233,     0.33333,     0.33433,     0.33534,\n",
       "           0.33634,     0.33734,     0.33834,     0.33934,     0.34034,     0.34134,     0.34234,     0.34334,     0.34434,     0.34535,     0.34635,     0.34735,     0.34835,     0.34935,     0.35035,     0.35135,     0.35235,     0.35335,     0.35435,     0.35536,     0.35636,     0.35736,     0.35836,     0.35936,\n",
       "           0.36036,     0.36136,     0.36236,     0.36336,     0.36436,     0.36537,     0.36637,     0.36737,     0.36837,     0.36937,     0.37037,     0.37137,     0.37237,     0.37337,     0.37437,     0.37538,     0.37638,     0.37738,     0.37838,     0.37938,     0.38038,     0.38138,     0.38238,     0.38338,\n",
       "           0.38438,     0.38539,     0.38639,     0.38739,     0.38839,     0.38939,     0.39039,     0.39139,     0.39239,     0.39339,     0.39439,      0.3954,      0.3964,      0.3974,      0.3984,      0.3994,      0.4004,      0.4014,      0.4024,      0.4034,      0.4044,     0.40541,     0.40641,     0.40741,\n",
       "           0.40841,     0.40941,     0.41041,     0.41141,     0.41241,     0.41341,     0.41441,     0.41542,     0.41642,     0.41742,     0.41842,     0.41942,     0.42042,     0.42142,     0.42242,     0.42342,     0.42442,     0.42543,     0.42643,     0.42743,     0.42843,     0.42943,     0.43043,     0.43143,\n",
       "           0.43243,     0.43343,     0.43443,     0.43544,     0.43644,     0.43744,     0.43844,     0.43944,     0.44044,     0.44144,     0.44244,     0.44344,     0.44444,     0.44545,     0.44645,     0.44745,     0.44845,     0.44945,     0.45045,     0.45145,     0.45245,     0.45345,     0.45445,     0.45546,\n",
       "           0.45646,     0.45746,     0.45846,     0.45946,     0.46046,     0.46146,     0.46246,     0.46346,     0.46446,     0.46547,     0.46647,     0.46747,     0.46847,     0.46947,     0.47047,     0.47147,     0.47247,     0.47347,     0.47447,     0.47548,     0.47648,     0.47748,     0.47848,     0.47948,\n",
       "           0.48048,     0.48148,     0.48248,     0.48348,     0.48448,     0.48549,     0.48649,     0.48749,     0.48849,     0.48949,     0.49049,     0.49149,     0.49249,     0.49349,     0.49449,      0.4955,      0.4965,      0.4975,      0.4985,      0.4995,      0.5005,      0.5015,      0.5025,      0.5035,\n",
       "            0.5045,     0.50551,     0.50651,     0.50751,     0.50851,     0.50951,     0.51051,     0.51151,     0.51251,     0.51351,     0.51451,     0.51552,     0.51652,     0.51752,     0.51852,     0.51952,     0.52052,     0.52152,     0.52252,     0.52352,     0.52452,     0.52553,     0.52653,     0.52753,\n",
       "           0.52853,     0.52953,     0.53053,     0.53153,     0.53253,     0.53353,     0.53453,     0.53554,     0.53654,     0.53754,     0.53854,     0.53954,     0.54054,     0.54154,     0.54254,     0.54354,     0.54454,     0.54555,     0.54655,     0.54755,     0.54855,     0.54955,     0.55055,     0.55155,\n",
       "           0.55255,     0.55355,     0.55455,     0.55556,     0.55656,     0.55756,     0.55856,     0.55956,     0.56056,     0.56156,     0.56256,     0.56356,     0.56456,     0.56557,     0.56657,     0.56757,     0.56857,     0.56957,     0.57057,     0.57157,     0.57257,     0.57357,     0.57457,     0.57558,\n",
       "           0.57658,     0.57758,     0.57858,     0.57958,     0.58058,     0.58158,     0.58258,     0.58358,     0.58458,     0.58559,     0.58659,     0.58759,     0.58859,     0.58959,     0.59059,     0.59159,     0.59259,     0.59359,     0.59459,      0.5956,      0.5966,      0.5976,      0.5986,      0.5996,\n",
       "            0.6006,      0.6016,      0.6026,      0.6036,      0.6046,     0.60561,     0.60661,     0.60761,     0.60861,     0.60961,     0.61061,     0.61161,     0.61261,     0.61361,     0.61461,     0.61562,     0.61662,     0.61762,     0.61862,     0.61962,     0.62062,     0.62162,     0.62262,     0.62362,\n",
       "           0.62462,     0.62563,     0.62663,     0.62763,     0.62863,     0.62963,     0.63063,     0.63163,     0.63263,     0.63363,     0.63463,     0.63564,     0.63664,     0.63764,     0.63864,     0.63964,     0.64064,     0.64164,     0.64264,     0.64364,     0.64464,     0.64565,     0.64665,     0.64765,\n",
       "           0.64865,     0.64965,     0.65065,     0.65165,     0.65265,     0.65365,     0.65465,     0.65566,     0.65666,     0.65766,     0.65866,     0.65966,     0.66066,     0.66166,     0.66266,     0.66366,     0.66466,     0.66567,     0.66667,     0.66767,     0.66867,     0.66967,     0.67067,     0.67167,\n",
       "           0.67267,     0.67367,     0.67467,     0.67568,     0.67668,     0.67768,     0.67868,     0.67968,     0.68068,     0.68168,     0.68268,     0.68368,     0.68468,     0.68569,     0.68669,     0.68769,     0.68869,     0.68969,     0.69069,     0.69169,     0.69269,     0.69369,     0.69469,      0.6957,\n",
       "            0.6967,      0.6977,      0.6987,      0.6997,      0.7007,      0.7017,      0.7027,      0.7037,      0.7047,     0.70571,     0.70671,     0.70771,     0.70871,     0.70971,     0.71071,     0.71171,     0.71271,     0.71371,     0.71471,     0.71572,     0.71672,     0.71772,     0.71872,     0.71972,\n",
       "           0.72072,     0.72172,     0.72272,     0.72372,     0.72472,     0.72573,     0.72673,     0.72773,     0.72873,     0.72973,     0.73073,     0.73173,     0.73273,     0.73373,     0.73473,     0.73574,     0.73674,     0.73774,     0.73874,     0.73974,     0.74074,     0.74174,     0.74274,     0.74374,\n",
       "           0.74474,     0.74575,     0.74675,     0.74775,     0.74875,     0.74975,     0.75075,     0.75175,     0.75275,     0.75375,     0.75475,     0.75576,     0.75676,     0.75776,     0.75876,     0.75976,     0.76076,     0.76176,     0.76276,     0.76376,     0.76476,     0.76577,     0.76677,     0.76777,\n",
       "           0.76877,     0.76977,     0.77077,     0.77177,     0.77277,     0.77377,     0.77477,     0.77578,     0.77678,     0.77778,     0.77878,     0.77978,     0.78078,     0.78178,     0.78278,     0.78378,     0.78478,     0.78579,     0.78679,     0.78779,     0.78879,     0.78979,     0.79079,     0.79179,\n",
       "           0.79279,     0.79379,     0.79479,      0.7958,      0.7968,      0.7978,      0.7988,      0.7998,      0.8008,      0.8018,      0.8028,      0.8038,      0.8048,     0.80581,     0.80681,     0.80781,     0.80881,     0.80981,     0.81081,     0.81181,     0.81281,     0.81381,     0.81481,     0.81582,\n",
       "           0.81682,     0.81782,     0.81882,     0.81982,     0.82082,     0.82182,     0.82282,     0.82382,     0.82482,     0.82583,     0.82683,     0.82783,     0.82883,     0.82983,     0.83083,     0.83183,     0.83283,     0.83383,     0.83483,     0.83584,     0.83684,     0.83784,     0.83884,     0.83984,\n",
       "           0.84084,     0.84184,     0.84284,     0.84384,     0.84484,     0.84585,     0.84685,     0.84785,     0.84885,     0.84985,     0.85085,     0.85185,     0.85285,     0.85385,     0.85485,     0.85586,     0.85686,     0.85786,     0.85886,     0.85986,     0.86086,     0.86186,     0.86286,     0.86386,\n",
       "           0.86486,     0.86587,     0.86687,     0.86787,     0.86887,     0.86987,     0.87087,     0.87187,     0.87287,     0.87387,     0.87487,     0.87588,     0.87688,     0.87788,     0.87888,     0.87988,     0.88088,     0.88188,     0.88288,     0.88388,     0.88488,     0.88589,     0.88689,     0.88789,\n",
       "           0.88889,     0.88989,     0.89089,     0.89189,     0.89289,     0.89389,     0.89489,      0.8959,      0.8969,      0.8979,      0.8989,      0.8999,      0.9009,      0.9019,      0.9029,      0.9039,      0.9049,     0.90591,     0.90691,     0.90791,     0.90891,     0.90991,     0.91091,     0.91191,\n",
       "           0.91291,     0.91391,     0.91491,     0.91592,     0.91692,     0.91792,     0.91892,     0.91992,     0.92092,     0.92192,     0.92292,     0.92392,     0.92492,     0.92593,     0.92693,     0.92793,     0.92893,     0.92993,     0.93093,     0.93193,     0.93293,     0.93393,     0.93493,     0.93594,\n",
       "           0.93694,     0.93794,     0.93894,     0.93994,     0.94094,     0.94194,     0.94294,     0.94394,     0.94494,     0.94595,     0.94695,     0.94795,     0.94895,     0.94995,     0.95095,     0.95195,     0.95295,     0.95395,     0.95495,     0.95596,     0.95696,     0.95796,     0.95896,     0.95996,\n",
       "           0.96096,     0.96196,     0.96296,     0.96396,     0.96496,     0.96597,     0.96697,     0.96797,     0.96897,     0.96997,     0.97097,     0.97197,     0.97297,     0.97397,     0.97497,     0.97598,     0.97698,     0.97798,     0.97898,     0.97998,     0.98098,     0.98198,     0.98298,     0.98398,\n",
       "           0.98498,     0.98599,     0.98699,     0.98799,     0.98899,     0.98999,     0.99099,     0.99199,     0.99299,     0.99399,     0.99499,       0.996,       0.997,       0.998,       0.999,           1]), array([[    0.84848,     0.84848,     0.84242, ...,           0,           0,           0],\n",
       "       [    0.98969,     0.98969,     0.98969, ...,           0,           0,           0],\n",
       "       [     0.9569,      0.9569,     0.94828, ...,           0,           0,           0],\n",
       "       ...,\n",
       "       [    0.97895,     0.97895,     0.97895, ...,           0,           0,           0],\n",
       "       [    0.95238,     0.95238,     0.95238, ...,           0,           0,           0],\n",
       "       [    0.95495,     0.95495,     0.95495, ...,           0,           0,           0]]), 'Confidence', 'Recall']]\n",
       "fitness: 0.7829964795171735\n",
       "keys: ['metrics/precision(B)', 'metrics/recall(B)', 'metrics/mAP50(B)', 'metrics/mAP50-95(B)']\n",
       "maps: array([    0.54053,     0.87344,     0.84707,     0.85666,     0.84451,      0.6749,     0.76021])\n",
       "names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       "plot: True\n",
       "results_dict: {'metrics/precision(B)': 0.8627888596914188, 'metrics/recall(B)': 0.8354001574399872, 'metrics/mAP50(B)': 0.890537626704212, 'metrics/mAP50-95(B)': 0.7710474631630582, 'fitness': 0.7829964795171735}\n",
       "save_dir: WindowsPath('runs/detect/train')\n",
       "speed: {'preprocess': 0.2689424869233528, 'inference': 1.7193321633127938, 'loss': 0.0, 'postprocess': 0.8583452849261528}\n",
       "task: 'detect'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(data='data.yaml', epochs=100, patience=24, batch=24, imgsz=640, optimizer = 'AdamW',\n",
    "            lr0=0.00145, # Ï¥àÍ∏∞ ÌïôÏäµÎ•†\n",
    "            lrf=0.00444,  # ÏµúÏ¢Ö ÌïôÏäµÎ•†\n",
    "            momentum = 0.76895,\n",
    "            weight_decay= 0.0006,\n",
    "            warmup_epochs = 2.39428,\n",
    "            warmup_momentum = 0.77794,\n",
    "            box = 4.845,\n",
    "            hsv_h= 0.01191,\n",
    "            hsv_s= 0.45532,\n",
    "            hsv_v= 0.28084,\n",
    "            translate = 0.06495,\n",
    "            mosaic = 0.56935,\n",
    "            dropout=0.10, # Í≥ºÏ†ÅÌï© Î∞©ÏßÄ 10ÌîÑÎ°úÏùò Îâ¥Îü∞ÏùÑ ÎÅÑÍ≥† ÌïôÏäµ\n",
    "            close_mosaic=0, # Ïò§Î•ò Î∞©ÏßÄ Ìï¥Îãπ Í∏∞Îä•ÏùÑ ÌÇ§Î©¥ ÌïôÏäµÏ§ëÏóê Î©àÏ∂§\n",
    "            seed=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'> 7\n"
     ]
    }
   ],
   "source": [
    "print(type(model.names), len(model.names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\-10_png.rf.ca08aef0e8f9d37d91f824809a55dea5.jpg: 640x640 1 Vinyl, 24.2ms\n",
      "image 2/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\-2_jpg.rf.38f87f357926e771563db44f60d7ad1a.jpg: 640x640 1 Metal, 16.4ms\n",
      "image 3/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\-4_jpg.rf.ff57349f27ca3ad85c3794266368d483.jpg: 640x640 1 Styrofoam, 17.0ms\n",
      "image 4/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\-7_jpg.rf.4a8ccd140c4ba931bb5f1ece10e8bc43.jpg: 640x640 1 General, 16.8ms\n",
      "image 5/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\KakaoTalk_20240318_201036576_15_jpg.rf.e8213b3b8450d429976e5501d263ae90.jpg: 640x640 1 Styrofoam, 17.0ms\n",
      "image 6/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\KakaoTalk_20240318_201036576_27_jpg.rf.7d61334e505e3fc5a94ae6ac1809b49b.jpg: 640x640 1 Plastic, 1 Styrofoam, 17.0ms\n",
      "image 7/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\KakaoTalk_20240318_201036576_29_jpg.rf.7ca8feafa30c0a93bd3614d9f1233592.jpg: 640x640 2 Plastics, 18.8ms\n",
      "image 8/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\KakaoTalk_20240318_201232732_19_jpg.rf.089a2f5833a0956fb1da062cc5c21e05.jpg: 640x640 11 Styrofoams, 13.8ms\n",
      "image 9/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\KakaoTalk_20240324_131152410_20_jpg.rf.1ed9648cd8b2da5fd5a8091574ede5fd.jpg: 640x640 2 Vinyls, 14.3ms\n",
      "image 10/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\KakaoTalk_20240327_123311918_09_jpg.rf.66a410a879cee1e66ed1f2831c035f73.jpg: 640x640 1 General, 1 Metal, 1 Vinyl, 14.0ms\n",
      "image 11/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\KakaoTalk_20240327_215401964_10_jpg.rf.686798155a97065b325493d246460a7f.jpg: 640x640 (no detections), 15.0ms\n",
      "image 12/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\KakaoTalk_20240327_215401964_19_jpg.rf.5ef13914d7402426950dbba5f5f58c96.jpg: 640x640 (no detections), 15.0ms\n",
      "image 13/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\KakaoTalk_20240327_215401964_25_jpg.rf.2be72a3b46dc1db2a296a3b6c3c6c652.jpg: 640x640 (no detections), 14.0ms\n",
      "image 14/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\KakaoTalk_20240327_215428250_jpg.rf.eb522eac2d0ce1c422717ed42b836c9e.jpg: 640x640 1 General, 11.0ms\n",
      "image 15/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\cardboard_001_jpg.rf.189779a1e2567315d25672b5d3c5ada4.jpg: 640x640 1 Paper, 11.3ms\n",
      "image 16/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\cardboard_014_jpg.rf.417593edd331ff5fab50495fc2c114fb.jpg: 640x640 1 Paper, 11.0ms\n",
      "image 17/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\cardboard_029_jpg.rf.4f25115e76eaec84f86468ac7d698b9d.jpg: 640x640 1 Paper, 11.1ms\n",
      "image 18/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\cardboard_036_jpg.rf.429aba1fe5a95fed206b9b00f81905eb.jpg: 640x640 2 Generals, 1 Paper, 11.0ms\n",
      "image 19/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\cardboard_046_jpg.rf.9e68be18de30ad0e56798a0bd648c6c4.jpg: 640x640 1 Paper, 11.1ms\n",
      "image 20/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\cardboard_051_jpg.rf.7f12344b1a0a8fd92559f6b0309f718a.jpg: 640x640 1 Paper, 11.0ms\n",
      "image 21/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\cardboard_052_jpg.rf.efddfd497d9180736586111711500f2d.jpg: 640x640 1 General, 1 Paper, 11.0ms\n",
      "image 22/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\cardboard_082_jpg.rf.5c3cbc40859cb19eae068f8a7ef8cb93.jpg: 640x640 1 Paper, 10.0ms\n",
      "image 23/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\cardboard_085_jpg.rf.df0887c8f24ab538688d13f682565dca.jpg: 640x640 1 Paper, 10.0ms\n",
      "image 24/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\cardboard_096_jpg.rf.2ce9e082f11b100e8d52c054d6035795.jpg: 640x640 1 Paper, 10.0ms\n",
      "image 25/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\cardboard_101_jpg.rf.f339a07690a2c78a45b4b45d68d9f6ed.jpg: 640x640 1 Paper, 12.0ms\n",
      "image 26/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\cardboard_104_jpg.rf.4c7cd37d9cff1815567b677c55f76004.jpg: 640x640 1 General, 1 Paper, 10.0ms\n",
      "image 27/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\cardboard_115_jpg.rf.97c5e691a0d576e5ad9a42d492418b4f.jpg: 640x640 (no detections), 10.0ms\n",
      "image 28/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\cardboard_117_jpg.rf.8b1328048d58217bb9a907f8ac5c19ed.jpg: 640x640 1 Metal, 10.0ms\n",
      "image 29/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\cardboard_126_jpg.rf.2a848186e9030d732f08cfbea5382c96.jpg: 640x640 1 General, 10.0ms\n",
      "image 30/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\cardboard_133_jpg.rf.27c3c2db5487683fc37cbe169683aff5.jpg: 640x640 1 Paper, 10.0ms\n",
      "image 31/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\cardboard_152_jpg.rf.641f17ae6d55af4105f21774b58dd09f.jpg: 640x640 1 Paper, 10.0ms\n",
      "image 32/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\cardboard_168_jpg.rf.15a6827a2938e5c30dcbf4ec2fb07ba0.jpg: 640x640 1 Paper, 11.0ms\n",
      "image 33/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\cardboard_176_jpg.rf.22bdc6ba0d1bc442de5b006a7456916f.jpg: 640x640 1 Paper, 13.0ms\n",
      "image 34/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\cardboard_184_jpg.rf.5560004504226f77131e0d8f30de1117.jpg: 640x640 1 Paper, 11.0ms\n",
      "image 35/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\cardboard_187_jpg.rf.f21f8d81293a415a3fb802f56d0f2f39.jpg: 640x640 1 Paper, 10.0ms\n",
      "image 36/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\cardboard_192_jpg.rf.d400add3caee55b025fb87464ef3d416.jpg: 640x640 1 General, 11.0ms\n",
      "image 37/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\cardboard_204_jpg.rf.7ffe96e9c0c8008ea8a8db776e49e448.jpg: 640x640 1 Paper, 11.0ms\n",
      "image 38/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\cardboard_210_jpg.rf.e661176ed4ef7286e0a45b2fa0ba1c31.jpg: 640x640 1 Paper, 11.0ms\n",
      "image 39/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\cardboard_216_jpg.rf.e5ddcb9c3628928ac640b2b26af8444b.jpg: 640x640 1 Paper, 10.0ms\n",
      "image 40/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\cardboard_220_jpg.rf.64f5f4bf6fe56e2c83b15cd1a8e2d639.jpg: 640x640 1 Paper, 10.0ms\n",
      "image 41/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\cardboard_224_jpg.rf.db871777d64a20f709d093ddca049ee7.jpg: 640x640 1 Paper, 10.0ms\n",
      "image 42/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\cardboard_230_jpg.rf.f87574008aa02a5838e3c6280f2c869d.jpg: 640x640 1 Paper, 10.0ms\n",
      "image 43/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\cardboard_256_jpg.rf.0c79864105e81af365cc44afa65e9c35.jpg: 640x640 1 General, 1 Paper, 10.0ms\n",
      "image 44/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\cardboard_272_jpg.rf.f0bc195374c513c5c523cb529d14084b.jpg: 640x640 1 Paper, 11.0ms\n",
      "image 45/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\cardboard_273_jpg.rf.ff981b36d1a017568d0926995bac8a71.jpg: 640x640 1 General, 1 Paper, 10.0ms\n",
      "image 46/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\cardboard_275_jpg.rf.84eca7830de28547bc6af9af4cacbfb9.jpg: 640x640 1 Paper, 10.0ms\n",
      "image 47/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\cardboard_280_jpg.rf.ece5300ac0d2059a8db7ffe10d0245fc.jpg: 640x640 1 Paper, 10.0ms\n",
      "image 48/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\cardboard_285_jpg.rf.87eb4366ecc8985acb417da06170a484.jpg: 640x640 1 Paper, 10.0ms\n",
      "image 49/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\cardboard_322_jpg.rf.8308dacc0e7b7a12021fadbafbaef720.jpg: 640x640 1 Paper, 10.0ms\n",
      "image 50/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\cardboard_323_jpg.rf.b3bd5464d49322cd5a7197a5d5e3159c.jpg: 640x640 1 General, 1 Paper, 10.0ms\n",
      "image 51/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\cardboard_328_jpg.rf.6b0f44f7a36c0f2b1579afbcd4c479c2.jpg: 640x640 1 Paper, 10.0ms\n",
      "image 52/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\cardboard_329_jpg.rf.57ef3666d2c939662821867d72e5785b.jpg: 640x640 (no detections), 10.0ms\n",
      "image 53/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\cardboard_332_jpg.rf.e4e86d77007eb3d022efa8d64b0a6ae0.jpg: 640x640 1 Paper, 10.0ms\n",
      "image 54/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\cardboard_366_jpg.rf.93401d6163fc82fdc06b61776d2d20f3.jpg: 640x640 (no detections), 10.0ms\n",
      "image 55/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\cardboard_369_jpg.rf.b72911cfe06b87c01b0eb02818b65055.jpg: 640x640 1 General, 10.0ms\n",
      "image 56/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\cardboard_375_jpg.rf.79383eddd74333f535f3aa6977114a76.jpg: 640x640 1 Paper, 9.2ms\n",
      "image 57/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\cardboard_379_jpg.rf.40d6daa8c4c4dd2cd9ba28bfa5ff5bdf.jpg: 640x640 1 Paper, 9.5ms\n",
      "image 58/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\cardboard_380_jpg.rf.c855447a932e36645ff19a0a29bbc907.jpg: 640x640 1 Paper, 11.5ms\n",
      "image 59/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\glass_001_jpg.rf.7f34ba942db382943290ac9b2dea27b0.jpg: 640x640 1 Glass, 10.0ms\n",
      "image 60/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\glass_006_jpg.rf.104b4daed7bb2fd5d00ef5936e67bc3d.jpg: 640x640 1 General, 10.0ms\n",
      "image 61/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\glass_013_jpg.rf.159ccb025e4a73c8332b0f57798afb2a.jpg: 640x640 1 Glass, 9.0ms\n",
      "image 62/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\glass_014_jpg.rf.8b6ebfdf2f782baf88b77eeebb0509d6.jpg: 640x640 1 Glass, 12.0ms\n",
      "image 63/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\glass_024_jpg.rf.fa54a0e483946566bc0f034aaba92f8f.jpg: 640x640 1 Glass, 9.0ms\n",
      "image 64/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\glass_033_jpg.rf.ea58319fa1125b70234ade4de6ac883a.jpg: 640x640 2 Glasss, 10.0ms\n",
      "image 65/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\glass_037_jpg.rf.fb99dbfea00c6da06aaf71cd9a96b788.jpg: 640x640 1 Glass, 10.0ms\n",
      "image 66/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\glass_039_jpg.rf.fc76548920db5a26eca1145dca13dbe7.jpg: 640x640 1 Glass, 10.0ms\n",
      "image 67/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\glass_071_jpg.rf.6a339812ef1536bd63874c5abdcbb7c2.jpg: 640x640 1 Glass, 11.0ms\n",
      "image 68/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\glass_072_jpg.rf.db82f9879c528293f6620ebf8d40a706.jpg: 640x640 1 Glass, 10.0ms\n",
      "image 69/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\glass_077_jpg.rf.d95f97c620c25af0cf4b1f7d3d0c3b4c.jpg: 640x640 1 Glass, 1 Metal, 10.1ms\n",
      "image 70/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\glass_092_jpg.rf.8bb0fc7b76d973057e44794eb51fc3e3.jpg: 640x640 1 Glass, 11.0ms\n",
      "image 71/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\glass_095_jpg.rf.200919d733f451a191fd70b6b8592179.jpg: 640x640 1 Glass, 10.0ms\n",
      "image 72/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\glass_106_jpg.rf.2b492dd6650b4d440522aca379543123.jpg: 640x640 1 General, 10.0ms\n",
      "image 73/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\glass_125_jpg.rf.4088fe8a70b0159bf60753f628bc5130.jpg: 640x640 1 Glass, 10.0ms\n",
      "image 74/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\glass_141_jpg.rf.40b851ad852d6eab2d092a494df72e89.jpg: 640x640 1 Metal, 10.0ms\n",
      "image 75/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\glass_148_jpg.rf.403fd7a8e99d4194669d31ccb629629d.jpg: 640x640 1 Glass, 10.0ms\n",
      "image 76/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\glass_151_jpg.rf.be67fd0e06b5fba8ae15311deddca151.jpg: 640x640 1 Glass, 10.0ms\n",
      "image 77/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\glass_166_jpg.rf.826c8c2bbad9b08596bc81cab8967cd4.jpg: 640x640 1 Plastic, 1 Vinyl, 10.0ms\n",
      "image 78/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\glass_171_jpg.rf.7bce2d72f5a5f9e94a7031a60e893eab.jpg: 640x640 1 Glass, 10.0ms\n",
      "image 79/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\glass_181_jpg.rf.cc7b98993ea127b5e78bb7f6ff96ee73.jpg: 640x640 1 Glass, 1 Plastic, 9.0ms\n",
      "image 80/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\glass_183_jpg.rf.a4c96ce0a46edf59a10c53c2ab78f225.jpg: 640x640 1 Glass, 9.0ms\n",
      "image 81/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\glass_221_jpg.rf.f27a6e7f36286ee8864e609f5a0ebba0.jpg: 640x640 1 Glass, 11.0ms\n",
      "image 82/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\glass_226_jpg.rf.d85be6a12c89ef01598bcb387e586fd0.jpg: 640x640 1 Glass, 10.0ms\n",
      "image 83/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\glass_236_jpg.rf.15446596270aa4d86bd9fcb51241074f.jpg: 640x640 1 Glass, 9.0ms\n",
      "image 84/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\glass_237_jpg.rf.df1ece31177a1b6bc81d09593e968daa.jpg: 640x640 1 Glass, 9.0ms\n",
      "image 85/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\glass_255_jpg.rf.249c844ccab2f5d6682c5872ae9d48ce.jpg: 640x640 1 Glass, 1 Metal, 10.0ms\n",
      "image 86/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\glass_257_jpg.rf.e49e5d2935b54d121e19ffa43a007b36.jpg: 640x640 1 General, 9.0ms\n",
      "image 87/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\glass_260_jpg.rf.e9a31fcacdca18b523e9cbcf193eca5c.jpg: 640x640 1 Glass, 10.0ms\n",
      "image 88/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\glass_272_jpg.rf.3e98885e5d525de66b52adae305696d6.jpg: 640x640 1 Glass, 11.0ms\n",
      "image 89/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\glass_289_jpg.rf.241d2850d1a585416155546cdb9cc263.jpg: 640x640 1 Glass, 9.2ms\n",
      "image 90/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\glass_291_jpg.rf.2142efe967a6d5f71b8dd313a1b91d8b.jpg: 640x640 1 Glass, 9.0ms\n",
      "image 91/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\glass_300_jpg.rf.db26b29877857a09e10bf2c9cc69f7b3.jpg: 640x640 1 Glass, 9.0ms\n",
      "image 92/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\glass_309_jpg.rf.4dee1d2ab7357dbbdc6a5bb126492e76.jpg: 640x640 1 Metal, 10.0ms\n",
      "image 93/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\glass_319_jpg.rf.462c5c71701be0494f73c5ffd2b78394.jpg: 640x640 1 Glass, 10.0ms\n",
      "image 94/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\glass_359_jpg.rf.a3fab5e11e3f71b668de5d3af36ffc2d.jpg: 640x640 1 Glass, 11.0ms\n",
      "image 95/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\glass_387_jpg.rf.d20db836e368a12b1f0f904caf174e1c.jpg: 640x640 1 General, 1 Glass, 9.0ms\n",
      "image 96/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\glass_391_jpg.rf.870b6066927b33981a82ae82aa6a18ce.jpg: 640x640 1 Metal, 9.0ms\n",
      "image 97/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\glass_413_jpg.rf.245aa1221a9b24b0d787771155351f17.jpg: 640x640 1 Plastic, 12.0ms\n",
      "image 98/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\glass_420_jpg.rf.d77f959060e61f232775b93a977def99.jpg: 640x640 1 Glass, 9.0ms\n",
      "image 99/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\glass_422_jpg.rf.1f50af88f2930961f98d3f82245c3b6e.jpg: 640x640 1 Glass, 10.0ms\n",
      "image 100/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\glass_425_jpg.rf.4eff5a0de5f98402a5ae4989421e09f6.jpg: 640x640 1 Glass, 9.1ms\n",
      "image 101/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\glass_436_jpg.rf.0da1727bd64ad38e7a60b5424644c552.jpg: 640x640 1 Glass, 12.0ms\n",
      "image 102/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\glass_462_jpg.rf.979b499d397cab9dfd1bd34e41533d9d.jpg: 640x640 2 Glasss, 9.0ms\n",
      "image 103/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\metal_009_jpg.rf.4beae19e4d2a5b90399318e2a1c2f7e6.jpg: 640x640 1 Metal, 9.0ms\n",
      "image 104/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\metal_014_jpg.rf.f8966c227560e2a10cd020f47d18d298.jpg: 640x640 1 Metal, 9.0ms\n",
      "image 105/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\metal_016_jpg.rf.f187bd52378e0482c301e9d57f6d755c.jpg: 640x640 1 General, 11.0ms\n",
      "image 106/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\metal_029_jpg.rf.1029f47ff6a0c4937d59aabc1c5a2488.jpg: 640x640 1 Metal, 9.0ms\n",
      "image 107/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\metal_044_jpg.rf.bdbb052679271b1f358bef3d92de2034.jpg: 640x640 1 General, 1 Vinyl, 9.0ms\n",
      "image 108/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\metal_047_jpg.rf.f9f101fae8495a9ee36d7e3299e5223f.jpg: 640x640 1 Metal, 10.0ms\n",
      "image 109/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\metal_051_jpg.rf.4fcc701b02688384d00eee9341f65723.jpg: 640x640 1 Metal, 8.7ms\n",
      "image 110/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\metal_061_jpg.rf.df309ff74e620b3e961bd6b1d73e49fd.jpg: 640x640 1 General, 9.2ms\n",
      "image 111/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\metal_063_jpg.rf.c073b9efdfb7b8e7d22203a11effe667.jpg: 640x640 1 Metal, 9.1ms\n",
      "image 112/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\metal_064_jpg.rf.ec30f697a938daacfaab2f3b35637ada.jpg: 640x640 1 Metal, 8.5ms\n",
      "image 113/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\metal_085_jpg.rf.b9e8cf1fb37b3cdce2db1e26a08775b2.jpg: 640x640 1 Metal, 9.3ms\n",
      "image 114/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\metal_104_jpg.rf.a1926e96b67de76d0821080db64ebdf4.jpg: 640x640 1 Metal, 9.5ms\n",
      "image 115/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\metal_110_jpg.rf.02b1145ff953bd9fe59228de6180ec05.jpg: 640x640 1 Metal, 9.9ms\n",
      "image 116/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\metal_115_jpg.rf.b1d858acfc850b80be8aa4287d1b6d1d.jpg: 640x640 1 Metal, 9.0ms\n",
      "image 117/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\metal_151_jpg.rf.4fc3192711c79a3eadcd792ce2ff485f.jpg: 640x640 1 Metal, 9.0ms\n",
      "image 118/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\metal_155_jpg.rf.38fcba6eccc58061b85cbedc1703704d.jpg: 640x640 1 Metal, 10.0ms\n",
      "image 119/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\metal_169_jpg.rf.77964d9a78fe163d75b0bf05b4a4e4b8.jpg: 640x640 1 General, 10.0ms\n",
      "image 120/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\metal_175_jpg.rf.01274cde0ee38f7a038d85e31ba152b6.jpg: 640x640 1 Metal, 10.0ms\n",
      "image 121/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\metal_179_jpg.rf.58f8ab9dcfd99ad91b51420b2a358259.jpg: 640x640 1 Metal, 9.0ms\n",
      "image 122/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\metal_192_jpg.rf.e3b9e445fd92f97231ca1d139771b7b0.jpg: 640x640 1 Metal, 9.0ms\n",
      "image 123/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\metal_194_jpg.rf.6328527eb6ac0f51f1cf488e5266d701.jpg: 640x640 1 Metal, 9.0ms\n",
      "image 124/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\metal_213_jpg.rf.49fda2ad3a802749a361d2c1f341ca86.jpg: 640x640 1 Metal, 9.0ms\n",
      "image 125/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\metal_223_jpg.rf.d743dca7d06ada0b9cbb68493562bbc5.jpg: 640x640 1 Metal, 9.0ms\n",
      "image 126/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\metal_232_jpg.rf.def7ce2d548060766bc387c113aabb65.jpg: 640x640 1 General, 9.0ms\n",
      "image 127/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\metal_233_jpg.rf.bfc8154e2aebfc9f17a5f392959c8ad9.jpg: 640x640 1 Metal, 9.0ms\n",
      "image 128/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\metal_239_jpg.rf.a6d9be48f6b9c250dfcc19e1be971a08.jpg: 640x640 1 Metal, 9.9ms\n",
      "image 129/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\metal_264_jpg.rf.aa74af4e259a16d2e88e141276622aa7.jpg: 640x640 1 Metal, 8.3ms\n",
      "image 130/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\metal_277_jpg.rf.c477340e1d1db4834b37d8eb2317acc1.jpg: 640x640 1 Glass, 1 Metal, 10.3ms\n",
      "image 131/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\metal_290_jpg.rf.76bcae11539e2caf0cd6ce5f1a334234.jpg: 640x640 1 General, 9.0ms\n",
      "image 132/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\metal_294_jpg.rf.6abc1678a02797f2860065fb067f3f9f.jpg: 640x640 1 Metal, 8.6ms\n",
      "image 133/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\metal_305_jpg.rf.af637d7c323f0b0be004d4372c9e9005.jpg: 640x640 1 Metal, 8.8ms\n",
      "image 134/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\metal_306_jpg.rf.c6912ba503c3e7c2c2307c1bff8a3072.jpg: 640x640 1 Metal, 9.6ms\n",
      "image 135/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\metal_311_jpg.rf.528b8966e16184a19df92bf685b56a6b.jpg: 640x640 1 Metal, 9.4ms\n",
      "image 136/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\metal_329_jpg.rf.c565b5d5e2d9265b14502443eb1b90c2.jpg: 640x640 1 Metal, 8.1ms\n",
      "image 137/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\metal_332_jpg.rf.dbcfdfeda2fdfcd2427947414f4c70b6.jpg: 640x640 1 Metal, 8.8ms\n",
      "image 138/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\metal_333_jpg.rf.3fde1952183c7a2b9f7e82cb8e257f7c.jpg: 640x640 1 Metal, 9.9ms\n",
      "image 139/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\metal_363_jpg.rf.7fd2553861e9f8d6ad3fbbc86a9cf8a2.jpg: 640x640 2 Metals, 9.3ms\n",
      "image 140/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\metal_380_jpg.rf.8b1d7cb29f2231ba0d1e231f09785eb0.jpg: 640x640 1 General, 1 Metal, 12.5ms\n",
      "image 141/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\metal_387_jpg.rf.e852dbfc9c05c389544f679794dc8d46.jpg: 640x640 1 Metal, 8.7ms\n",
      "image 142/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\metal_404_jpg.rf.76243b1cfc7ea69c4bfdc996e28ef3cc.jpg: 640x640 1 Vinyl, 9.7ms\n",
      "image 143/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\paper_009_jpg.rf.281fefea4b56210f9c60e3765f4a2c75.jpg: 640x640 1 Paper, 8.9ms\n",
      "image 144/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\paper_011_jpg.rf.c22ab51545813b6d4435d07db7dfd282.jpg: 640x640 1 Paper, 9.4ms\n",
      "image 145/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\paper_014_jpg.rf.f6597b84059c20e6e3d023a71efb6230.jpg: 640x640 1 Paper, 9.2ms\n",
      "image 146/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\paper_017_jpg.rf.94476f32a17dbdc64b08c0d37ab18fb4.jpg: 640x640 1 Paper, 9.2ms\n",
      "image 147/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\paper_024_jpg.rf.eb7a702d99885ecc39e735c722bc1aba.jpg: 640x640 1 Paper, 12.4ms\n",
      "image 148/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\paper_030_jpg.rf.91731985d7eddd3d206a4596d98fc558.jpg: 640x640 1 Paper, 9.0ms\n",
      "image 149/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\paper_039_jpg.rf.ccb5f0e95663688256c0b33176055112.jpg: 640x640 1 Paper, 8.2ms\n",
      "image 150/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\paper_042_jpg.rf.49016f4c6b516b6f027f89f0061a9781.jpg: 640x640 1 Paper, 8.8ms\n",
      "image 151/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\paper_051_jpg.rf.39fa7ec3cdce29055a8de36c4b627682.jpg: 640x640 1 Paper, 9.3ms\n",
      "image 152/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\paper_075_jpg.rf.f625e6155300de8268d5635b1c7674ff.jpg: 640x640 1 Paper, 9.5ms\n",
      "image 153/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\paper_082_jpg.rf.7f105a21f65ab58da6f51b5493ea0c38.jpg: 640x640 1 Paper, 1 Vinyl, 9.0ms\n",
      "image 154/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\paper_093_jpg.rf.ea536af0e0861ed0fec75800604ffb1f.jpg: 640x640 1 Paper, 9.8ms\n",
      "image 155/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\paper_097_jpg.rf.2d26744ee99abb9a7a1a0a3ccd434c94.jpg: 640x640 1 Paper, 8.9ms\n",
      "image 156/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\paper_111_jpg.rf.37993cfd45f32b140a94e75064834947.jpg: 640x640 1 Paper, 8.3ms\n",
      "image 157/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\paper_113_jpg.rf.2b7280bc175a4cf58e173697341b5ab2.jpg: 640x640 1 Paper, 9.2ms\n",
      "image 158/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\paper_117_jpg.rf.ffde9363e0ec263ebe245a9997796ddf.jpg: 640x640 1 Paper, 9.3ms\n",
      "image 159/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\paper_134_jpg.rf.77b15ce258ef383e7a8032b81f619014.jpg: 640x640 1 Paper, 9.8ms\n",
      "image 160/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\paper_138_jpg.rf.ec4e65699a9cab6cbce0e133a9e4ab37.jpg: 640x640 1 Paper, 9.4ms\n",
      "image 161/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\paper_139_jpg.rf.4795a0c89c41d7fa9da454e434ff9240.jpg: 640x640 1 Paper, 8.7ms\n",
      "image 162/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\paper_153_jpg.rf.9b666b90f799e852b0a197b838680187.jpg: 640x640 1 Paper, 9.9ms\n",
      "image 163/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\paper_172_jpg.rf.63b415ed65aa6d08ad3b2bf721948d4e.jpg: 640x640 1 Paper, 9.6ms\n",
      "image 164/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\paper_174_jpg.rf.7257c0675c723b2170509d5b249ce56a.jpg: 640x640 1 Paper, 9.2ms\n",
      "image 165/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\paper_201_jpg.rf.1ee62b1176c94c24f6a90bbccb1e011e.jpg: 640x640 1 Paper, 11.3ms\n",
      "image 166/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\paper_207_jpg.rf.c80f4a198ab6ca24a6ec8a9fb7b9ee5a.jpg: 640x640 1 Paper, 9.8ms\n",
      "image 167/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\paper_228_jpg.rf.33426507caa00c20942067c9ec1ed358.jpg: 640x640 1 Paper, 9.1ms\n",
      "image 168/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\paper_274_jpg.rf.51407f3ab2bf3bbf0590a5288fd16d53.jpg: 640x640 1 Paper, 8.7ms\n",
      "image 169/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\paper_280_jpg.rf.cc24082536b596e40693bed24915ea9b.jpg: 640x640 1 Paper, 9.1ms\n",
      "image 170/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\paper_284_jpg.rf.a7eaccedc8014e60986266e55cbd22a9.jpg: 640x640 1 General, 10.2ms\n",
      "image 171/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\paper_306_jpg.rf.28755e5b28b0da59aac2a0a1d96bfd53.jpg: 640x640 1 Paper, 8.1ms\n",
      "image 172/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\paper_309_jpg.rf.5851ffa57ac7331ff58a03d524ffd51e.jpg: 640x640 1 Paper, 9.2ms\n",
      "image 173/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\paper_340_jpg.rf.da01a60cd465b22f152bf16cee60e062.jpg: 640x640 1 Paper, 8.9ms\n",
      "image 174/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\paper_353_jpg.rf.3a9d34d9e20606db2626f91ed00ee992.jpg: 640x640 1 Paper, 9.5ms\n",
      "image 175/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\paper_361_jpg.rf.bea5f586f116f12e68f925435720df50.jpg: 640x640 1 Paper, 9.5ms\n",
      "image 176/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\paper_365_jpg.rf.7f3930c20ffce228084d0f9b8a5a308c.jpg: 640x640 1 Paper, 10.1ms\n",
      "image 177/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\paper_384_jpg.rf.fd1bb5b9ad89fded1a2d37ea8468256c.jpg: 640x640 1 Paper, 9.0ms\n",
      "image 178/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\paper_388_jpg.rf.8560ad30c3910de47c555ab50601ff51.jpg: 640x640 1 Paper, 8.7ms\n",
      "image 179/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\paper_394_jpg.rf.f5d8dbb0e06c61251ddbe5f10de6d162.jpg: 640x640 1 Paper, 8.6ms\n",
      "image 180/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\paper_397_jpg.rf.d2edfb78f94a85c191d5bf531a6da35a.jpg: 640x640 1 Paper, 10.0ms\n",
      "image 181/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\paper_401_jpg.rf.fae4647b6d675084ca2e128f0eebb5b7.jpg: 640x640 1 Paper, 9.1ms\n",
      "image 182/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\paper_403_jpg.rf.4c42303d4645967c836c34b5a17a989a.jpg: 640x640 1 Paper, 8.5ms\n",
      "image 183/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\paper_414_jpg.rf.f076c42fc6a6bd5724d1ef297ed69a04.jpg: 640x640 1 Paper, 8.4ms\n",
      "image 184/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\plastic_014_jpg.rf.80fc91c15f79db0f0d2398fab1f6c5e5.jpg: 640x640 1 Plastic, 1 Vinyl, 11.4ms\n",
      "image 185/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\plastic_028_jpg.rf.c923d84522ba7dd8a96174c323391efd.jpg: 640x640 1 Plastic, 8.8ms\n",
      "image 186/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\plastic_031_jpg.rf.6583a966c0860a85f637392a88bf4229.jpg: 640x640 1 General, 1 Plastic, 9.2ms\n",
      "image 187/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\plastic_093_jpg.rf.1f3188f5259ff78202585d251c0cb3e0.jpg: 640x640 1 Plastic, 8.6ms\n",
      "image 188/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\plastic_095_jpg.rf.36e5dabcb86b3823ea80c81ddcb3992f.jpg: 640x640 1 Plastic, 1 Vinyl, 9.3ms\n",
      "image 189/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\plastic_099_jpg.rf.ee23989577a61e106df348ed8fbede82.jpg: 640x640 1 Plastic, 8.5ms\n",
      "image 190/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\plastic_103_jpg.rf.9be7edba9d3df3f60d452c4d40aa9318.jpg: 640x640 1 General, 1 Plastic, 9.0ms\n",
      "image 191/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\plastic_106_jpg.rf.3944be8836018cac2eb9cd6fc167a6f7.jpg: 640x640 1 Plastic, 1 Vinyl, 10.5ms\n",
      "image 192/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\plastic_119_jpg.rf.9f6a9e92cb8fc17ee41f62d27e84a9dd.jpg: 640x640 1 Plastic, 9.4ms\n",
      "image 193/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\plastic_126_jpg.rf.d2514f33b446514399983ec2c5e5ee2c.jpg: 640x640 1 Plastic, 8.3ms\n",
      "image 194/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\plastic_143_jpg.rf.3a8fccedc963938be267da84ab5aab41.jpg: 640x640 1 General, 1 Plastic, 9.6ms\n",
      "image 195/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\plastic_144_jpg.rf.4f6db99e7377d5a87380008f263cfa55.jpg: 640x640 1 Plastic, 1 Vinyl, 8.6ms\n",
      "image 196/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\plastic_153_jpg.rf.c9d46ef7ba1885a837f934010f31400e.jpg: 640x640 1 Plastic, 1 Vinyl, 8.3ms\n",
      "image 197/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\plastic_156_jpg.rf.e87db417dcf0f4cc00511ea3d5bcd611.jpg: 640x640 1 General, 1 Plastic, 8.0ms\n",
      "image 198/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\plastic_163_jpg.rf.1d365631758f9d80d576a6f783a6bbd5.jpg: 640x640 1 Plastic, 9.4ms\n",
      "image 199/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\plastic_165_jpg.rf.8c33742afb88049ac8f5d37645efd531.jpg: 640x640 1 Plastic, 8.2ms\n",
      "image 200/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\plastic_170_jpg.rf.ee10c3a6d21a0c03377205b8e1728a96.jpg: 640x640 1 Plastic, 1 Vinyl, 9.1ms\n",
      "image 201/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\plastic_182_jpg.rf.c567a3cb0fcfd1748e05518aadda95b9.jpg: 640x640 1 Plastic, 1 Vinyl, 8.7ms\n",
      "image 202/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\plastic_198_jpg.rf.360fa52e7a9caab44d9da0dc76adf676.jpg: 640x640 1 Plastic, 1 Vinyl, 9.0ms\n",
      "image 203/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\plastic_211_jpg.rf.7667337535817cdb834564bc4029c875.jpg: 640x640 1 Plastic, 8.9ms\n",
      "image 204/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\plastic_230_jpg.rf.183902946c19c457fafcdffe07deaab8.jpg: 640x640 1 Plastic, 8.4ms\n",
      "image 205/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\plastic_242_jpg.rf.b35257f1493e966b30a92fab6aea6e06.jpg: 640x640 1 General, 1 Plastic, 9.5ms\n",
      "image 206/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\plastic_247_jpg.rf.c472ada75516c6db11bb89d6443e17cb.jpg: 640x640 1 General, 1 Plastic, 9.2ms\n",
      "image 207/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\plastic_274_jpg.rf.e52c53ff81049f7a553d6f12d3494210.jpg: 640x640 1 Plastic, 9.4ms\n",
      "image 208/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\plastic_275_jpg.rf.e6ecb4b83e3e90babaaaca572a5b19f9.jpg: 640x640 1 Plastic, 2 Vinyls, 9.4ms\n",
      "image 209/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\plastic_300_jpg.rf.38ffc4c2c6b84ca827497c10aef4a285.jpg: 640x640 1 Plastic, 8.7ms\n",
      "image 210/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\plastic_301_jpg.rf.ddd56e569b79ef49c927bc38c8207b46.jpg: 640x640 1 Plastic, 3 Vinyls, 8.2ms\n",
      "image 211/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\plastic_308_jpg.rf.8d7874b7d77e7297d4655ac197a99535.jpg: 640x640 1 Plastic, 8.1ms\n",
      "image 212/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\plastic_476_jpg.rf.cca498a29cf0be07136ee256daa3fcdb.jpg: 640x640 1 Plastic, 9.1ms\n",
      "image 213/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\trash_015_jpg.rf.7a8c4bf2f01df151542fac313f27e5c5.jpg: 640x640 1 Vinyl, 9.0ms\n",
      "image 214/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\trash_021_jpg.rf.a2fb91a96cb976a30b7bbc51128dbe33.jpg: 640x640 1 Vinyl, 9.1ms\n",
      "image 215/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\trash_023_jpg.rf.6b695c298278b5cf07e5e8ef805cb311.jpg: 640x640 1 General, 8.4ms\n",
      "image 216/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\trash_033_jpg.rf.0462f7e7656954bda632340d8f1497be.jpg: 640x640 3 Generals, 9.6ms\n",
      "image 217/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\trash_035_jpg.rf.a366cd1ca7e2c9771d634bde106c9184.jpg: 640x640 1 Vinyl, 8.5ms\n",
      "image 218/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\trash_068_jpg.rf.fdedad4f575d1323319eb453f8f279d6.jpg: 640x640 1 General, 9.1ms\n",
      "image 219/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\trash_082_jpg.rf.dca17589e7c16ba3e9ccae2f5897bc2f.jpg: 640x640 1 Vinyl, 9.1ms\n",
      "image 220/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\trash_093_jpg.rf.123be87bd5ee77de628c8f376df9f143.jpg: 640x640 1 Styrofoam, 9.0ms\n",
      "image 221/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\trash_102_jpg.rf.3ad8c75de2b2d81ec6d84c38a95771e6.jpg: 640x640 1 Vinyl, 8.0ms\n",
      "image 222/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\trash_105_jpg.rf.26375830e16a4028a5afa797ad35e760.jpg: 640x640 1 Vinyl, 8.7ms\n",
      "image 223/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\trash_110_jpg.rf.cfc8cf662bc4de7689c78d235bd1126c.jpg: 640x640 1 Vinyl, 9.5ms\n",
      "image 224/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\trash_131_jpg.rf.db07bd141de015234817724e77e638d5.jpg: 640x640 1 General, 8.6ms\n",
      "image 225/225 c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test\\images\\trash_137_jpg.rf.316dc6bcc0766fbc170a03f92ea767eb.jpg: 640x640 1 Paper, 8.0ms\n",
      "Speed: 3.6ms preprocess, 10.0ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\train2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results = model.predict(source='test/images/', save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir = 'runs/detect/train2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestModelpath = 'runs/detect/train/weights/best.pt'\n",
    "bestModel = YOLO(bestModelpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.image as mpimg\n",
    "\n",
    "def show_random_images(folder_path, num_images=9):\n",
    "    # Get the list of image files in the folder\n",
    "    image_files = [f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    \n",
    "    # If the number of images in the folder is less than requested, adjust num_images\n",
    "    num_images = min(num_images, len(image_files))\n",
    "    \n",
    "    # Randomly select num_images images\n",
    "    selected_images = random.sample(image_files, num_images)\n",
    "    \n",
    "    # Plot the selected images\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n",
    "    for i, image_file in enumerate(selected_images):\n",
    "        row = i // 3\n",
    "        col = i % 3\n",
    "        image_path = os.path.join(folder_path, image_file)\n",
    "        image = mpimg.imread(image_path)\n",
    "        axes[row, col].imshow(image)\n",
    "        axes[row, col].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage:\n",
    "folder_path = 'train\\images'\n",
    "show_random_images(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestModelpath = 'runs/detect/train/weights/best.pt'\n",
    "bestModel = YOLO(bestModelpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "WARNING ‚ö†Ô∏è inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "video 1/1 (frame 1/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Plastic, 36.9ms\n",
      "video 1/1 (frame 2/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Plastic, 30.4ms\n",
      "video 1/1 (frame 3/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Plastic, 23.9ms\n",
      "video 1/1 (frame 4/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Plastic, 23.4ms\n",
      "video 1/1 (frame 5/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Plastic, 26.9ms\n",
      "video 1/1 (frame 6/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Plastic, 5.0ms\n",
      "video 1/1 (frame 7/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 (no detections), 4.0ms\n",
      "video 1/1 (frame 8/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Plastic, 6.0ms\n",
      "video 1/1 (frame 9/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Paper, 1 Plastic, 5.0ms\n",
      "video 1/1 (frame 10/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Paper, 8.0ms\n",
      "video 1/1 (frame 11/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 (no detections), 4.0ms\n",
      "video 1/1 (frame 12/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 (no detections), 4.0ms\n",
      "video 1/1 (frame 13/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 (no detections), 4.0ms\n",
      "video 1/1 (frame 14/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Paper, 4.0ms\n",
      "video 1/1 (frame 15/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 (no detections), 8.0ms\n",
      "video 1/1 (frame 16/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Paper, 6.0ms\n",
      "video 1/1 (frame 17/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Paper, 5.0ms\n",
      "video 1/1 (frame 18/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 2 Papers, 6.0ms\n",
      "video 1/1 (frame 19/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Paper, 9.0ms\n",
      "video 1/1 (frame 20/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Paper, 4.0ms\n",
      "video 1/1 (frame 21/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Paper, 5.0ms\n",
      "video 1/1 (frame 22/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Paper, 4.3ms\n",
      "video 1/1 (frame 23/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 (no detections), 4.0ms\n",
      "video 1/1 (frame 24/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 (no detections), 8.0ms\n",
      "video 1/1 (frame 25/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 (no detections), 8.0ms\n",
      "video 1/1 (frame 26/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 (no detections), 5.3ms\n",
      "video 1/1 (frame 27/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 (no detections), 7.0ms\n",
      "video 1/1 (frame 28/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Paper, 5.0ms\n",
      "video 1/1 (frame 29/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Paper, 8.0ms\n",
      "video 1/1 (frame 30/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 (no detections), 5.0ms\n",
      "video 1/1 (frame 31/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 (no detections), 5.0ms\n",
      "video 1/1 (frame 32/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 (no detections), 5.0ms\n",
      "video 1/1 (frame 33/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 (no detections), 4.0ms\n",
      "video 1/1 (frame 34/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 (no detections), 5.0ms\n",
      "video 1/1 (frame 35/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Styrofoam, 4.0ms\n",
      "video 1/1 (frame 36/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 (no detections), 7.0ms\n",
      "video 1/1 (frame 37/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 (no detections), 5.3ms\n",
      "video 1/1 (frame 38/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 (no detections), 3.8ms\n",
      "video 1/1 (frame 39/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 (no detections), 4.0ms\n",
      "video 1/1 (frame 40/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 (no detections), 7.0ms\n",
      "video 1/1 (frame 41/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 (no detections), 5.0ms\n",
      "video 1/1 (frame 42/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 (no detections), 5.0ms\n",
      "video 1/1 (frame 43/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Plastic, 5.0ms\n",
      "video 1/1 (frame 44/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Styrofoam, 5.0ms\n",
      "video 1/1 (frame 45/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Styrofoam, 1 Vinyl, 5.5ms\n",
      "video 1/1 (frame 46/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Styrofoam, 1 Vinyl, 5.2ms\n",
      "video 1/1 (frame 47/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Styrofoam, 1 Vinyl, 5.1ms\n",
      "video 1/1 (frame 48/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Styrofoam, 1 Vinyl, 10.0ms\n",
      "video 1/1 (frame 49/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Styrofoam, 1 Vinyl, 4.0ms\n",
      "video 1/1 (frame 50/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Vinyl, 7.0ms\n",
      "video 1/1 (frame 51/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Styrofoam, 5.0ms\n",
      "video 1/1 (frame 52/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 (no detections), 4.0ms\n",
      "video 1/1 (frame 53/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 (no detections), 5.0ms\n",
      "video 1/1 (frame 54/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 (no detections), 5.0ms\n",
      "video 1/1 (frame 55/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 (no detections), 6.0ms\n",
      "video 1/1 (frame 56/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 (no detections), 4.0ms\n",
      "video 1/1 (frame 57/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Paper, 4.0ms\n",
      "video 1/1 (frame 58/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 (no detections), 4.0ms\n",
      "video 1/1 (frame 59/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 (no detections), 4.0ms\n",
      "video 1/1 (frame 60/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 (no detections), 4.0ms\n",
      "video 1/1 (frame 61/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Paper, 7.9ms\n",
      "video 1/1 (frame 62/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Styrofoam, 7.0ms\n",
      "video 1/1 (frame 63/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Styrofoam, 8.0ms\n",
      "video 1/1 (frame 64/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Styrofoam, 4.0ms\n",
      "video 1/1 (frame 65/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Styrofoam, 1 Vinyl, 4.0ms\n",
      "video 1/1 (frame 66/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Vinyl, 5.0ms\n",
      "video 1/1 (frame 67/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 (no detections), 4.0ms\n",
      "video 1/1 (frame 68/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Styrofoam, 7.4ms\n",
      "video 1/1 (frame 69/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 (no detections), 5.0ms\n",
      "video 1/1 (frame 70/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Styrofoam, 4.0ms\n",
      "video 1/1 (frame 71/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Plastic, 2 Styrofoams, 1 Vinyl, 4.0ms\n",
      "video 1/1 (frame 72/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Styrofoam, 7.0ms\n",
      "video 1/1 (frame 73/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Styrofoam, 4.0ms\n",
      "video 1/1 (frame 74/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Plastic, 1 Styrofoam, 1 Vinyl, 4.8ms\n",
      "video 1/1 (frame 75/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Styrofoam, 1 Vinyl, 6.0ms\n",
      "video 1/1 (frame 76/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Styrofoam, 1 Vinyl, 6.0ms\n",
      "video 1/1 (frame 77/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Styrofoam, 1 Vinyl, 4.0ms\n",
      "video 1/1 (frame 78/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Vinyl, 6.0ms\n",
      "video 1/1 (frame 79/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Vinyl, 5.0ms\n",
      "video 1/1 (frame 80/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Vinyl, 4.0ms\n",
      "video 1/1 (frame 81/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Vinyl, 7.0ms\n",
      "video 1/1 (frame 82/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Vinyl, 4.0ms\n",
      "video 1/1 (frame 83/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Vinyl, 4.0ms\n",
      "video 1/1 (frame 84/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Vinyl, 5.0ms\n",
      "video 1/1 (frame 85/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Vinyl, 4.0ms\n",
      "video 1/1 (frame 86/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Vinyl, 4.0ms\n",
      "video 1/1 (frame 87/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Vinyl, 5.0ms\n",
      "video 1/1 (frame 88/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Vinyl, 5.0ms\n",
      "video 1/1 (frame 89/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Vinyl, 7.0ms\n",
      "video 1/1 (frame 90/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Vinyl, 7.0ms\n",
      "video 1/1 (frame 91/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Vinyl, 6.0ms\n",
      "video 1/1 (frame 92/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Vinyl, 8.0ms\n",
      "video 1/1 (frame 93/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Vinyl, 4.0ms\n",
      "video 1/1 (frame 94/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Vinyl, 5.0ms\n",
      "video 1/1 (frame 95/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Styrofoam, 1 Vinyl, 4.0ms\n",
      "video 1/1 (frame 96/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Vinyl, 6.0ms\n",
      "video 1/1 (frame 97/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Styrofoam, 1 Vinyl, 5.0ms\n",
      "video 1/1 (frame 98/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Styrofoam, 1 Vinyl, 4.0ms\n",
      "video 1/1 (frame 99/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Vinyl, 6.0ms\n",
      "video 1/1 (frame 100/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Vinyl, 4.0ms\n",
      "video 1/1 (frame 101/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Styrofoam, 1 Vinyl, 5.0ms\n",
      "video 1/1 (frame 102/102) c:\\Users\\HoJin\\Desktop\\python\\ML_project\\zreo_py\\DL_Project\\Trash-classification\\ecosort\\test2.mp4: 384x640 1 Vinyl, 5.0ms\n",
      "Speed: 1.2ms preprocess, 6.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict4\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[126, 131, 137],\n",
       "         [126, 131, 137],\n",
       "         [126, 131, 137],\n",
       "         ...,\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181]],\n",
       " \n",
       "        [[126, 131, 137],\n",
       "         [126, 131, 137],\n",
       "         [126, 131, 137],\n",
       "         ...,\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181]],\n",
       " \n",
       "        [[128, 133, 139],\n",
       "         [128, 133, 139],\n",
       "         [128, 133, 139],\n",
       "         ...,\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 42,  43,  48],\n",
       "         [ 42,  43,  48],\n",
       "         [ 42,  43,  48],\n",
       "         ...,\n",
       "         [155, 163, 167],\n",
       "         [156, 164, 168],\n",
       "         [156, 164, 168]],\n",
       " \n",
       "        [[ 42,  43,  48],\n",
       "         [ 42,  43,  48],\n",
       "         [ 42,  43,  48],\n",
       "         ...,\n",
       "         [155, 163, 167],\n",
       "         [156, 164, 168],\n",
       "         [156, 164, 168]],\n",
       " \n",
       "        [[ 42,  43,  48],\n",
       "         [ 42,  43,  48],\n",
       "         [ 42,  43,  48],\n",
       "         ...,\n",
       "         [155, 163, 167],\n",
       "         [156, 164, 168],\n",
       "         [156, 164, 168]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 2.989530563354492, 'inference': 36.87644004821777, 'postprocess': 0.9975433349609375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[126, 131, 137],\n",
       "         [126, 131, 137],\n",
       "         [126, 131, 137],\n",
       "         ...,\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181]],\n",
       " \n",
       "        [[126, 131, 137],\n",
       "         [126, 131, 137],\n",
       "         [126, 131, 137],\n",
       "         ...,\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181]],\n",
       " \n",
       "        [[128, 133, 139],\n",
       "         [128, 133, 139],\n",
       "         [128, 133, 139],\n",
       "         ...,\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 42,  43,  48],\n",
       "         [ 42,  43,  48],\n",
       "         [ 42,  43,  48],\n",
       "         ...,\n",
       "         [155, 163, 167],\n",
       "         [156, 164, 168],\n",
       "         [156, 164, 168]],\n",
       " \n",
       "        [[ 42,  43,  48],\n",
       "         [ 42,  43,  48],\n",
       "         [ 42,  43,  48],\n",
       "         ...,\n",
       "         [155, 163, 167],\n",
       "         [156, 164, 168],\n",
       "         [156, 164, 168]],\n",
       " \n",
       "        [[ 42,  43,  48],\n",
       "         [ 42,  43,  48],\n",
       "         [ 42,  43,  48],\n",
       "         ...,\n",
       "         [155, 163, 167],\n",
       "         [156, 164, 168],\n",
       "         [156, 164, 168]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 2.9900074005126953, 'inference': 30.403852462768555, 'postprocess': 4.984855651855469},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[126, 131, 137],\n",
       "         [126, 131, 137],\n",
       "         [126, 131, 137],\n",
       "         ...,\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181]],\n",
       " \n",
       "        [[126, 131, 137],\n",
       "         [126, 131, 137],\n",
       "         [126, 131, 137],\n",
       "         ...,\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181]],\n",
       " \n",
       "        [[128, 133, 139],\n",
       "         [128, 133, 139],\n",
       "         [128, 133, 139],\n",
       "         ...,\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 42,  43,  48],\n",
       "         [ 42,  43,  48],\n",
       "         [ 42,  43,  48],\n",
       "         ...,\n",
       "         [155, 163, 167],\n",
       "         [155, 163, 167],\n",
       "         [156, 164, 168]],\n",
       " \n",
       "        [[ 42,  43,  48],\n",
       "         [ 42,  43,  48],\n",
       "         [ 42,  43,  48],\n",
       "         ...,\n",
       "         [155, 163, 167],\n",
       "         [155, 163, 167],\n",
       "         [156, 164, 168]],\n",
       " \n",
       "        [[ 42,  43,  48],\n",
       "         [ 42,  43,  48],\n",
       "         [ 42,  43,  48],\n",
       "         ...,\n",
       "         [155, 163, 167],\n",
       "         [155, 163, 167],\n",
       "         [156, 164, 168]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 2.9315948486328125, 'inference': 23.921728134155273, 'postprocess': 3.9827823638916016},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[126, 131, 137],\n",
       "         [126, 131, 137],\n",
       "         [126, 131, 137],\n",
       "         ...,\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181]],\n",
       " \n",
       "        [[126, 131, 137],\n",
       "         [126, 131, 137],\n",
       "         [126, 131, 137],\n",
       "         ...,\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181]],\n",
       " \n",
       "        [[128, 133, 139],\n",
       "         [128, 133, 139],\n",
       "         [128, 133, 139],\n",
       "         ...,\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 41,  42,  47],\n",
       "         [ 41,  42,  47],\n",
       "         [ 41,  42,  47],\n",
       "         ...,\n",
       "         [155, 163, 167],\n",
       "         [155, 163, 167],\n",
       "         [155, 163, 167]],\n",
       " \n",
       "        [[ 41,  42,  47],\n",
       "         [ 41,  42,  47],\n",
       "         [ 41,  42,  47],\n",
       "         ...,\n",
       "         [155, 163, 167],\n",
       "         [155, 163, 167],\n",
       "         [155, 163, 167]],\n",
       " \n",
       "        [[ 41,  42,  47],\n",
       "         [ 41,  42,  47],\n",
       "         [ 42,  43,  48],\n",
       "         ...,\n",
       "         [155, 163, 167],\n",
       "         [155, 163, 167],\n",
       "         [155, 163, 167]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 2.9876232147216797, 'inference': 23.436546325683594, 'postprocess': 4.045724868774414},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[126, 131, 137],\n",
       "         [126, 131, 137],\n",
       "         [126, 131, 137],\n",
       "         ...,\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181]],\n",
       " \n",
       "        [[126, 131, 137],\n",
       "         [126, 131, 137],\n",
       "         [126, 131, 137],\n",
       "         ...,\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181]],\n",
       " \n",
       "        [[128, 133, 139],\n",
       "         [128, 133, 139],\n",
       "         [128, 133, 139],\n",
       "         ...,\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 42,  43,  48],\n",
       "         [ 42,  43,  48],\n",
       "         [ 42,  43,  48],\n",
       "         ...,\n",
       "         [154, 162, 166],\n",
       "         [155, 163, 167],\n",
       "         [155, 163, 167]],\n",
       " \n",
       "        [[ 42,  43,  48],\n",
       "         [ 42,  43,  48],\n",
       "         [ 42,  43,  48],\n",
       "         ...,\n",
       "         [154, 162, 166],\n",
       "         [155, 163, 167],\n",
       "         [155, 163, 167]],\n",
       " \n",
       "        [[ 42,  43,  48],\n",
       "         [ 42,  43,  48],\n",
       "         [ 42,  43,  48],\n",
       "         ...,\n",
       "         [154, 162, 166],\n",
       "         [155, 163, 167],\n",
       "         [155, 163, 167]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 1.9903182983398438, 'inference': 26.91197395324707, 'postprocess': 4.987478256225586},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[126, 131, 137],\n",
       "         [126, 131, 137],\n",
       "         [126, 131, 137],\n",
       "         ...,\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181]],\n",
       " \n",
       "        [[126, 131, 137],\n",
       "         [126, 131, 137],\n",
       "         [126, 131, 137],\n",
       "         ...,\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181]],\n",
       " \n",
       "        [[128, 133, 139],\n",
       "         [128, 133, 139],\n",
       "         [128, 133, 139],\n",
       "         ...,\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 47,  45,  50],\n",
       "         [ 47,  45,  50],\n",
       "         [ 47,  45,  50],\n",
       "         ...,\n",
       "         [151, 159, 163],\n",
       "         [154, 162, 166],\n",
       "         [155, 163, 167]],\n",
       " \n",
       "        [[ 43,  44,  49],\n",
       "         [ 43,  44,  49],\n",
       "         [ 43,  44,  49],\n",
       "         ...,\n",
       "         [151, 159, 163],\n",
       "         [154, 162, 166],\n",
       "         [155, 163, 167]],\n",
       " \n",
       "        [[ 43,  44,  49],\n",
       "         [ 43,  44,  49],\n",
       "         [ 43,  44,  49],\n",
       "         ...,\n",
       "         [151, 159, 163],\n",
       "         [154, 162, 166],\n",
       "         [155, 163, 167]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 1.9927024841308594, 'inference': 4.9839019775390625, 'postprocess': 0.9965896606445312},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[126, 131, 137],\n",
       "         [126, 131, 137],\n",
       "         [126, 131, 137],\n",
       "         ...,\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181]],\n",
       " \n",
       "        [[126, 131, 137],\n",
       "         [126, 131, 137],\n",
       "         [126, 131, 137],\n",
       "         ...,\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181]],\n",
       " \n",
       "        [[128, 133, 139],\n",
       "         [128, 133, 139],\n",
       "         [128, 133, 139],\n",
       "         ...,\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 54,  49,  55],\n",
       "         [ 54,  49,  55],\n",
       "         [ 54,  49,  55],\n",
       "         ...,\n",
       "         [149, 157, 161],\n",
       "         [151, 159, 163],\n",
       "         [154, 162, 166]],\n",
       " \n",
       "        [[ 53,  48,  54],\n",
       "         [ 53,  48,  54],\n",
       "         [ 53,  48,  54],\n",
       "         ...,\n",
       "         [149, 157, 161],\n",
       "         [151, 159, 163],\n",
       "         [154, 162, 166]],\n",
       " \n",
       "        [[ 52,  47,  53],\n",
       "         [ 52,  47,  53],\n",
       "         [ 52,  47,  53],\n",
       "         ...,\n",
       "         [149, 157, 161],\n",
       "         [151, 159, 163],\n",
       "         [154, 162, 166]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 1.9931793212890625, 'inference': 3.9861202239990234, 'postprocess': 0.9970664978027344},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[126, 131, 137],\n",
       "         [126, 131, 137],\n",
       "         [126, 131, 137],\n",
       "         ...,\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181]],\n",
       " \n",
       "        [[126, 131, 137],\n",
       "         [126, 131, 137],\n",
       "         [126, 131, 137],\n",
       "         ...,\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181]],\n",
       " \n",
       "        [[128, 133, 139],\n",
       "         [128, 133, 139],\n",
       "         [128, 133, 139],\n",
       "         ...,\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 56,  51,  57],\n",
       "         [ 56,  51,  57],\n",
       "         [ 56,  51,  57],\n",
       "         ...,\n",
       "         [147, 155, 159],\n",
       "         [150, 158, 162],\n",
       "         [152, 160, 164]],\n",
       " \n",
       "        [[ 57,  52,  58],\n",
       "         [ 57,  52,  58],\n",
       "         [ 57,  52,  58],\n",
       "         ...,\n",
       "         [148, 156, 160],\n",
       "         [150, 158, 162],\n",
       "         [152, 160, 164]],\n",
       " \n",
       "        [[ 57,  52,  58],\n",
       "         [ 57,  52,  58],\n",
       "         [ 57,  52,  58],\n",
       "         ...,\n",
       "         [148, 156, 160],\n",
       "         [150, 158, 162],\n",
       "         [152, 160, 164]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 1.9927024841308594, 'inference': 5.978584289550781, 'postprocess': 0.9961128234863281},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[126, 131, 137],\n",
       "         [126, 131, 137],\n",
       "         [126, 131, 137],\n",
       "         ...,\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181]],\n",
       " \n",
       "        [[126, 131, 137],\n",
       "         [126, 131, 137],\n",
       "         [126, 131, 137],\n",
       "         ...,\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181]],\n",
       " \n",
       "        [[128, 133, 139],\n",
       "         [128, 133, 139],\n",
       "         [128, 133, 139],\n",
       "         ...,\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181],\n",
       "         [173, 180, 181]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 58,  56,  61],\n",
       "         [ 58,  56,  61],\n",
       "         [ 58,  56,  61],\n",
       "         ...,\n",
       "         [140, 148, 152],\n",
       "         [143, 151, 155],\n",
       "         [148, 156, 160]],\n",
       " \n",
       "        [[ 59,  54,  60],\n",
       "         [ 59,  54,  60],\n",
       "         [ 59,  54,  60],\n",
       "         ...,\n",
       "         [144, 152, 156],\n",
       "         [147, 155, 159],\n",
       "         [149, 157, 161]],\n",
       " \n",
       "        [[ 59,  54,  60],\n",
       "         [ 59,  54,  60],\n",
       "         [ 59,  54,  60],\n",
       "         ...,\n",
       "         [145, 153, 157],\n",
       "         [147, 155, 159],\n",
       "         [149, 157, 161]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9951591491699219, 'inference': 4.982709884643555, 'postprocess': 0.9973049163818359},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[126, 131, 137],\n",
       "         [126, 131, 137],\n",
       "         [126, 131, 137],\n",
       "         ...,\n",
       "         [172, 179, 180],\n",
       "         [172, 179, 180],\n",
       "         [172, 179, 180]],\n",
       " \n",
       "        [[126, 131, 137],\n",
       "         [126, 131, 137],\n",
       "         [126, 131, 137],\n",
       "         ...,\n",
       "         [172, 179, 180],\n",
       "         [172, 179, 180],\n",
       "         [172, 179, 180]],\n",
       " \n",
       "        [[128, 133, 139],\n",
       "         [128, 133, 139],\n",
       "         [128, 133, 139],\n",
       "         ...,\n",
       "         [172, 179, 180],\n",
       "         [172, 179, 180],\n",
       "         [172, 179, 180]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 59,  57,  62],\n",
       "         [ 59,  57,  62],\n",
       "         [ 59,  57,  62],\n",
       "         ...,\n",
       "         [129, 137, 141],\n",
       "         [137, 145, 149],\n",
       "         [141, 149, 153]],\n",
       " \n",
       "        [[ 59,  57,  62],\n",
       "         [ 59,  57,  62],\n",
       "         [ 59,  57,  62],\n",
       "         ...,\n",
       "         [131, 139, 143],\n",
       "         [142, 150, 154],\n",
       "         [145, 153, 157]],\n",
       " \n",
       "        [[ 59,  57,  62],\n",
       "         [ 59,  57,  62],\n",
       "         [ 59,  57,  62],\n",
       "         ...,\n",
       "         [133, 141, 145],\n",
       "         [143, 151, 155],\n",
       "         [147, 155, 159]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9963512420654297, 'inference': 7.973670959472656, 'postprocess': 1.9922256469726562},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[126, 131, 137],\n",
       "         [126, 131, 137],\n",
       "         [126, 131, 137],\n",
       "         ...,\n",
       "         [172, 179, 180],\n",
       "         [172, 179, 180],\n",
       "         [172, 179, 180]],\n",
       " \n",
       "        [[126, 131, 137],\n",
       "         [126, 131, 137],\n",
       "         [126, 131, 137],\n",
       "         ...,\n",
       "         [172, 179, 180],\n",
       "         [172, 179, 180],\n",
       "         [172, 179, 180]],\n",
       " \n",
       "        [[128, 133, 139],\n",
       "         [128, 133, 139],\n",
       "         [128, 133, 139],\n",
       "         ...,\n",
       "         [172, 179, 180],\n",
       "         [172, 179, 180],\n",
       "         [172, 179, 180]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 67,  62,  68],\n",
       "         [ 67,  62,  68],\n",
       "         [ 67,  62,  68],\n",
       "         ...,\n",
       "         [113, 121, 125],\n",
       "         [126, 134, 138],\n",
       "         [136, 144, 148]],\n",
       " \n",
       "        [[ 62,  60,  65],\n",
       "         [ 62,  60,  65],\n",
       "         [ 62,  60,  65],\n",
       "         ...,\n",
       "         [115, 123, 127],\n",
       "         [128, 136, 140],\n",
       "         [140, 148, 152]],\n",
       " \n",
       "        [[ 62,  60,  65],\n",
       "         [ 62,  60,  65],\n",
       "         [ 62,  60,  65],\n",
       "         ...,\n",
       "         [116, 124, 128],\n",
       "         [129, 137, 141],\n",
       "         [141, 149, 153]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9961128234863281, 'inference': 3.9861202239990234, 'postprocess': 0.9965896606445312},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[128, 130, 137],\n",
       "         [128, 130, 137],\n",
       "         [128, 130, 137],\n",
       "         ...,\n",
       "         [172, 179, 180],\n",
       "         [172, 179, 180],\n",
       "         [172, 179, 180]],\n",
       " \n",
       "        [[128, 130, 137],\n",
       "         [128, 130, 137],\n",
       "         [128, 130, 137],\n",
       "         ...,\n",
       "         [172, 179, 180],\n",
       "         [172, 179, 180],\n",
       "         [172, 179, 180]],\n",
       " \n",
       "        [[128, 130, 137],\n",
       "         [128, 130, 137],\n",
       "         [128, 130, 137],\n",
       "         ...,\n",
       "         [172, 179, 180],\n",
       "         [172, 179, 180],\n",
       "         [172, 179, 180]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 72,  65,  71],\n",
       "         [ 72,  65,  71],\n",
       "         [ 72,  65,  71],\n",
       "         ...,\n",
       "         [ 93, 101, 105],\n",
       "         [106, 114, 118],\n",
       "         [120, 128, 132]],\n",
       " \n",
       "        [[ 72,  65,  71],\n",
       "         [ 72,  65,  71],\n",
       "         [ 72,  65,  71],\n",
       "         ...,\n",
       "         [ 93, 101, 105],\n",
       "         [106, 114, 118],\n",
       "         [120, 128, 132]],\n",
       " \n",
       "        [[ 72,  65,  71],\n",
       "         [ 72,  65,  71],\n",
       "         [ 72,  65,  71],\n",
       "         ...,\n",
       "         [ 93, 101, 105],\n",
       "         [106, 114, 118],\n",
       "         [120, 128, 132]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9963512420654297, 'inference': 3.9877891540527344, 'postprocess': 0.9970664978027344},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[128, 130, 137],\n",
       "         [128, 130, 137],\n",
       "         [128, 130, 137],\n",
       "         ...,\n",
       "         [171, 178, 179],\n",
       "         [171, 178, 179],\n",
       "         [171, 178, 179]],\n",
       " \n",
       "        [[128, 130, 137],\n",
       "         [128, 130, 137],\n",
       "         [128, 130, 137],\n",
       "         ...,\n",
       "         [171, 178, 179],\n",
       "         [171, 178, 179],\n",
       "         [171, 178, 179]],\n",
       " \n",
       "        [[128, 130, 137],\n",
       "         [128, 130, 137],\n",
       "         [128, 130, 137],\n",
       "         ...,\n",
       "         [171, 178, 179],\n",
       "         [171, 178, 179],\n",
       "         [171, 178, 179]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 79,  72,  78],\n",
       "         [ 79,  72,  78],\n",
       "         [ 77,  70,  76],\n",
       "         ...,\n",
       "         [ 91,  99, 103],\n",
       "         [ 92, 100, 104],\n",
       "         [102, 110, 114]],\n",
       " \n",
       "        [[ 79,  72,  78],\n",
       "         [ 79,  72,  78],\n",
       "         [ 77,  70,  76],\n",
       "         ...,\n",
       "         [ 91,  99, 103],\n",
       "         [ 92, 100, 104],\n",
       "         [102, 110, 114]],\n",
       " \n",
       "        [[ 79,  72,  78],\n",
       "         [ 79,  72,  78],\n",
       "         [ 77,  70,  76],\n",
       "         ...,\n",
       "         [ 91,  99, 103],\n",
       "         [ 92, 100, 104],\n",
       "         [102, 110, 114]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9961128234863281, 'inference': 3.985881805419922, 'postprocess': 0.9968280792236328},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[128, 130, 137],\n",
       "         [128, 130, 137],\n",
       "         [128, 130, 137],\n",
       "         ...,\n",
       "         [168, 175, 176],\n",
       "         [168, 175, 176],\n",
       "         [168, 175, 176]],\n",
       " \n",
       "        [[128, 130, 137],\n",
       "         [128, 130, 137],\n",
       "         [128, 130, 137],\n",
       "         ...,\n",
       "         [168, 175, 176],\n",
       "         [168, 175, 176],\n",
       "         [168, 175, 176]],\n",
       " \n",
       "        [[128, 130, 137],\n",
       "         [128, 130, 137],\n",
       "         [128, 130, 137],\n",
       "         ...,\n",
       "         [168, 175, 176],\n",
       "         [168, 175, 176],\n",
       "         [168, 175, 176]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 83,  76,  82],\n",
       "         [ 83,  76,  82],\n",
       "         [ 83,  76,  82],\n",
       "         ...,\n",
       "         [ 93, 101, 105],\n",
       "         [ 86,  94,  98],\n",
       "         [ 87,  95,  99]],\n",
       " \n",
       "        [[ 80,  73,  79],\n",
       "         [ 80,  73,  79],\n",
       "         [ 80,  73,  79],\n",
       "         ...,\n",
       "         [ 92, 100, 104],\n",
       "         [ 85,  93,  97],\n",
       "         [ 86,  94,  98]],\n",
       " \n",
       "        [[ 80,  73,  79],\n",
       "         [ 80,  73,  79],\n",
       "         [ 80,  73,  79],\n",
       "         ...,\n",
       "         [ 92, 100, 104],\n",
       "         [ 85,  93,  97],\n",
       "         [ 86,  94,  98]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9970664978027344, 'inference': 3.9861202239990234, 'postprocess': 0.9975433349609375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[126, 129, 134],\n",
       "         [126, 129, 134],\n",
       "         [126, 129, 134],\n",
       "         ...,\n",
       "         [168, 175, 176],\n",
       "         [168, 175, 176],\n",
       "         [168, 175, 176]],\n",
       " \n",
       "        [[126, 129, 134],\n",
       "         [126, 129, 134],\n",
       "         [126, 129, 134],\n",
       "         ...,\n",
       "         [168, 175, 176],\n",
       "         [168, 175, 176],\n",
       "         [168, 175, 176]],\n",
       " \n",
       "        [[126, 129, 134],\n",
       "         [126, 129, 134],\n",
       "         [126, 129, 134],\n",
       "         ...,\n",
       "         [168, 175, 176],\n",
       "         [168, 175, 176],\n",
       "         [168, 175, 176]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[186, 184, 189],\n",
       "         [186, 184, 189],\n",
       "         [189, 187, 192],\n",
       "         ...,\n",
       "         [101, 109, 113],\n",
       "         [ 91,  99, 103],\n",
       "         [ 86,  94,  98]],\n",
       " \n",
       "        [[189, 184, 190],\n",
       "         [189, 184, 190],\n",
       "         [192, 187, 193],\n",
       "         ...,\n",
       "         [100, 108, 112],\n",
       "         [ 89,  97, 101],\n",
       "         [ 85,  93,  97]],\n",
       " \n",
       "        [[145, 140, 146],\n",
       "         [145, 140, 146],\n",
       "         [148, 143, 149],\n",
       "         ...,\n",
       "         [100, 108, 112],\n",
       "         [ 89,  97, 101],\n",
       "         [ 85,  93,  97]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9975433349609375, 'inference': 7.973432540893555, 'postprocess': 0.995635986328125},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[126, 129, 134],\n",
       "         [126, 129, 134],\n",
       "         [126, 129, 134],\n",
       "         ...,\n",
       "         [168, 175, 176],\n",
       "         [168, 175, 176],\n",
       "         [168, 175, 176]],\n",
       " \n",
       "        [[126, 129, 134],\n",
       "         [126, 129, 134],\n",
       "         [126, 129, 134],\n",
       "         ...,\n",
       "         [168, 175, 176],\n",
       "         [168, 175, 176],\n",
       "         [168, 175, 176]],\n",
       " \n",
       "        [[126, 129, 134],\n",
       "         [126, 129, 134],\n",
       "         [126, 129, 134],\n",
       "         ...,\n",
       "         [168, 175, 176],\n",
       "         [168, 175, 176],\n",
       "         [168, 175, 176]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 90,  87,  94],\n",
       "         [ 90,  87,  94],\n",
       "         [ 85,  82,  89],\n",
       "         ...,\n",
       "         [120, 128, 132],\n",
       "         [105, 113, 117],\n",
       "         [ 92, 100, 104]],\n",
       " \n",
       "        [[160, 158, 163],\n",
       "         [160, 158, 163],\n",
       "         [154, 152, 157],\n",
       "         ...,\n",
       "         [120, 128, 132],\n",
       "         [105, 113, 117],\n",
       "         [ 92, 100, 104]],\n",
       " \n",
       "        [[228, 226, 231],\n",
       "         [228, 226, 231],\n",
       "         [222, 220, 225],\n",
       "         ...,\n",
       "         [120, 128, 132],\n",
       "         [105, 113, 117],\n",
       "         [ 92, 100, 104]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9963512420654297, 'inference': 5.978584289550781, 'postprocess': 0.9968280792236328},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[125, 128, 133],\n",
       "         [125, 128, 133],\n",
       "         [125, 128, 133],\n",
       "         ...,\n",
       "         [167, 174, 175],\n",
       "         [167, 174, 175],\n",
       "         [167, 174, 175]],\n",
       " \n",
       "        [[125, 128, 133],\n",
       "         [125, 128, 133],\n",
       "         [125, 128, 133],\n",
       "         ...,\n",
       "         [167, 174, 175],\n",
       "         [167, 174, 175],\n",
       "         [167, 174, 175]],\n",
       " \n",
       "        [[125, 128, 133],\n",
       "         [125, 128, 133],\n",
       "         [125, 128, 133],\n",
       "         ...,\n",
       "         [167, 174, 175],\n",
       "         [167, 174, 175],\n",
       "         [167, 174, 175]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 91, 101, 105],\n",
       "         [ 90, 100, 104],\n",
       "         [ 83,  93,  97],\n",
       "         ...,\n",
       "         [123, 131, 135],\n",
       "         [112, 120, 124],\n",
       "         [ 96, 104, 108]],\n",
       " \n",
       "        [[ 87,  97, 101],\n",
       "         [ 90, 100, 104],\n",
       "         [ 92, 102, 106],\n",
       "         ...,\n",
       "         [122, 130, 134],\n",
       "         [110, 118, 122],\n",
       "         [ 95, 103, 107]],\n",
       " \n",
       "        [[ 87,  97, 101],\n",
       "         [ 92, 102, 106],\n",
       "         [101, 111, 115],\n",
       "         ...,\n",
       "         [122, 130, 134],\n",
       "         [110, 118, 122],\n",
       "         [ 95, 103, 107]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9968280792236328, 'inference': 4.981279373168945, 'postprocess': 1.0004043579101562},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[124, 127, 132],\n",
       "         [124, 127, 132],\n",
       "         [124, 127, 132],\n",
       "         ...,\n",
       "         [165, 172, 173],\n",
       "         [165, 172, 173],\n",
       "         [165, 172, 173]],\n",
       " \n",
       "        [[124, 127, 132],\n",
       "         [124, 127, 132],\n",
       "         [124, 127, 132],\n",
       "         ...,\n",
       "         [165, 172, 173],\n",
       "         [165, 172, 173],\n",
       "         [165, 172, 173]],\n",
       " \n",
       "        [[124, 127, 132],\n",
       "         [124, 127, 132],\n",
       "         [124, 127, 132],\n",
       "         ...,\n",
       "         [165, 172, 173],\n",
       "         [165, 172, 173],\n",
       "         [165, 172, 173]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[113, 123, 127],\n",
       "         [113, 123, 127],\n",
       "         [112, 122, 126],\n",
       "         ...,\n",
       "         [127, 135, 139],\n",
       "         [120, 128, 132],\n",
       "         [106, 114, 118]],\n",
       " \n",
       "        [[106, 116, 120],\n",
       "         [106, 116, 120],\n",
       "         [105, 115, 119],\n",
       "         ...,\n",
       "         [127, 135, 139],\n",
       "         [120, 128, 132],\n",
       "         [106, 114, 118]],\n",
       " \n",
       "        [[101, 111, 115],\n",
       "         [101, 111, 115],\n",
       "         [100, 110, 114],\n",
       "         ...,\n",
       "         [127, 135, 139],\n",
       "         [120, 128, 132],\n",
       "         [106, 114, 118]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 1.0027885437011719, 'inference': 5.972862243652344, 'postprocess': 0.9973049163818359},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[120, 128, 132],\n",
       "         [120, 128, 132],\n",
       "         [120, 128, 132],\n",
       "         ...,\n",
       "         [165, 172, 173],\n",
       "         [165, 172, 173],\n",
       "         [165, 172, 173]],\n",
       " \n",
       "        [[120, 128, 132],\n",
       "         [120, 128, 132],\n",
       "         [120, 128, 132],\n",
       "         ...,\n",
       "         [165, 172, 173],\n",
       "         [165, 172, 173],\n",
       "         [165, 172, 173]],\n",
       " \n",
       "        [[120, 128, 132],\n",
       "         [120, 128, 132],\n",
       "         [120, 128, 132],\n",
       "         ...,\n",
       "         [165, 172, 173],\n",
       "         [165, 172, 173],\n",
       "         [165, 172, 173]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[115, 125, 129],\n",
       "         [115, 125, 129],\n",
       "         [115, 125, 129],\n",
       "         ...,\n",
       "         [128, 136, 140],\n",
       "         [126, 134, 138],\n",
       "         [116, 124, 128]],\n",
       " \n",
       "        [[117, 127, 131],\n",
       "         [117, 127, 131],\n",
       "         [115, 125, 129],\n",
       "         ...,\n",
       "         [128, 136, 140],\n",
       "         [126, 134, 138],\n",
       "         [116, 124, 128]],\n",
       " \n",
       "        [[114, 124, 128],\n",
       "         [114, 124, 128],\n",
       "         [113, 123, 127],\n",
       "         ...,\n",
       "         [128, 136, 140],\n",
       "         [126, 134, 138],\n",
       "         [116, 124, 128]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 1.001119613647461, 'inference': 8.967161178588867, 'postprocess': 1.497507095336914},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[121, 124, 129],\n",
       "         [121, 124, 129],\n",
       "         [121, 124, 129],\n",
       "         ...,\n",
       "         [165, 172, 173],\n",
       "         [165, 172, 173],\n",
       "         [165, 172, 173]],\n",
       " \n",
       "        [[121, 124, 129],\n",
       "         [121, 124, 129],\n",
       "         [121, 124, 129],\n",
       "         ...,\n",
       "         [165, 172, 173],\n",
       "         [165, 172, 173],\n",
       "         [165, 172, 173]],\n",
       " \n",
       "        [[121, 124, 129],\n",
       "         [121, 124, 129],\n",
       "         [121, 124, 129],\n",
       "         ...,\n",
       "         [165, 172, 173],\n",
       "         [165, 172, 173],\n",
       "         [165, 172, 173]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[115, 125, 129],\n",
       "         [115, 125, 129],\n",
       "         [115, 125, 129],\n",
       "         ...,\n",
       "         [128, 136, 140],\n",
       "         [128, 136, 140],\n",
       "         [121, 129, 133]],\n",
       " \n",
       "        [[117, 127, 131],\n",
       "         [117, 127, 131],\n",
       "         [117, 127, 131],\n",
       "         ...,\n",
       "         [128, 136, 140],\n",
       "         [128, 136, 140],\n",
       "         [121, 129, 133]],\n",
       " \n",
       "        [[114, 124, 128],\n",
       "         [114, 124, 128],\n",
       "         [114, 124, 128],\n",
       "         ...,\n",
       "         [128, 136, 140],\n",
       "         [128, 136, 140],\n",
       "         [121, 129, 133]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.995635986328125, 'inference': 3.9827823638916016, 'postprocess': 0.9963512420654297},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[117, 123, 132],\n",
       "         [117, 123, 132],\n",
       "         [117, 123, 132],\n",
       "         ...,\n",
       "         [165, 172, 173],\n",
       "         [165, 172, 173],\n",
       "         [165, 172, 173]],\n",
       " \n",
       "        [[117, 123, 132],\n",
       "         [117, 123, 132],\n",
       "         [117, 123, 132],\n",
       "         ...,\n",
       "         [165, 172, 173],\n",
       "         [165, 172, 173],\n",
       "         [165, 172, 173]],\n",
       " \n",
       "        [[117, 123, 132],\n",
       "         [117, 123, 132],\n",
       "         [117, 123, 132],\n",
       "         ...,\n",
       "         [165, 172, 173],\n",
       "         [165, 172, 173],\n",
       "         [165, 172, 173]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[115, 125, 129],\n",
       "         [115, 125, 129],\n",
       "         [115, 125, 129],\n",
       "         ...,\n",
       "         [128, 136, 140],\n",
       "         [128, 136, 140],\n",
       "         [121, 129, 133]],\n",
       " \n",
       "        [[117, 127, 131],\n",
       "         [117, 127, 131],\n",
       "         [117, 127, 131],\n",
       "         ...,\n",
       "         [128, 136, 140],\n",
       "         [128, 136, 140],\n",
       "         [121, 129, 133]],\n",
       " \n",
       "        [[114, 124, 128],\n",
       "         [114, 124, 128],\n",
       "         [114, 124, 128],\n",
       "         ...,\n",
       "         [128, 136, 140],\n",
       "         [128, 136, 140],\n",
       "         [121, 129, 133]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9968280792236328, 'inference': 4.982709884643555, 'postprocess': 0.9968280792236328},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[117, 123, 132],\n",
       "         [117, 123, 132],\n",
       "         [117, 123, 132],\n",
       "         ...,\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171]],\n",
       " \n",
       "        [[117, 123, 132],\n",
       "         [117, 123, 132],\n",
       "         [117, 123, 132],\n",
       "         ...,\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171]],\n",
       " \n",
       "        [[117, 123, 132],\n",
       "         [117, 123, 132],\n",
       "         [117, 123, 132],\n",
       "         ...,\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[115, 125, 129],\n",
       "         [115, 125, 129],\n",
       "         [115, 125, 129],\n",
       "         ...,\n",
       "         [128, 136, 140],\n",
       "         [129, 137, 141],\n",
       "         [123, 131, 135]],\n",
       " \n",
       "        [[117, 127, 131],\n",
       "         [117, 127, 131],\n",
       "         [117, 127, 131],\n",
       "         ...,\n",
       "         [128, 136, 140],\n",
       "         [129, 137, 141],\n",
       "         [123, 131, 135]],\n",
       " \n",
       "        [[114, 124, 128],\n",
       "         [114, 124, 128],\n",
       "         [114, 124, 128],\n",
       "         ...,\n",
       "         [128, 136, 140],\n",
       "         [129, 137, 141],\n",
       "         [123, 131, 135]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9968280792236328, 'inference': 4.312992095947266, 'postprocess': 0.9207725524902344},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[117, 123, 132],\n",
       "         [117, 123, 132],\n",
       "         [117, 123, 132],\n",
       "         ...,\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171]],\n",
       " \n",
       "        [[117, 123, 132],\n",
       "         [117, 123, 132],\n",
       "         [117, 123, 132],\n",
       "         ...,\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171]],\n",
       " \n",
       "        [[117, 123, 132],\n",
       "         [117, 123, 132],\n",
       "         [117, 123, 132],\n",
       "         ...,\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[117, 127, 131],\n",
       "         [117, 127, 131],\n",
       "         [115, 125, 129],\n",
       "         ...,\n",
       "         [128, 136, 140],\n",
       "         [129, 137, 141],\n",
       "         [123, 131, 135]],\n",
       " \n",
       "        [[115, 125, 129],\n",
       "         [115, 125, 129],\n",
       "         [114, 124, 128],\n",
       "         ...,\n",
       "         [128, 136, 140],\n",
       "         [129, 137, 141],\n",
       "         [123, 131, 135]],\n",
       " \n",
       "        [[113, 123, 127],\n",
       "         [111, 121, 125],\n",
       "         [110, 120, 124],\n",
       "         ...,\n",
       "         [128, 136, 140],\n",
       "         [129, 137, 141],\n",
       "         [123, 131, 135]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 1.0018348693847656, 'inference': 3.980875015258789, 'postprocess': 0.9968280792236328},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[120, 122, 129],\n",
       "         [120, 122, 129],\n",
       "         [120, 122, 129],\n",
       "         ...,\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171]],\n",
       " \n",
       "        [[120, 122, 129],\n",
       "         [120, 122, 129],\n",
       "         [120, 122, 129],\n",
       "         ...,\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171]],\n",
       " \n",
       "        [[118, 120, 127],\n",
       "         [119, 121, 128],\n",
       "         [119, 121, 128],\n",
       "         ...,\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[110, 120, 124],\n",
       "         [107, 117, 121],\n",
       "         [100, 110, 114],\n",
       "         ...,\n",
       "         [128, 136, 140],\n",
       "         [129, 137, 141],\n",
       "         [123, 131, 135]],\n",
       " \n",
       "        [[ 97, 107, 111],\n",
       "         [ 92, 102, 106],\n",
       "         [ 84,  94,  98],\n",
       "         ...,\n",
       "         [128, 136, 140],\n",
       "         [129, 137, 141],\n",
       "         [123, 131, 135]],\n",
       " \n",
       "        [[ 85,  95,  99],\n",
       "         [ 80,  90,  94],\n",
       "         [ 72,  82,  86],\n",
       "         ...,\n",
       "         [128, 136, 140],\n",
       "         [129, 137, 141],\n",
       "         [123, 131, 135]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 1.9936561584472656, 'inference': 7.976770401000977, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[119, 121, 128],\n",
       "         [120, 122, 129],\n",
       "         [120, 122, 129],\n",
       "         ...,\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171]],\n",
       " \n",
       "        [[118, 120, 127],\n",
       "         [119, 121, 128],\n",
       "         [118, 120, 127],\n",
       "         ...,\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171]],\n",
       " \n",
       "        [[117, 119, 126],\n",
       "         [117, 119, 126],\n",
       "         [116, 118, 125],\n",
       "         ...,\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 85,  86,  91],\n",
       "         [ 85,  86,  91],\n",
       "         [ 83,  84,  89],\n",
       "         ...,\n",
       "         [128, 136, 140],\n",
       "         [129, 137, 141],\n",
       "         [123, 131, 135]],\n",
       " \n",
       "        [[ 78,  79,  84],\n",
       "         [ 80,  81,  86],\n",
       "         [ 83,  84,  89],\n",
       "         ...,\n",
       "         [128, 136, 140],\n",
       "         [129, 137, 141],\n",
       "         [123, 131, 135]],\n",
       " \n",
       "        [[ 78,  79,  84],\n",
       "         [ 80,  81,  86],\n",
       "         [ 82,  83,  88],\n",
       "         ...,\n",
       "         [128, 136, 140],\n",
       "         [129, 137, 141],\n",
       "         [123, 131, 135]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9984970092773438, 'inference': 7.971525192260742, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[119, 121, 128],\n",
       "         [120, 122, 129],\n",
       "         [120, 122, 129],\n",
       "         ...,\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171]],\n",
       " \n",
       "        [[118, 120, 127],\n",
       "         [119, 121, 128],\n",
       "         [118, 120, 127],\n",
       "         ...,\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171]],\n",
       " \n",
       "        [[117, 119, 126],\n",
       "         [117, 119, 126],\n",
       "         [116, 118, 125],\n",
       "         ...,\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 83,  89,  93],\n",
       "         [ 96, 102, 106],\n",
       "         [123, 129, 133],\n",
       "         ...,\n",
       "         [128, 136, 140],\n",
       "         [129, 137, 141],\n",
       "         [123, 131, 135]],\n",
       " \n",
       "        [[103, 109, 113],\n",
       "         [117, 123, 127],\n",
       "         [144, 150, 154],\n",
       "         ...,\n",
       "         [128, 136, 140],\n",
       "         [129, 137, 141],\n",
       "         [123, 131, 135]],\n",
       " \n",
       "        [[154, 160, 164],\n",
       "         [160, 166, 170],\n",
       "         [174, 180, 184],\n",
       "         ...,\n",
       "         [128, 136, 140],\n",
       "         [129, 137, 141],\n",
       "         [123, 131, 135]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9968280792236328, 'inference': 5.266666412353516, 'postprocess': 0.9989738464355469},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[119, 121, 128],\n",
       "         [120, 122, 129],\n",
       "         [120, 122, 129],\n",
       "         ...,\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171]],\n",
       " \n",
       "        [[118, 120, 127],\n",
       "         [119, 121, 128],\n",
       "         [118, 120, 127],\n",
       "         ...,\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171]],\n",
       " \n",
       "        [[117, 119, 126],\n",
       "         [117, 119, 126],\n",
       "         [116, 118, 125],\n",
       "         ...,\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[188, 194, 198],\n",
       "         [196, 202, 206],\n",
       "         [209, 215, 219],\n",
       "         ...,\n",
       "         [128, 136, 140],\n",
       "         [129, 137, 141],\n",
       "         [127, 135, 139]],\n",
       " \n",
       "        [[185, 191, 195],\n",
       "         [194, 200, 204],\n",
       "         [207, 213, 217],\n",
       "         ...,\n",
       "         [128, 136, 140],\n",
       "         [129, 137, 141],\n",
       "         [127, 135, 139]],\n",
       " \n",
       "        [[186, 192, 196],\n",
       "         [194, 200, 204],\n",
       "         [207, 213, 217],\n",
       "         ...,\n",
       "         [128, 136, 140],\n",
       "         [129, 137, 141],\n",
       "         [127, 135, 139]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 1.0023117065429688, 'inference': 7.029056549072266, 'postprocess': 0.9965896606445312},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[119, 121, 128],\n",
       "         [120, 122, 129],\n",
       "         [120, 122, 129],\n",
       "         ...,\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171]],\n",
       " \n",
       "        [[118, 120, 127],\n",
       "         [119, 121, 128],\n",
       "         [118, 120, 127],\n",
       "         ...,\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171]],\n",
       " \n",
       "        [[117, 119, 126],\n",
       "         [117, 119, 126],\n",
       "         [116, 118, 125],\n",
       "         ...,\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[170, 168, 173],\n",
       "         [173, 171, 176],\n",
       "         [170, 168, 173],\n",
       "         ...,\n",
       "         [128, 136, 140],\n",
       "         [129, 137, 141],\n",
       "         [127, 135, 139]],\n",
       " \n",
       "        [[112, 110, 115],\n",
       "         [116, 114, 119],\n",
       "         [112, 110, 115],\n",
       "         ...,\n",
       "         [128, 136, 140],\n",
       "         [129, 137, 141],\n",
       "         [127, 135, 139]],\n",
       " \n",
       "        [[ 83,  81,  86],\n",
       "         [ 87,  85,  90],\n",
       "         [ 83,  81,  86],\n",
       "         ...,\n",
       "         [128, 136, 140],\n",
       "         [129, 137, 141],\n",
       "         [127, 135, 139]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9968280792236328, 'inference': 4.987478256225586, 'postprocess': 0.9961128234863281},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[114, 116, 123],\n",
       "         [114, 116, 123],\n",
       "         [116, 118, 125],\n",
       "         ...,\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171]],\n",
       " \n",
       "        [[114, 116, 123],\n",
       "         [114, 116, 123],\n",
       "         [114, 116, 123],\n",
       "         ...,\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171]],\n",
       " \n",
       "        [[116, 118, 125],\n",
       "         [116, 118, 125],\n",
       "         [116, 118, 125],\n",
       "         ...,\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 62,  60,  65],\n",
       "         [ 64,  62,  67],\n",
       "         [ 66,  64,  69],\n",
       "         ...,\n",
       "         [128, 136, 140],\n",
       "         [129, 137, 141],\n",
       "         [127, 135, 139]],\n",
       " \n",
       "        [[ 62,  60,  65],\n",
       "         [ 64,  62,  67],\n",
       "         [ 66,  64,  69],\n",
       "         ...,\n",
       "         [128, 136, 140],\n",
       "         [129, 137, 141],\n",
       "         [127, 135, 139]],\n",
       " \n",
       "        [[ 62,  60,  65],\n",
       "         [ 64,  62,  67],\n",
       "         [ 66,  64,  69],\n",
       "         ...,\n",
       "         [128, 136, 140],\n",
       "         [129, 137, 141],\n",
       "         [127, 135, 139]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9965896606445312, 'inference': 7.973670959472656, 'postprocess': 1.0006427764892578},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[114, 116, 123],\n",
       "         [114, 116, 123],\n",
       "         [116, 118, 125],\n",
       "         ...,\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171]],\n",
       " \n",
       "        [[114, 116, 123],\n",
       "         [114, 116, 123],\n",
       "         [114, 116, 123],\n",
       "         ...,\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171]],\n",
       " \n",
       "        [[116, 118, 125],\n",
       "         [116, 118, 125],\n",
       "         [116, 118, 125],\n",
       "         ...,\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171],\n",
       "         [163, 170, 171]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 62,  60,  65],\n",
       "         [ 62,  60,  65],\n",
       "         [ 62,  60,  65],\n",
       "         ...,\n",
       "         [128, 136, 140],\n",
       "         [129, 137, 141],\n",
       "         [127, 135, 139]],\n",
       " \n",
       "        [[ 62,  60,  65],\n",
       "         [ 62,  60,  65],\n",
       "         [ 62,  60,  65],\n",
       "         ...,\n",
       "         [128, 136, 140],\n",
       "         [129, 137, 141],\n",
       "         [127, 135, 139]],\n",
       " \n",
       "        [[ 62,  60,  65],\n",
       "         [ 62,  60,  65],\n",
       "         [ 62,  60,  65],\n",
       "         ...,\n",
       "         [128, 136, 140],\n",
       "         [129, 137, 141],\n",
       "         [127, 135, 139]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 1.001119613647461, 'inference': 4.978656768798828, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         ...,\n",
       "         [161, 170, 171],\n",
       "         [161, 170, 171],\n",
       "         [161, 170, 171]],\n",
       " \n",
       "        [[115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         ...,\n",
       "         [161, 170, 171],\n",
       "         [161, 170, 171],\n",
       "         [161, 170, 171]],\n",
       " \n",
       "        [[114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         ...,\n",
       "         [161, 170, 171],\n",
       "         [161, 170, 171],\n",
       "         [161, 170, 171]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 66,  60,  63],\n",
       "         [ 66,  60,  63],\n",
       "         [ 65,  59,  62],\n",
       "         ...,\n",
       "         [124, 133, 139],\n",
       "         [121, 130, 136],\n",
       "         [122, 131, 137]],\n",
       " \n",
       "        [[ 65,  59,  62],\n",
       "         [ 65,  59,  62],\n",
       "         [ 65,  59,  62],\n",
       "         ...,\n",
       "         [121, 130, 136],\n",
       "         [120, 129, 135],\n",
       "         [120, 129, 135]],\n",
       " \n",
       "        [[ 65,  59,  62],\n",
       "         [ 65,  59,  62],\n",
       "         [ 65,  59,  62],\n",
       "         ...,\n",
       "         [120, 129, 135],\n",
       "         [120, 129, 135],\n",
       "         [120, 129, 135]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9961128234863281, 'inference': 4.9877166748046875, 'postprocess': 0.9927749633789062},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         ...,\n",
       "         [161, 170, 171],\n",
       "         [161, 170, 171],\n",
       "         [161, 170, 171]],\n",
       " \n",
       "        [[115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         ...,\n",
       "         [161, 170, 171],\n",
       "         [161, 170, 171],\n",
       "         [161, 170, 171]],\n",
       " \n",
       "        [[114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         ...,\n",
       "         [161, 170, 171],\n",
       "         [161, 170, 171],\n",
       "         [161, 170, 171]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 65,  59,  62],\n",
       "         [ 65,  59,  62],\n",
       "         [ 65,  59,  62],\n",
       "         ...,\n",
       "         [124, 133, 139],\n",
       "         [121, 130, 136],\n",
       "         [122, 131, 137]],\n",
       " \n",
       "        [[ 65,  59,  62],\n",
       "         [ 65,  59,  62],\n",
       "         [ 65,  59,  62],\n",
       "         ...,\n",
       "         [121, 130, 136],\n",
       "         [120, 129, 135],\n",
       "         [120, 129, 135]],\n",
       " \n",
       "        [[ 65,  59,  62],\n",
       "         [ 65,  59,  62],\n",
       "         [ 65,  59,  62],\n",
       "         ...,\n",
       "         [120, 129, 135],\n",
       "         [120, 129, 135],\n",
       "         [120, 129, 135]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9970664978027344, 'inference': 4.986286163330078, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         ...,\n",
       "         [161, 170, 171],\n",
       "         [161, 170, 171],\n",
       "         [161, 170, 171]],\n",
       " \n",
       "        [[115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         ...,\n",
       "         [161, 170, 171],\n",
       "         [161, 170, 171],\n",
       "         [161, 170, 171]],\n",
       " \n",
       "        [[114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         ...,\n",
       "         [161, 170, 171],\n",
       "         [161, 170, 171],\n",
       "         [161, 170, 171]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 65,  59,  62],\n",
       "         [ 64,  58,  61],\n",
       "         [ 64,  58,  61],\n",
       "         ...,\n",
       "         [124, 133, 139],\n",
       "         [121, 130, 136],\n",
       "         [122, 131, 137]],\n",
       " \n",
       "        [[ 65,  59,  62],\n",
       "         [ 64,  58,  61],\n",
       "         [ 64,  58,  61],\n",
       "         ...,\n",
       "         [121, 130, 136],\n",
       "         [120, 129, 135],\n",
       "         [120, 129, 135]],\n",
       " \n",
       "        [[ 65,  59,  62],\n",
       "         [ 64,  58,  61],\n",
       "         [ 64,  58,  61],\n",
       "         ...,\n",
       "         [120, 129, 135],\n",
       "         [120, 129, 135],\n",
       "         [120, 129, 135]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9968280792236328, 'inference': 3.9856433868408203, 'postprocess': 0.9973049163818359},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         ...,\n",
       "         [162, 171, 172],\n",
       "         [162, 171, 172],\n",
       "         [162, 171, 172]],\n",
       " \n",
       "        [[115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         ...,\n",
       "         [162, 171, 172],\n",
       "         [162, 171, 172],\n",
       "         [162, 171, 172]],\n",
       " \n",
       "        [[114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         ...,\n",
       "         [162, 171, 172],\n",
       "         [162, 171, 172],\n",
       "         [162, 171, 172]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 64,  58,  61],\n",
       "         [ 63,  57,  60],\n",
       "         [ 63,  57,  60],\n",
       "         ...,\n",
       "         [124, 133, 139],\n",
       "         [121, 130, 136],\n",
       "         [122, 131, 137]],\n",
       " \n",
       "        [[ 64,  58,  61],\n",
       "         [ 63,  57,  60],\n",
       "         [ 63,  57,  60],\n",
       "         ...,\n",
       "         [121, 130, 136],\n",
       "         [120, 129, 135],\n",
       "         [120, 129, 135]],\n",
       " \n",
       "        [[ 64,  58,  61],\n",
       "         [ 63,  57,  60],\n",
       "         [ 63,  57,  60],\n",
       "         ...,\n",
       "         [120, 129, 135],\n",
       "         [120, 129, 135],\n",
       "         [120, 129, 135]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9968280792236328, 'inference': 4.983186721801758, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         ...,\n",
       "         [162, 171, 172],\n",
       "         [162, 171, 172],\n",
       "         [162, 171, 172]],\n",
       " \n",
       "        [[115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         ...,\n",
       "         [162, 171, 172],\n",
       "         [162, 171, 172],\n",
       "         [162, 171, 172]],\n",
       " \n",
       "        [[114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         ...,\n",
       "         [162, 171, 172],\n",
       "         [162, 171, 172],\n",
       "         [162, 171, 172]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 63,  57,  60],\n",
       "         [ 64,  58,  61],\n",
       "         [ 64,  58,  61],\n",
       "         ...,\n",
       "         [124, 133, 139],\n",
       "         [121, 130, 136],\n",
       "         [121, 130, 136]],\n",
       " \n",
       "        [[ 63,  57,  60],\n",
       "         [ 64,  58,  61],\n",
       "         [ 64,  58,  61],\n",
       "         ...,\n",
       "         [121, 130, 136],\n",
       "         [121, 130, 136],\n",
       "         [120, 129, 135]],\n",
       " \n",
       "        [[ 63,  57,  60],\n",
       "         [ 64,  58,  61],\n",
       "         [ 64,  58,  61],\n",
       "         ...,\n",
       "         [120, 129, 135],\n",
       "         [120, 129, 135],\n",
       "         [120, 129, 135]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9970664978027344, 'inference': 3.986358642578125, 'postprocess': 0.9961128234863281},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         ...,\n",
       "         [162, 171, 172],\n",
       "         [162, 171, 172],\n",
       "         [162, 171, 172]],\n",
       " \n",
       "        [[115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         ...,\n",
       "         [162, 171, 172],\n",
       "         [162, 171, 172],\n",
       "         [162, 171, 172]],\n",
       " \n",
       "        [[114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         ...,\n",
       "         [162, 171, 172],\n",
       "         [162, 171, 172],\n",
       "         [162, 171, 172]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 61,  55,  58],\n",
       "         [ 64,  58,  61],\n",
       "         [ 72,  66,  69],\n",
       "         ...,\n",
       "         [126, 135, 141],\n",
       "         [124, 133, 139],\n",
       "         [124, 133, 139]],\n",
       " \n",
       "        [[ 68,  62,  65],\n",
       "         [ 69,  63,  66],\n",
       "         [ 66,  60,  63],\n",
       "         ...,\n",
       "         [122, 131, 137],\n",
       "         [121, 130, 136],\n",
       "         [120, 129, 135]],\n",
       " \n",
       "        [[ 71,  65,  68],\n",
       "         [ 69,  63,  66],\n",
       "         [ 68,  62,  65],\n",
       "         ...,\n",
       "         [120, 129, 135],\n",
       "         [121, 130, 136],\n",
       "         [120, 129, 135]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 1.9946098327636719, 'inference': 6.9751739501953125, 'postprocess': 0.9968280792236328},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         ...,\n",
       "         [162, 171, 172],\n",
       "         [162, 171, 172],\n",
       "         [162, 171, 172]],\n",
       " \n",
       "        [[115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         ...,\n",
       "         [162, 171, 172],\n",
       "         [162, 171, 172],\n",
       "         [162, 171, 172]],\n",
       " \n",
       "        [[114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         ...,\n",
       "         [162, 171, 172],\n",
       "         [162, 171, 172],\n",
       "         [162, 171, 172]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 66,  60,  63],\n",
       "         [ 66,  60,  63],\n",
       "         [ 64,  58,  61],\n",
       "         ...,\n",
       "         [128, 137, 143],\n",
       "         [126, 135, 141],\n",
       "         [125, 134, 140]],\n",
       " \n",
       "        [[ 66,  60,  63],\n",
       "         [ 65,  59,  62],\n",
       "         [ 63,  57,  60],\n",
       "         ...,\n",
       "         [125, 134, 140],\n",
       "         [124, 133, 139],\n",
       "         [121, 130, 136]],\n",
       " \n",
       "        [[ 66,  60,  63],\n",
       "         [ 65,  59,  62],\n",
       "         [ 63,  57,  60],\n",
       "         ...,\n",
       "         [121, 130, 136],\n",
       "         [121, 130, 136],\n",
       "         [121, 130, 136]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 1.3098716735839844, 'inference': 5.33747673034668, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         ...,\n",
       "         [162, 171, 172],\n",
       "         [162, 171, 172],\n",
       "         [162, 171, 172]],\n",
       " \n",
       "        [[115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         ...,\n",
       "         [162, 171, 172],\n",
       "         [162, 171, 172],\n",
       "         [162, 171, 172]],\n",
       " \n",
       "        [[114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         ...,\n",
       "         [162, 171, 172],\n",
       "         [162, 171, 172],\n",
       "         [162, 171, 172]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 66,  60,  63],\n",
       "         [ 66,  60,  63],\n",
       "         [ 61,  55,  58],\n",
       "         ...,\n",
       "         [128, 137, 143],\n",
       "         [126, 135, 141],\n",
       "         [125, 134, 140]],\n",
       " \n",
       "        [[ 66,  60,  63],\n",
       "         [ 64,  58,  61],\n",
       "         [ 61,  55,  58],\n",
       "         ...,\n",
       "         [125, 134, 140],\n",
       "         [124, 133, 139],\n",
       "         [121, 130, 136]],\n",
       " \n",
       "        [[ 66,  60,  63],\n",
       "         [ 64,  58,  61],\n",
       "         [ 61,  55,  58],\n",
       "         ...,\n",
       "         [121, 130, 136],\n",
       "         [121, 130, 136],\n",
       "         [121, 130, 136]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 1.2755393981933594, 'inference': 3.8385391235351562, 'postprocess': 1.4317035675048828},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         ...,\n",
       "         [162, 171, 172],\n",
       "         [162, 171, 172],\n",
       "         [162, 171, 172]],\n",
       " \n",
       "        [[115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         ...,\n",
       "         [162, 171, 172],\n",
       "         [162, 171, 172],\n",
       "         [162, 171, 172]],\n",
       " \n",
       "        [[114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         ...,\n",
       "         [162, 171, 172],\n",
       "         [162, 171, 172],\n",
       "         [162, 171, 172]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 65,  59,  62],\n",
       "         [ 63,  57,  60],\n",
       "         [ 58,  52,  55],\n",
       "         ...,\n",
       "         [128, 137, 143],\n",
       "         [127, 136, 142],\n",
       "         [125, 134, 140]],\n",
       " \n",
       "        [[ 65,  59,  62],\n",
       "         [ 63,  57,  60],\n",
       "         [ 58,  52,  55],\n",
       "         ...,\n",
       "         [125, 134, 140],\n",
       "         [124, 133, 139],\n",
       "         [122, 131, 137]],\n",
       " \n",
       "        [[ 65,  59,  62],\n",
       "         [ 63,  57,  60],\n",
       "         [ 58,  52,  55],\n",
       "         ...,\n",
       "         [122, 131, 137],\n",
       "         [121, 130, 136],\n",
       "         [121, 130, 136]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 1.001596450805664, 'inference': 4.039287567138672, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         ...,\n",
       "         [162, 171, 172],\n",
       "         [162, 171, 172],\n",
       "         [162, 171, 172]],\n",
       " \n",
       "        [[115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         ...,\n",
       "         [162, 171, 172],\n",
       "         [162, 171, 172],\n",
       "         [162, 171, 172]],\n",
       " \n",
       "        [[114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         ...,\n",
       "         [162, 171, 172],\n",
       "         [162, 171, 172],\n",
       "         [162, 171, 172]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 58,  52,  55],\n",
       "         [ 51,  45,  48],\n",
       "         [ 54,  48,  51],\n",
       "         ...,\n",
       "         [128, 137, 143],\n",
       "         [128, 137, 143],\n",
       "         [126, 135, 141]],\n",
       " \n",
       "        [[ 56,  50,  53],\n",
       "         [ 52,  46,  49],\n",
       "         [ 55,  49,  52],\n",
       "         ...,\n",
       "         [125, 134, 140],\n",
       "         [125, 134, 140],\n",
       "         [122, 131, 137]],\n",
       " \n",
       "        [[ 56,  50,  53],\n",
       "         [ 52,  46,  49],\n",
       "         [ 55,  49,  52],\n",
       "         ...,\n",
       "         [122, 131, 137],\n",
       "         [122, 131, 137],\n",
       "         [121, 130, 136]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 1.073598861694336, 'inference': 6.97636604309082, 'postprocess': 0.9961128234863281},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         ...,\n",
       "         [163, 172, 173],\n",
       "         [163, 172, 173],\n",
       "         [163, 172, 173]],\n",
       " \n",
       "        [[115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         ...,\n",
       "         [163, 172, 173],\n",
       "         [163, 172, 173],\n",
       "         [163, 172, 173]],\n",
       " \n",
       "        [[114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         ...,\n",
       "         [163, 172, 173],\n",
       "         [163, 172, 173],\n",
       "         [163, 172, 173]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 52,  46,  49],\n",
       "         [ 59,  53,  56],\n",
       "         [ 64,  58,  61],\n",
       "         ...,\n",
       "         [128, 137, 143],\n",
       "         [128, 137, 143],\n",
       "         [126, 135, 141]],\n",
       " \n",
       "        [[ 52,  46,  49],\n",
       "         [ 59,  53,  56],\n",
       "         [ 64,  58,  61],\n",
       "         ...,\n",
       "         [125, 134, 140],\n",
       "         [125, 134, 140],\n",
       "         [122, 131, 137]],\n",
       " \n",
       "        [[ 52,  46,  49],\n",
       "         [ 59,  53,  56],\n",
       "         [ 64,  58,  61],\n",
       "         ...,\n",
       "         [122, 131, 137],\n",
       "         [122, 131, 137],\n",
       "         [121, 130, 136]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9894371032714844, 'inference': 4.983425140380859, 'postprocess': 0.9982585906982422},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         ...,\n",
       "         [163, 172, 173],\n",
       "         [163, 172, 173],\n",
       "         [163, 172, 173]],\n",
       " \n",
       "        [[115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         ...,\n",
       "         [163, 172, 173],\n",
       "         [163, 172, 173],\n",
       "         [163, 172, 173]],\n",
       " \n",
       "        [[114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         ...,\n",
       "         [163, 172, 173],\n",
       "         [163, 172, 173],\n",
       "         [163, 172, 173]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 52,  46,  49],\n",
       "         [ 54,  48,  51],\n",
       "         [ 61,  55,  58],\n",
       "         ...,\n",
       "         [129, 138, 144],\n",
       "         [129, 138, 144],\n",
       "         [128, 137, 143]],\n",
       " \n",
       "        [[ 52,  46,  49],\n",
       "         [ 54,  48,  51],\n",
       "         [ 61,  55,  58],\n",
       "         ...,\n",
       "         [126, 135, 141],\n",
       "         [126, 135, 141],\n",
       "         [125, 134, 140]],\n",
       " \n",
       "        [[ 52,  46,  49],\n",
       "         [ 54,  48,  51],\n",
       "         [ 61,  55,  58],\n",
       "         ...,\n",
       "         [124, 133, 139],\n",
       "         [124, 133, 139],\n",
       "         [122, 131, 137]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9968280792236328, 'inference': 4.983425140380859, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         ...,\n",
       "         [163, 172, 173],\n",
       "         [163, 172, 173],\n",
       "         [163, 172, 173]],\n",
       " \n",
       "        [[115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         ...,\n",
       "         [163, 172, 173],\n",
       "         [163, 172, 173],\n",
       "         [163, 172, 173]],\n",
       " \n",
       "        [[114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         ...,\n",
       "         [163, 172, 173],\n",
       "         [163, 172, 173],\n",
       "         [163, 172, 173]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 56,  50,  53],\n",
       "         [ 52,  46,  49],\n",
       "         [ 54,  48,  51],\n",
       "         ...,\n",
       "         [129, 138, 144],\n",
       "         [129, 138, 144],\n",
       "         [128, 137, 143]],\n",
       " \n",
       "        [[ 55,  49,  52],\n",
       "         [ 51,  45,  48],\n",
       "         [ 52,  46,  49],\n",
       "         ...,\n",
       "         [126, 135, 141],\n",
       "         [126, 135, 141],\n",
       "         [125, 134, 140]],\n",
       " \n",
       "        [[ 55,  49,  52],\n",
       "         [ 51,  45,  48],\n",
       "         [ 52,  46,  49],\n",
       "         ...,\n",
       "         [124, 133, 139],\n",
       "         [124, 133, 139],\n",
       "         [122, 131, 137]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9965896606445312, 'inference': 4.983425140380859, 'postprocess': 0.9961128234863281},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         ...,\n",
       "         [163, 172, 173],\n",
       "         [163, 172, 173],\n",
       "         [163, 172, 173]],\n",
       " \n",
       "        [[115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         ...,\n",
       "         [163, 172, 173],\n",
       "         [163, 172, 173],\n",
       "         [163, 172, 173]],\n",
       " \n",
       "        [[114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         ...,\n",
       "         [163, 172, 173],\n",
       "         [163, 172, 173],\n",
       "         [163, 172, 173]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 59,  53,  56],\n",
       "         [ 56,  50,  53],\n",
       "         [ 48,  42,  45],\n",
       "         ...,\n",
       "         [131, 140, 146],\n",
       "         [131, 140, 146],\n",
       "         [129, 138, 144]],\n",
       " \n",
       "        [[ 58,  52,  55],\n",
       "         [ 55,  49,  52],\n",
       "         [ 48,  42,  45],\n",
       "         ...,\n",
       "         [128, 137, 143],\n",
       "         [128, 137, 143],\n",
       "         [127, 136, 142]],\n",
       " \n",
       "        [[ 58,  52,  55],\n",
       "         [ 55,  49,  52],\n",
       "         [ 48,  42,  45],\n",
       "         ...,\n",
       "         [125, 134, 140],\n",
       "         [125, 134, 140],\n",
       "         [124, 133, 139]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 1.0013580322265625, 'inference': 4.97746467590332, 'postprocess': 1.0018348693847656},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         ...,\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177]],\n",
       " \n",
       "        [[115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         ...,\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177]],\n",
       " \n",
       "        [[114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         ...,\n",
       "         [166, 175, 176],\n",
       "         [166, 175, 176],\n",
       "         [166, 175, 176]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 56,  50,  53],\n",
       "         [ 59,  53,  56],\n",
       "         [ 55,  49,  52],\n",
       "         ...,\n",
       "         [131, 140, 146],\n",
       "         [131, 140, 146],\n",
       "         [131, 140, 146]],\n",
       " \n",
       "        [[ 56,  50,  53],\n",
       "         [ 59,  53,  56],\n",
       "         [ 55,  49,  52],\n",
       "         ...,\n",
       "         [129, 138, 144],\n",
       "         [129, 138, 144],\n",
       "         [129, 138, 144]],\n",
       " \n",
       "        [[ 56,  50,  53],\n",
       "         [ 59,  53,  56],\n",
       "         [ 55,  49,  52],\n",
       "         ...,\n",
       "         [126, 135, 141],\n",
       "         [126, 135, 141],\n",
       "         [126, 135, 141]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 1.1615753173828125, 'inference': 5.471944808959961, 'postprocess': 0.9973049163818359},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         ...,\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177]],\n",
       " \n",
       "        [[115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         ...,\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177]],\n",
       " \n",
       "        [[114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         ...,\n",
       "         [166, 175, 176],\n",
       "         [166, 175, 176],\n",
       "         [166, 175, 176]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 51,  45,  48],\n",
       "         [ 47,  41,  44],\n",
       "         [ 47,  43,  46],\n",
       "         ...,\n",
       "         [131, 140, 146],\n",
       "         [131, 140, 146],\n",
       "         [131, 140, 146]],\n",
       " \n",
       "        [[ 50,  44,  47],\n",
       "         [ 47,  41,  44],\n",
       "         [ 47,  43,  46],\n",
       "         ...,\n",
       "         [129, 138, 144],\n",
       "         [129, 138, 144],\n",
       "         [129, 138, 144]],\n",
       " \n",
       "        [[ 50,  44,  47],\n",
       "         [ 47,  41,  44],\n",
       "         [ 47,  43,  46],\n",
       "         ...,\n",
       "         [126, 135, 141],\n",
       "         [126, 135, 141],\n",
       "         [126, 135, 141]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9963512420654297, 'inference': 5.2337646484375, 'postprocess': 0.9984970092773438},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         ...,\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177]],\n",
       " \n",
       "        [[115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         ...,\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177]],\n",
       " \n",
       "        [[114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         ...,\n",
       "         [166, 175, 176],\n",
       "         [166, 175, 176],\n",
       "         [166, 175, 176]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 45,  41,  44],\n",
       "         [ 50,  46,  49],\n",
       "         [ 52,  51,  53],\n",
       "         ...,\n",
       "         [131, 140, 146],\n",
       "         [131, 140, 146],\n",
       "         [131, 140, 146]],\n",
       " \n",
       "        [[ 45,  41,  44],\n",
       "         [ 50,  46,  49],\n",
       "         [ 52,  51,  53],\n",
       "         ...,\n",
       "         [129, 138, 144],\n",
       "         [129, 138, 144],\n",
       "         [129, 138, 144]],\n",
       " \n",
       "        [[ 45,  41,  44],\n",
       "         [ 50,  46,  49],\n",
       "         [ 52,  51,  53],\n",
       "         ...,\n",
       "         [126, 135, 141],\n",
       "         [126, 135, 141],\n",
       "         [126, 135, 141]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9958744049072266, 'inference': 5.058050155639648, 'postprocess': 0.9963512420654297},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         ...,\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177]],\n",
       " \n",
       "        [[114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         ...,\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177]],\n",
       " \n",
       "        [[114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         ...,\n",
       "         [166, 175, 176],\n",
       "         [166, 175, 176],\n",
       "         [166, 175, 176]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 47,  43,  46],\n",
       "         [ 53,  49,  52],\n",
       "         [ 50,  49,  51],\n",
       "         ...,\n",
       "         [131, 140, 146],\n",
       "         [131, 140, 146],\n",
       "         [131, 140, 146]],\n",
       " \n",
       "        [[ 47,  43,  46],\n",
       "         [ 53,  49,  52],\n",
       "         [ 50,  49,  51],\n",
       "         ...,\n",
       "         [131, 140, 146],\n",
       "         [131, 140, 146],\n",
       "         [131, 140, 146]],\n",
       " \n",
       "        [[ 47,  43,  46],\n",
       "         [ 53,  49,  52],\n",
       "         [ 50,  49,  51],\n",
       "         ...,\n",
       "         [127, 136, 142],\n",
       "         [127, 136, 142],\n",
       "         [127, 136, 142]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9999275207519531, 'inference': 9.96255874633789, 'postprocess': 1.993417739868164},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         ...,\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177]],\n",
       " \n",
       "        [[114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         ...,\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177]],\n",
       " \n",
       "        [[114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         ...,\n",
       "         [167, 176, 177],\n",
       "         [166, 175, 176],\n",
       "         [166, 175, 176]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 47,  43,  46],\n",
       "         [ 47,  43,  46],\n",
       "         [ 52,  48,  51],\n",
       "         ...,\n",
       "         [131, 140, 146],\n",
       "         [131, 140, 146],\n",
       "         [131, 140, 146]],\n",
       " \n",
       "        [[ 47,  43,  46],\n",
       "         [ 47,  43,  46],\n",
       "         [ 52,  48,  51],\n",
       "         ...,\n",
       "         [131, 140, 146],\n",
       "         [131, 140, 146],\n",
       "         [131, 140, 146]],\n",
       " \n",
       "        [[ 47,  43,  46],\n",
       "         [ 47,  43,  46],\n",
       "         [ 52,  48,  51],\n",
       "         ...,\n",
       "         [127, 136, 142],\n",
       "         [127, 136, 142],\n",
       "         [127, 136, 142]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 1.9931793212890625, 'inference': 3.9870738983154297, 'postprocess': 0.9968280792236328},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         [115, 121, 130],\n",
       "         ...,\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177]],\n",
       " \n",
       "        [[114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         ...,\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177]],\n",
       " \n",
       "        [[114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         ...,\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177],\n",
       "         [166, 175, 176]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 47,  43,  46],\n",
       "         [ 47,  43,  46],\n",
       "         [ 47,  43,  46],\n",
       "         ...,\n",
       "         [133, 142, 148],\n",
       "         [131, 140, 146],\n",
       "         [131, 140, 146]],\n",
       " \n",
       "        [[ 47,  43,  46],\n",
       "         [ 47,  43,  46],\n",
       "         [ 47,  43,  46],\n",
       "         ...,\n",
       "         [131, 140, 146],\n",
       "         [131, 140, 146],\n",
       "         [131, 140, 146]],\n",
       " \n",
       "        [[ 47,  43,  46],\n",
       "         [ 47,  43,  46],\n",
       "         [ 47,  43,  46],\n",
       "         ...,\n",
       "         [127, 136, 142],\n",
       "         [127, 136, 142],\n",
       "         [127, 136, 142]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 1.9965171813964844, 'inference': 6.973028182983398, 'postprocess': 2.5010108947753906},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         ...,\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177]],\n",
       " \n",
       "        [[114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         ...,\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177]],\n",
       " \n",
       "        [[113, 119, 128],\n",
       "         [113, 119, 128],\n",
       "         [113, 119, 128],\n",
       "         ...,\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 47,  43,  46],\n",
       "         [ 47,  43,  46],\n",
       "         [ 47,  43,  46],\n",
       "         ...,\n",
       "         [134, 143, 149],\n",
       "         [132, 141, 147],\n",
       "         [131, 140, 146]],\n",
       " \n",
       "        [[ 47,  43,  46],\n",
       "         [ 47,  43,  46],\n",
       "         [ 47,  43,  46],\n",
       "         ...,\n",
       "         [131, 140, 146],\n",
       "         [129, 138, 144],\n",
       "         [131, 140, 146]],\n",
       " \n",
       "        [[ 47,  43,  46],\n",
       "         [ 47,  43,  46],\n",
       "         [ 47,  43,  46],\n",
       "         ...,\n",
       "         [127, 136, 142],\n",
       "         [127, 136, 142],\n",
       "         [127, 136, 142]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9965896606445312, 'inference': 4.982948303222656, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         ...,\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179],\n",
       "         [167, 176, 177]],\n",
       " \n",
       "        [[114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         ...,\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179],\n",
       "         [167, 176, 177]],\n",
       " \n",
       "        [[113, 119, 128],\n",
       "         [113, 119, 128],\n",
       "         [113, 119, 128],\n",
       "         ...,\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179],\n",
       "         [167, 176, 177]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 40,  39,  41],\n",
       "         [ 51,  50,  52],\n",
       "         [ 63,  59,  62],\n",
       "         ...,\n",
       "         [135, 144, 150],\n",
       "         [133, 142, 148],\n",
       "         [131, 140, 146]],\n",
       " \n",
       "        [[ 40,  39,  41],\n",
       "         [ 52,  51,  53],\n",
       "         [ 64,  60,  63],\n",
       "         ...,\n",
       "         [131, 140, 146],\n",
       "         [129, 138, 144],\n",
       "         [129, 138, 144]],\n",
       " \n",
       "        [[ 40,  39,  41],\n",
       "         [ 52,  51,  53],\n",
       "         [ 64,  60,  63],\n",
       "         ...,\n",
       "         [126, 135, 141],\n",
       "         [127, 136, 142],\n",
       "         [127, 136, 142]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 1.9936561584472656, 'inference': 3.986358642578125, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         ...,\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179]],\n",
       " \n",
       "        [[114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         ...,\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179]],\n",
       " \n",
       "        [[113, 119, 128],\n",
       "         [113, 119, 128],\n",
       "         [113, 119, 128],\n",
       "         ...,\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 49,  43,  46],\n",
       "         [ 54,  48,  51],\n",
       "         [ 52,  46,  49],\n",
       "         ...,\n",
       "         [136, 145, 151],\n",
       "         [133, 142, 148],\n",
       "         [132, 141, 147]],\n",
       " \n",
       "        [[ 50,  44,  47],\n",
       "         [ 52,  46,  49],\n",
       "         [ 51,  45,  48],\n",
       "         ...,\n",
       "         [128, 137, 143],\n",
       "         [129, 138, 144],\n",
       "         [129, 138, 144]],\n",
       " \n",
       "        [[ 50,  44,  47],\n",
       "         [ 52,  46,  49],\n",
       "         [ 49,  43,  46],\n",
       "         ...,\n",
       "         [125, 134, 140],\n",
       "         [127, 136, 142],\n",
       "         [127, 136, 142]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 1.9936561584472656, 'inference': 4.98652458190918, 'postprocess': 0.9930133819580078},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         ...,\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179]],\n",
       " \n",
       "        [[114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         ...,\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179]],\n",
       " \n",
       "        [[113, 119, 128],\n",
       "         [113, 119, 128],\n",
       "         [113, 119, 128],\n",
       "         ...,\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 48,  44,  47],\n",
       "         [ 47,  43,  46],\n",
       "         [ 49,  43,  46],\n",
       "         ...,\n",
       "         [139, 148, 154],\n",
       "         [135, 144, 150],\n",
       "         [133, 142, 148]],\n",
       " \n",
       "        [[ 47,  43,  46],\n",
       "         [ 48,  44,  47],\n",
       "         [ 50,  44,  47],\n",
       "         ...,\n",
       "         [132, 141, 147],\n",
       "         [132, 141, 147],\n",
       "         [131, 140, 146]],\n",
       " \n",
       "        [[ 46,  42,  45],\n",
       "         [ 49,  45,  48],\n",
       "         [ 52,  46,  49],\n",
       "         ...,\n",
       "         [122, 131, 137],\n",
       "         [127, 136, 142],\n",
       "         [128, 137, 143]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9968280792236328, 'inference': 4.983425140380859, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         [114, 120, 129],\n",
       "         ...,\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179]],\n",
       " \n",
       "        [[113, 119, 128],\n",
       "         [113, 119, 128],\n",
       "         [113, 119, 128],\n",
       "         ...,\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179]],\n",
       " \n",
       "        [[113, 119, 128],\n",
       "         [113, 119, 128],\n",
       "         [113, 119, 128],\n",
       "         ...,\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 59,  55,  58],\n",
       "         [ 57,  53,  56],\n",
       "         [ 53,  49,  52],\n",
       "         ...,\n",
       "         [139, 148, 154],\n",
       "         [135, 144, 150],\n",
       "         [133, 142, 148]],\n",
       " \n",
       "        [[ 61,  57,  60],\n",
       "         [ 59,  55,  58],\n",
       "         [ 50,  46,  49],\n",
       "         ...,\n",
       "         [132, 141, 147],\n",
       "         [132, 141, 147],\n",
       "         [131, 140, 146]],\n",
       " \n",
       "        [[ 60,  56,  59],\n",
       "         [ 55,  51,  54],\n",
       "         [ 48,  44,  47],\n",
       "         ...,\n",
       "         [122, 131, 137],\n",
       "         [127, 136, 142],\n",
       "         [128, 137, 143]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9968280792236328, 'inference': 5.980014801025391, 'postprocess': 0.9961128234863281},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[113, 119, 128],\n",
       "         [113, 119, 128],\n",
       "         [113, 119, 128],\n",
       "         ...,\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179]],\n",
       " \n",
       "        [[113, 119, 128],\n",
       "         [113, 119, 128],\n",
       "         [113, 119, 128],\n",
       "         ...,\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179]],\n",
       " \n",
       "        [[112, 118, 127],\n",
       "         [112, 118, 127],\n",
       "         [113, 119, 128],\n",
       "         ...,\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 54,  48,  51],\n",
       "         [ 48,  42,  45],\n",
       "         [ 50,  44,  47],\n",
       "         ...,\n",
       "         [140, 149, 155],\n",
       "         [140, 149, 155],\n",
       "         [138, 147, 153]],\n",
       " \n",
       "        [[ 49,  45,  48],\n",
       "         [ 46,  42,  45],\n",
       "         [ 50,  46,  49],\n",
       "         ...,\n",
       "         [136, 145, 151],\n",
       "         [135, 144, 150],\n",
       "         [134, 143, 149]],\n",
       " \n",
       "        [[ 48,  44,  47],\n",
       "         [ 48,  44,  47],\n",
       "         [ 52,  48,  51],\n",
       "         ...,\n",
       "         [120, 129, 135],\n",
       "         [124, 133, 139],\n",
       "         [126, 135, 141]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9970664978027344, 'inference': 3.9856433868408203, 'postprocess': 0.9963512420654297},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[113, 119, 128],\n",
       "         [113, 119, 128],\n",
       "         [113, 119, 128],\n",
       "         ...,\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179]],\n",
       " \n",
       "        [[113, 119, 128],\n",
       "         [113, 119, 128],\n",
       "         [113, 119, 128],\n",
       "         ...,\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179]],\n",
       " \n",
       "        [[112, 118, 127],\n",
       "         [112, 118, 127],\n",
       "         [113, 119, 128],\n",
       "         ...,\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 48,  42,  45],\n",
       "         [ 57,  51,  54],\n",
       "         [ 63,  57,  60],\n",
       "         ...,\n",
       "         [140, 149, 155],\n",
       "         [140, 149, 155],\n",
       "         [140, 149, 155]],\n",
       " \n",
       "        [[ 48,  44,  47],\n",
       "         [ 56,  52,  55],\n",
       "         [ 59,  55,  58],\n",
       "         ...,\n",
       "         [136, 145, 151],\n",
       "         [136, 145, 151],\n",
       "         [135, 144, 150]],\n",
       " \n",
       "        [[ 50,  46,  49],\n",
       "         [ 56,  52,  55],\n",
       "         [ 57,  53,  56],\n",
       "         ...,\n",
       "         [119, 128, 134],\n",
       "         [121, 130, 136],\n",
       "         [125, 134, 140]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9996891021728516, 'inference': 3.9861202239990234, 'postprocess': 0.9965896606445312},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[113, 119, 128],\n",
       "         [113, 119, 128],\n",
       "         [113, 119, 128],\n",
       "         ...,\n",
       "         [167, 176, 177],\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179]],\n",
       " \n",
       "        [[112, 118, 127],\n",
       "         [112, 118, 127],\n",
       "         [113, 119, 128],\n",
       "         ...,\n",
       "         [167, 176, 177],\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179]],\n",
       " \n",
       "        [[112, 118, 127],\n",
       "         [112, 118, 127],\n",
       "         [112, 118, 127],\n",
       "         ...,\n",
       "         [170, 179, 180],\n",
       "         [170, 179, 180],\n",
       "         [169, 178, 179]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 53,  49,  52],\n",
       "         [ 50,  46,  49],\n",
       "         [ 48,  44,  47],\n",
       "         ...,\n",
       "         [136, 145, 151],\n",
       "         [140, 149, 155],\n",
       "         [140, 149, 155]],\n",
       " \n",
       "        [[ 53,  49,  52],\n",
       "         [ 50,  46,  49],\n",
       "         [ 48,  44,  47],\n",
       "         ...,\n",
       "         [128, 137, 143],\n",
       "         [135, 144, 150],\n",
       "         [136, 145, 151]],\n",
       " \n",
       "        [[ 53,  49,  52],\n",
       "         [ 50,  46,  49],\n",
       "         [ 48,  44,  47],\n",
       "         ...,\n",
       "         [110, 119, 125],\n",
       "         [117, 126, 132],\n",
       "         [120, 129, 135]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9961128234863281, 'inference': 3.9873123168945312, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[113, 119, 128],\n",
       "         [113, 119, 128],\n",
       "         [113, 119, 128],\n",
       "         ...,\n",
       "         [166, 175, 176],\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179]],\n",
       " \n",
       "        [[112, 118, 127],\n",
       "         [112, 118, 127],\n",
       "         [112, 118, 127],\n",
       "         ...,\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177],\n",
       "         [169, 178, 179]],\n",
       " \n",
       "        [[112, 118, 127],\n",
       "         [112, 118, 127],\n",
       "         [112, 118, 127],\n",
       "         ...,\n",
       "         [170, 179, 180],\n",
       "         [170, 179, 180],\n",
       "         [170, 179, 180]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 48,  44,  47],\n",
       "         [ 53,  49,  52],\n",
       "         [ 61,  55,  58],\n",
       "         ...,\n",
       "         [133, 142, 148],\n",
       "         [140, 149, 155],\n",
       "         [141, 150, 156]],\n",
       " \n",
       "        [[ 48,  44,  47],\n",
       "         [ 53,  49,  52],\n",
       "         [ 61,  55,  58],\n",
       "         ...,\n",
       "         [117, 126, 132],\n",
       "         [124, 133, 139],\n",
       "         [128, 137, 143]],\n",
       " \n",
       "        [[ 48,  44,  47],\n",
       "         [ 53,  49,  52],\n",
       "         [ 61,  55,  58],\n",
       "         ...,\n",
       "         [106, 115, 121],\n",
       "         [113, 122, 128],\n",
       "         [118, 127, 133]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9965896606445312, 'inference': 3.9873123168945312, 'postprocess': 0.9958744049072266},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[113, 119, 128],\n",
       "         [113, 119, 128],\n",
       "         [113, 119, 128],\n",
       "         ...,\n",
       "         [167, 176, 177],\n",
       "         [166, 175, 176],\n",
       "         [167, 176, 177]],\n",
       " \n",
       "        [[112, 118, 127],\n",
       "         [112, 118, 127],\n",
       "         [112, 118, 127],\n",
       "         ...,\n",
       "         [167, 176, 177],\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179]],\n",
       " \n",
       "        [[112, 118, 127],\n",
       "         [112, 118, 127],\n",
       "         [112, 118, 127],\n",
       "         ...,\n",
       "         [167, 176, 177],\n",
       "         [170, 179, 180],\n",
       "         [170, 179, 180]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 49,  43,  46],\n",
       "         [ 49,  43,  46],\n",
       "         [ 48,  42,  45],\n",
       "         ...,\n",
       "         [122, 131, 137],\n",
       "         [128, 137, 143],\n",
       "         [135, 144, 150]],\n",
       " \n",
       "        [[ 49,  43,  46],\n",
       "         [ 49,  43,  46],\n",
       "         [ 48,  42,  45],\n",
       "         ...,\n",
       "         [108, 117, 123],\n",
       "         [112, 121, 127],\n",
       "         [119, 128, 134]],\n",
       " \n",
       "        [[ 49,  43,  46],\n",
       "         [ 49,  43,  46],\n",
       "         [ 48,  42,  45],\n",
       "         ...,\n",
       "         [104, 113, 119],\n",
       "         [105, 114, 120],\n",
       "         [108, 117, 123]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9965896606445312, 'inference': 3.9861202239990234, 'postprocess': 0.9965896606445312},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[115, 121, 125],\n",
       "         [115, 121, 125],\n",
       "         [115, 121, 125],\n",
       "         ...,\n",
       "         [169, 179, 183],\n",
       "         [169, 179, 183],\n",
       "         [169, 179, 183]],\n",
       " \n",
       "        [[115, 121, 125],\n",
       "         [115, 121, 125],\n",
       "         [115, 121, 125],\n",
       "         ...,\n",
       "         [169, 179, 183],\n",
       "         [169, 179, 183],\n",
       "         [169, 179, 183]],\n",
       " \n",
       "        [[112, 118, 122],\n",
       "         [112, 118, 122],\n",
       "         [114, 120, 124],\n",
       "         ...,\n",
       "         [169, 179, 183],\n",
       "         [169, 179, 183],\n",
       "         [169, 179, 183]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 48,  42,  45],\n",
       "         [ 48,  42,  45],\n",
       "         [ 48,  42,  45],\n",
       "         ...,\n",
       "         [120, 128, 132],\n",
       "         [122, 130, 134],\n",
       "         [115, 123, 127]],\n",
       " \n",
       "        [[ 47,  41,  44],\n",
       "         [ 47,  41,  44],\n",
       "         [ 47,  41,  44],\n",
       "         ...,\n",
       "         [103, 111, 115],\n",
       "         [107, 115, 119],\n",
       "         [ 99, 107, 111]],\n",
       " \n",
       "        [[ 47,  41,  44],\n",
       "         [ 47,  41,  44],\n",
       "         [ 47,  41,  44],\n",
       "         ...,\n",
       "         [ 91,  99, 103],\n",
       "         [ 94, 102, 106],\n",
       "         [ 88,  96, 100]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 1.0378360748291016, 'inference': 7.931947708129883, 'postprocess': 1.9931793212890625},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[115, 121, 125],\n",
       "         [115, 121, 125],\n",
       "         [115, 121, 125],\n",
       "         ...,\n",
       "         [169, 179, 183],\n",
       "         [169, 179, 183],\n",
       "         [169, 179, 183]],\n",
       " \n",
       "        [[112, 118, 122],\n",
       "         [112, 118, 122],\n",
       "         [114, 120, 124],\n",
       "         ...,\n",
       "         [169, 179, 183],\n",
       "         [169, 179, 183],\n",
       "         [169, 179, 183]],\n",
       " \n",
       "        [[112, 118, 122],\n",
       "         [112, 118, 122],\n",
       "         [114, 120, 124],\n",
       "         ...,\n",
       "         [169, 179, 183],\n",
       "         [169, 179, 183],\n",
       "         [169, 179, 183]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 54,  48,  51],\n",
       "         [ 54,  48,  51],\n",
       "         [ 52,  46,  49],\n",
       "         ...,\n",
       "         [103, 111, 115],\n",
       "         [114, 122, 126],\n",
       "         [112, 120, 124]],\n",
       " \n",
       "        [[ 54,  48,  51],\n",
       "         [ 54,  48,  51],\n",
       "         [ 52,  46,  49],\n",
       "         ...,\n",
       "         [ 85,  93,  97],\n",
       "         [ 98, 106, 110],\n",
       "         [ 98, 106, 110]],\n",
       " \n",
       "        [[ 54,  48,  51],\n",
       "         [ 54,  48,  51],\n",
       "         [ 52,  46,  49],\n",
       "         ...,\n",
       "         [ 79,  87,  91],\n",
       "         [ 92, 100, 104],\n",
       "         [ 92, 100, 104]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 1.9881725311279297, 'inference': 6.981611251831055, 'postprocess': 1.9922256469726562},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[115, 121, 125],\n",
       "         [115, 121, 125],\n",
       "         [115, 121, 125],\n",
       "         ...,\n",
       "         [169, 179, 183],\n",
       "         [169, 179, 183],\n",
       "         [169, 179, 183]],\n",
       " \n",
       "        [[112, 118, 122],\n",
       "         [112, 118, 122],\n",
       "         [114, 120, 124],\n",
       "         ...,\n",
       "         [169, 179, 183],\n",
       "         [169, 179, 183],\n",
       "         [169, 179, 183]],\n",
       " \n",
       "        [[112, 118, 122],\n",
       "         [112, 118, 122],\n",
       "         [114, 120, 124],\n",
       "         ...,\n",
       "         [169, 179, 183],\n",
       "         [169, 179, 183],\n",
       "         [169, 179, 183]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 56,  50,  53],\n",
       "         [ 56,  50,  53],\n",
       "         [ 56,  50,  53],\n",
       "         ...,\n",
       "         [101, 109, 113],\n",
       "         [101, 109, 113],\n",
       "         [109, 117, 121]],\n",
       " \n",
       "        [[ 55,  49,  52],\n",
       "         [ 55,  49,  52],\n",
       "         [ 55,  49,  52],\n",
       "         ...,\n",
       "         [ 93, 101, 105],\n",
       "         [ 85,  93,  97],\n",
       "         [ 91,  99, 103]],\n",
       " \n",
       "        [[ 55,  49,  52],\n",
       "         [ 55,  49,  52],\n",
       "         [ 55,  49,  52],\n",
       "         ...,\n",
       "         [ 93, 101, 105],\n",
       "         [ 80,  88,  92],\n",
       "         [ 85,  93,  97]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9968280792236328, 'inference': 7.972478866577148, 'postprocess': 1.9936561584472656},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[114, 120, 124],\n",
       "         [114, 120, 124],\n",
       "         [114, 120, 124],\n",
       "         ...,\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180]],\n",
       " \n",
       "        [[112, 118, 122],\n",
       "         [112, 118, 122],\n",
       "         [114, 120, 124],\n",
       "         ...,\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180]],\n",
       " \n",
       "        [[111, 117, 121],\n",
       "         [111, 117, 121],\n",
       "         [111, 117, 121],\n",
       "         ...,\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 56,  50,  53],\n",
       "         [ 56,  50,  53],\n",
       "         [ 56,  50,  53],\n",
       "         ...,\n",
       "         [ 95, 103, 107],\n",
       "         [ 92, 100, 104],\n",
       "         [ 92, 100, 104]],\n",
       " \n",
       "        [[ 55,  49,  52],\n",
       "         [ 55,  49,  52],\n",
       "         [ 55,  49,  52],\n",
       "         ...,\n",
       "         [ 98, 106, 110],\n",
       "         [ 88,  96, 100],\n",
       "         [ 84,  92,  96]],\n",
       " \n",
       "        [[ 55,  49,  52],\n",
       "         [ 55,  49,  52],\n",
       "         [ 55,  49,  52],\n",
       "         ...,\n",
       "         [101, 109, 113],\n",
       "         [ 91,  99, 103],\n",
       "         [ 82,  90,  94]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9946823120117188, 'inference': 3.9870738983154297, 'postprocess': 1.989603042602539},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[114, 120, 124],\n",
       "         [114, 120, 124],\n",
       "         [114, 120, 124],\n",
       "         ...,\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180]],\n",
       " \n",
       "        [[112, 118, 122],\n",
       "         [112, 118, 122],\n",
       "         [114, 120, 124],\n",
       "         ...,\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180]],\n",
       " \n",
       "        [[111, 117, 121],\n",
       "         [111, 117, 121],\n",
       "         [111, 117, 121],\n",
       "         ...,\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 61,  55,  58],\n",
       "         [ 61,  55,  58],\n",
       "         [ 61,  55,  58],\n",
       "         ...,\n",
       "         [ 96, 104, 108],\n",
       "         [ 94, 102, 106],\n",
       "         [ 92, 100, 104]],\n",
       " \n",
       "        [[ 61,  55,  58],\n",
       "         [ 61,  55,  58],\n",
       "         [ 61,  55,  58],\n",
       "         ...,\n",
       "         [105, 113, 117],\n",
       "         [ 95, 103, 107],\n",
       "         [ 87,  95,  99]],\n",
       " \n",
       "        [[ 59,  53,  56],\n",
       "         [ 59,  53,  56],\n",
       "         [ 59,  53,  56],\n",
       "         ...,\n",
       "         [108, 116, 120],\n",
       "         [ 99, 107, 111],\n",
       "         [ 88,  96, 100]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9961128234863281, 'inference': 3.986835479736328, 'postprocess': 0.9968280792236328},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[114, 120, 124],\n",
       "         [114, 120, 124],\n",
       "         [114, 120, 124],\n",
       "         ...,\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180]],\n",
       " \n",
       "        [[112, 118, 122],\n",
       "         [112, 118, 122],\n",
       "         [112, 118, 122],\n",
       "         ...,\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180]],\n",
       " \n",
       "        [[110, 116, 120],\n",
       "         [110, 116, 120],\n",
       "         [109, 115, 119],\n",
       "         ...,\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 61,  55,  58],\n",
       "         [ 61,  55,  58],\n",
       "         [ 61,  55,  58],\n",
       "         ...,\n",
       "         [ 98, 106, 110],\n",
       "         [ 96, 104, 108],\n",
       "         [ 95, 103, 107]],\n",
       " \n",
       "        [[ 61,  55,  58],\n",
       "         [ 61,  55,  58],\n",
       "         [ 61,  55,  58],\n",
       "         ...,\n",
       "         [107, 115, 119],\n",
       "         [105, 113, 117],\n",
       "         [ 98, 106, 110]],\n",
       " \n",
       "        [[ 59,  53,  56],\n",
       "         [ 59,  53,  56],\n",
       "         [ 59,  53,  56],\n",
       "         ...,\n",
       "         [119, 127, 131],\n",
       "         [110, 118, 122],\n",
       "         [101, 109, 113]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9958744049072266, 'inference': 4.9839019775390625, 'postprocess': 0.9963512420654297},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[114, 120, 124],\n",
       "         [114, 120, 124],\n",
       "         [114, 120, 124],\n",
       "         ...,\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180]],\n",
       " \n",
       "        [[111, 117, 121],\n",
       "         [111, 117, 121],\n",
       "         [110, 116, 120],\n",
       "         ...,\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180]],\n",
       " \n",
       "        [[105, 111, 115],\n",
       "         [105, 111, 115],\n",
       "         [105, 111, 115],\n",
       "         ...,\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 61,  55,  58],\n",
       "         [ 61,  55,  58],\n",
       "         [ 61,  55,  58],\n",
       "         ...,\n",
       "         [ 99, 107, 111],\n",
       "         [ 96, 104, 108],\n",
       "         [ 95, 103, 107]],\n",
       " \n",
       "        [[ 61,  55,  58],\n",
       "         [ 61,  55,  58],\n",
       "         [ 61,  55,  58],\n",
       "         ...,\n",
       "         [107, 115, 119],\n",
       "         [106, 114, 118],\n",
       "         [100, 108, 112]],\n",
       " \n",
       "        [[ 59,  53,  56],\n",
       "         [ 59,  53,  56],\n",
       "         [ 59,  53,  56],\n",
       "         ...,\n",
       "         [120, 128, 132],\n",
       "         [113, 121, 125],\n",
       "         [103, 111, 115]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9975433349609375, 'inference': 3.9865970611572266, 'postprocess': 0.9968280792236328},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[114, 120, 124],\n",
       "         [114, 120, 124],\n",
       "         [114, 120, 124],\n",
       "         ...,\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180]],\n",
       " \n",
       "        [[111, 117, 121],\n",
       "         [111, 117, 121],\n",
       "         [110, 116, 120],\n",
       "         ...,\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180]],\n",
       " \n",
       "        [[105, 111, 115],\n",
       "         [105, 111, 115],\n",
       "         [105, 111, 115],\n",
       "         ...,\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 61,  55,  58],\n",
       "         [ 61,  55,  58],\n",
       "         [ 61,  55,  58],\n",
       "         ...,\n",
       "         [102, 110, 114],\n",
       "         [ 99, 107, 111],\n",
       "         [ 96, 104, 108]],\n",
       " \n",
       "        [[ 61,  55,  58],\n",
       "         [ 61,  55,  58],\n",
       "         [ 61,  55,  58],\n",
       "         ...,\n",
       "         [109, 117, 121],\n",
       "         [107, 115, 119],\n",
       "         [105, 113, 117]],\n",
       " \n",
       "        [[ 59,  53,  56],\n",
       "         [ 59,  53,  56],\n",
       "         [ 59,  53,  56],\n",
       "         ...,\n",
       "         [123, 131, 135],\n",
       "         [119, 127, 131],\n",
       "         [110, 118, 122]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9965896606445312, 'inference': 7.353067398071289, 'postprocess': 0.9965896606445312},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[111, 117, 121],\n",
       "         [111, 117, 121],\n",
       "         [110, 116, 120],\n",
       "         ...,\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180]],\n",
       " \n",
       "        [[105, 111, 115],\n",
       "         [105, 111, 115],\n",
       "         [105, 111, 115],\n",
       "         ...,\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180]],\n",
       " \n",
       "        [[101, 107, 111],\n",
       "         [101, 107, 111],\n",
       "         [102, 108, 112],\n",
       "         ...,\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 59,  53,  56],\n",
       "         [ 59,  53,  56],\n",
       "         [ 59,  53,  56],\n",
       "         ...,\n",
       "         [105, 113, 117],\n",
       "         [102, 110, 114],\n",
       "         [ 99, 107, 111]],\n",
       " \n",
       "        [[ 59,  53,  56],\n",
       "         [ 59,  53,  56],\n",
       "         [ 59,  53,  56],\n",
       "         ...,\n",
       "         [113, 121, 125],\n",
       "         [109, 117, 121],\n",
       "         [107, 115, 119]],\n",
       " \n",
       "        [[ 59,  53,  56],\n",
       "         [ 59,  53,  56],\n",
       "         [ 59,  53,  56],\n",
       "         ...,\n",
       "         [128, 136, 140],\n",
       "         [123, 131, 135],\n",
       "         [119, 127, 131]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9975433349609375, 'inference': 4.982948303222656, 'postprocess': 0.995635986328125},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[111, 117, 121],\n",
       "         [111, 117, 121],\n",
       "         [110, 116, 120],\n",
       "         ...,\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180]],\n",
       " \n",
       "        [[105, 111, 115],\n",
       "         [105, 111, 115],\n",
       "         [105, 111, 115],\n",
       "         ...,\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180]],\n",
       " \n",
       "        [[101, 107, 111],\n",
       "         [101, 107, 111],\n",
       "         [102, 108, 112],\n",
       "         ...,\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 59,  53,  56],\n",
       "         [ 59,  53,  56],\n",
       "         [ 59,  53,  56],\n",
       "         ...,\n",
       "         [114, 122, 126],\n",
       "         [107, 115, 119],\n",
       "         [103, 111, 115]],\n",
       " \n",
       "        [[ 59,  53,  56],\n",
       "         [ 59,  53,  56],\n",
       "         [ 59,  53,  56],\n",
       "         ...,\n",
       "         [127, 135, 139],\n",
       "         [116, 124, 128],\n",
       "         [110, 118, 122]],\n",
       " \n",
       "        [[ 59,  53,  56],\n",
       "         [ 59,  53,  56],\n",
       "         [ 59,  53,  56],\n",
       "         ...,\n",
       "         [135, 143, 147],\n",
       "         [130, 138, 142],\n",
       "         [126, 134, 138]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9961128234863281, 'inference': 3.987550735473633, 'postprocess': 0.9975433349609375},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[103, 109, 113],\n",
       "         [103, 109, 113],\n",
       "         [103, 109, 113],\n",
       "         ...,\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180]],\n",
       " \n",
       "        [[100, 106, 110],\n",
       "         [100, 106, 110],\n",
       "         [101, 107, 111],\n",
       "         ...,\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180]],\n",
       " \n",
       "        [[100, 106, 110],\n",
       "         [100, 106, 110],\n",
       "         [100, 106, 110],\n",
       "         ...,\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 59,  53,  56],\n",
       "         [ 59,  53,  56],\n",
       "         [ 59,  53,  56],\n",
       "         ...,\n",
       "         [124, 132, 136],\n",
       "         [114, 122, 126],\n",
       "         [108, 116, 120]],\n",
       " \n",
       "        [[ 59,  53,  56],\n",
       "         [ 59,  53,  56],\n",
       "         [ 59,  53,  56],\n",
       "         ...,\n",
       "         [134, 142, 146],\n",
       "         [128, 136, 140],\n",
       "         [122, 130, 134]],\n",
       " \n",
       "        [[ 59,  53,  56],\n",
       "         [ 59,  53,  56],\n",
       "         [ 59,  53,  56],\n",
       "         ...,\n",
       "         [136, 144, 148],\n",
       "         [131, 139, 143],\n",
       "         [127, 135, 139]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9965896606445312, 'inference': 3.9861202239990234, 'postprocess': 0.9968280792236328},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[103, 109, 113],\n",
       "         [103, 109, 113],\n",
       "         [103, 109, 113],\n",
       "         ...,\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180]],\n",
       " \n",
       "        [[100, 106, 110],\n",
       "         [100, 106, 110],\n",
       "         [101, 107, 111],\n",
       "         ...,\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180]],\n",
       " \n",
       "        [[100, 106, 110],\n",
       "         [100, 106, 110],\n",
       "         [100, 106, 110],\n",
       "         ...,\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 59,  53,  56],\n",
       "         [ 59,  53,  56],\n",
       "         [ 59,  53,  56],\n",
       "         ...,\n",
       "         [136, 144, 148],\n",
       "         [130, 138, 142],\n",
       "         [120, 128, 132]],\n",
       " \n",
       "        [[ 59,  53,  56],\n",
       "         [ 59,  53,  56],\n",
       "         [ 59,  53,  56],\n",
       "         ...,\n",
       "         [140, 148, 152],\n",
       "         [136, 144, 148],\n",
       "         [131, 139, 143]],\n",
       " \n",
       "        [[ 59,  53,  56],\n",
       "         [ 59,  53,  56],\n",
       "         [ 59,  53,  56],\n",
       "         ...,\n",
       "         [140, 148, 152],\n",
       "         [137, 145, 149],\n",
       "         [133, 141, 145]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 1.0004043579101562, 'inference': 6.972312927246094, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[103, 109, 113],\n",
       "         [103, 109, 113],\n",
       "         [103, 109, 113],\n",
       "         ...,\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180]],\n",
       " \n",
       "        [[100, 106, 110],\n",
       "         [100, 106, 110],\n",
       "         [101, 107, 111],\n",
       "         ...,\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180]],\n",
       " \n",
       "        [[100, 106, 110],\n",
       "         [100, 106, 110],\n",
       "         [100, 106, 110],\n",
       "         ...,\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 54,  50,  53],\n",
       "         [ 54,  50,  53],\n",
       "         [ 54,  50,  53],\n",
       "         ...,\n",
       "         [136, 144, 148],\n",
       "         [130, 138, 142],\n",
       "         [120, 128, 132]],\n",
       " \n",
       "        [[ 54,  50,  53],\n",
       "         [ 54,  50,  53],\n",
       "         [ 54,  50,  53],\n",
       "         ...,\n",
       "         [140, 148, 152],\n",
       "         [136, 144, 148],\n",
       "         [131, 139, 143]],\n",
       " \n",
       "        [[ 54,  50,  53],\n",
       "         [ 54,  50,  53],\n",
       "         [ 54,  50,  53],\n",
       "         ...,\n",
       "         [140, 148, 152],\n",
       "         [137, 145, 149],\n",
       "         [133, 141, 145]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9963512420654297, 'inference': 3.9985179901123047, 'postprocess': 0.9927749633789062},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[100, 106, 110],\n",
       "         [100, 106, 110],\n",
       "         [101, 107, 111],\n",
       "         ...,\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180]],\n",
       " \n",
       "        [[100, 106, 110],\n",
       "         [100, 106, 110],\n",
       "         [100, 106, 110],\n",
       "         ...,\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180]],\n",
       " \n",
       "        [[101, 107, 111],\n",
       "         [101, 107, 111],\n",
       "         [101, 107, 111],\n",
       "         ...,\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180],\n",
       "         [169, 181, 180]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 54,  50,  53],\n",
       "         [ 54,  50,  53],\n",
       "         [ 54,  50,  53],\n",
       "         ...,\n",
       "         [141, 149, 153],\n",
       "         [136, 144, 148],\n",
       "         [130, 138, 142]],\n",
       " \n",
       "        [[ 54,  50,  53],\n",
       "         [ 54,  50,  53],\n",
       "         [ 54,  50,  53],\n",
       "         ...,\n",
       "         [145, 153, 157],\n",
       "         [140, 148, 152],\n",
       "         [136, 144, 148]],\n",
       " \n",
       "        [[ 54,  50,  53],\n",
       "         [ 54,  50,  53],\n",
       "         [ 54,  50,  53],\n",
       "         ...,\n",
       "         [145, 153, 157],\n",
       "         [140, 148, 152],\n",
       "         [137, 145, 149]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9963512420654297, 'inference': 4.759311676025391, 'postprocess': 0.9965896606445312},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[100, 106, 110],\n",
       "         [100, 106, 110],\n",
       "         [100, 106, 110],\n",
       "         ...,\n",
       "         [173, 180, 181],\n",
       "         [171, 181, 180],\n",
       "         [171, 181, 180]],\n",
       " \n",
       "        [[100, 106, 110],\n",
       "         [100, 106, 110],\n",
       "         [ 98, 104, 108],\n",
       "         ...,\n",
       "         [173, 180, 181],\n",
       "         [171, 181, 180],\n",
       "         [171, 181, 180]],\n",
       " \n",
       "        [[101, 107, 111],\n",
       "         [101, 107, 111],\n",
       "         [100, 106, 110],\n",
       "         ...,\n",
       "         [173, 180, 181],\n",
       "         [171, 181, 180],\n",
       "         [171, 181, 180]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 54,  50,  53],\n",
       "         [ 54,  50,  53],\n",
       "         [ 54,  50,  53],\n",
       "         ...,\n",
       "         [152, 160, 164],\n",
       "         [147, 155, 159],\n",
       "         [141, 149, 153]],\n",
       " \n",
       "        [[ 54,  50,  53],\n",
       "         [ 54,  50,  53],\n",
       "         [ 54,  50,  53],\n",
       "         ...,\n",
       "         [156, 164, 168],\n",
       "         [150, 158, 162],\n",
       "         [145, 153, 157]],\n",
       " \n",
       "        [[ 54,  50,  53],\n",
       "         [ 54,  50,  53],\n",
       "         [ 54,  50,  53],\n",
       "         ...,\n",
       "         [155, 163, 167],\n",
       "         [150, 158, 162],\n",
       "         [145, 153, 157]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9968280792236328, 'inference': 5.979299545288086, 'postprocess': 0.9963512420654297},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[100, 106, 110],\n",
       "         [100, 106, 110],\n",
       "         [100, 106, 110],\n",
       "         ...,\n",
       "         [173, 180, 181],\n",
       "         [171, 181, 180],\n",
       "         [171, 181, 180]],\n",
       " \n",
       "        [[100, 106, 110],\n",
       "         [100, 106, 110],\n",
       "         [ 98, 104, 108],\n",
       "         ...,\n",
       "         [173, 180, 181],\n",
       "         [171, 181, 180],\n",
       "         [171, 181, 180]],\n",
       " \n",
       "        [[101, 107, 111],\n",
       "         [101, 107, 111],\n",
       "         [100, 106, 110],\n",
       "         ...,\n",
       "         [173, 180, 181],\n",
       "         [171, 181, 180],\n",
       "         [171, 181, 180]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 54,  50,  53],\n",
       "         [ 54,  50,  53],\n",
       "         [ 54,  50,  53],\n",
       "         ...,\n",
       "         [152, 160, 164],\n",
       "         [147, 155, 159],\n",
       "         [141, 149, 153]],\n",
       " \n",
       "        [[ 54,  50,  53],\n",
       "         [ 54,  50,  53],\n",
       "         [ 54,  50,  53],\n",
       "         ...,\n",
       "         [156, 164, 168],\n",
       "         [150, 158, 162],\n",
       "         [145, 153, 157]],\n",
       " \n",
       "        [[ 54,  50,  53],\n",
       "         [ 54,  50,  53],\n",
       "         [ 54,  50,  53],\n",
       "         ...,\n",
       "         [155, 163, 167],\n",
       "         [150, 158, 162],\n",
       "         [145, 153, 157]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9953975677490234, 'inference': 5.976438522338867, 'postprocess': 0.9968280792236328},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[100, 106, 110],\n",
       "         [100, 106, 110],\n",
       "         [ 98, 104, 108],\n",
       "         ...,\n",
       "         [173, 180, 181],\n",
       "         [171, 181, 180],\n",
       "         [171, 181, 180]],\n",
       " \n",
       "        [[101, 107, 111],\n",
       "         [101, 107, 111],\n",
       "         [100, 106, 110],\n",
       "         ...,\n",
       "         [173, 180, 181],\n",
       "         [171, 181, 180],\n",
       "         [171, 181, 180]],\n",
       " \n",
       "        [[104, 110, 114],\n",
       "         [104, 110, 114],\n",
       "         [103, 109, 113],\n",
       "         ...,\n",
       "         [173, 180, 181],\n",
       "         [171, 181, 180],\n",
       "         [171, 181, 180]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 55,  51,  54],\n",
       "         [ 55,  51,  54],\n",
       "         [ 55,  51,  54],\n",
       "         ...,\n",
       "         [158, 166, 170],\n",
       "         [152, 160, 164],\n",
       "         [145, 153, 157]],\n",
       " \n",
       "        [[ 54,  50,  53],\n",
       "         [ 54,  50,  53],\n",
       "         [ 54,  50,  53],\n",
       "         ...,\n",
       "         [158, 166, 170],\n",
       "         [152, 160, 164],\n",
       "         [148, 156, 160]],\n",
       " \n",
       "        [[ 54,  50,  53],\n",
       "         [ 54,  50,  53],\n",
       "         [ 54,  50,  53],\n",
       "         ...,\n",
       "         [157, 165, 169],\n",
       "         [152, 160, 164],\n",
       "         [148, 156, 160]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9918212890625, 'inference': 3.989696502685547, 'postprocess': 0.9927749633789062},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[100, 106, 110],\n",
       "         [100, 106, 110],\n",
       "         [ 98, 104, 108],\n",
       "         ...,\n",
       "         [173, 179, 183],\n",
       "         [173, 179, 183],\n",
       "         [173, 179, 183]],\n",
       " \n",
       "        [[101, 107, 111],\n",
       "         [101, 107, 111],\n",
       "         [100, 106, 110],\n",
       "         ...,\n",
       "         [173, 179, 183],\n",
       "         [173, 179, 183],\n",
       "         [173, 179, 183]],\n",
       " \n",
       "        [[104, 110, 114],\n",
       "         [104, 110, 114],\n",
       "         [103, 109, 113],\n",
       "         ...,\n",
       "         [173, 179, 183],\n",
       "         [173, 179, 183],\n",
       "         [173, 179, 183]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 61,  57,  60],\n",
       "         [ 61,  57,  60],\n",
       "         [ 61,  57,  60],\n",
       "         ...,\n",
       "         [163, 171, 175],\n",
       "         [158, 166, 170],\n",
       "         [152, 160, 164]],\n",
       " \n",
       "        [[ 60,  56,  59],\n",
       "         [ 60,  56,  59],\n",
       "         [ 60,  56,  59],\n",
       "         ...,\n",
       "         [161, 169, 173],\n",
       "         [158, 166, 170],\n",
       "         [152, 160, 164]],\n",
       " \n",
       "        [[ 57,  53,  56],\n",
       "         [ 57,  53,  56],\n",
       "         [ 57,  53,  56],\n",
       "         ...,\n",
       "         [161, 169, 173],\n",
       "         [157, 165, 169],\n",
       "         [152, 160, 164]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 1.0020732879638672, 'inference': 5.974531173706055, 'postprocess': 0.9968280792236328},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[ 94, 100, 104],\n",
       "         [ 94, 100, 104],\n",
       "         [ 94, 100, 104],\n",
       "         ...,\n",
       "         [173, 179, 183],\n",
       "         [173, 179, 183],\n",
       "         [173, 179, 183]],\n",
       " \n",
       "        [[ 95, 101, 105],\n",
       "         [ 95, 101, 105],\n",
       "         [ 95, 101, 105],\n",
       "         ...,\n",
       "         [173, 179, 183],\n",
       "         [173, 179, 183],\n",
       "         [173, 179, 183]],\n",
       " \n",
       "        [[100, 106, 110],\n",
       "         [100, 106, 110],\n",
       "         [100, 106, 110],\n",
       "         ...,\n",
       "         [173, 179, 183],\n",
       "         [173, 179, 183],\n",
       "         [173, 179, 183]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 61,  63,  65],\n",
       "         [ 61,  63,  65],\n",
       "         [ 61,  63,  65],\n",
       "         ...,\n",
       "         [162, 170, 174],\n",
       "         [163, 171, 175],\n",
       "         [162, 170, 174]],\n",
       " \n",
       "        [[ 60,  59,  61],\n",
       "         [ 60,  59,  61],\n",
       "         [ 60,  59,  61],\n",
       "         ...,\n",
       "         [161, 169, 173],\n",
       "         [161, 169, 173],\n",
       "         [161, 169, 173]],\n",
       " \n",
       "        [[ 64,  63,  65],\n",
       "         [ 64,  63,  65],\n",
       "         [ 64,  63,  65],\n",
       "         ...,\n",
       "         [162, 170, 174],\n",
       "         [161, 169, 173],\n",
       "         [159, 167, 171]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9963512420654297, 'inference': 4.989862442016602, 'postprocess': 0.9920597076416016},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[ 94, 100, 104],\n",
       "         [ 94, 100, 104],\n",
       "         [ 94, 100, 104],\n",
       "         ...,\n",
       "         [173, 179, 183],\n",
       "         [173, 179, 183],\n",
       "         [173, 179, 183]],\n",
       " \n",
       "        [[ 95, 101, 105],\n",
       "         [ 95, 101, 105],\n",
       "         [ 95, 101, 105],\n",
       "         ...,\n",
       "         [173, 179, 183],\n",
       "         [173, 179, 183],\n",
       "         [173, 179, 183]],\n",
       " \n",
       "        [[100, 106, 110],\n",
       "         [100, 106, 110],\n",
       "         [100, 106, 110],\n",
       "         ...,\n",
       "         [173, 179, 183],\n",
       "         [173, 179, 183],\n",
       "         [173, 179, 183]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[152, 156, 158],\n",
       "         [152, 156, 158],\n",
       "         [149, 153, 155],\n",
       "         ...,\n",
       "         [156, 164, 168],\n",
       "         [156, 164, 168],\n",
       "         [156, 164, 168]],\n",
       " \n",
       "        [[ 94,  96,  98],\n",
       "         [ 94,  96,  98],\n",
       "         [ 94,  96,  98],\n",
       "         ...,\n",
       "         [156, 164, 168],\n",
       "         [155, 163, 167],\n",
       "         [154, 162, 166]],\n",
       " \n",
       "        [[ 58,  60,  62],\n",
       "         [ 58,  60,  62],\n",
       "         [ 56,  58,  60],\n",
       "         ...,\n",
       "         [156, 164, 168],\n",
       "         [155, 163, 167],\n",
       "         [154, 162, 166]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9984970092773438, 'inference': 4.007577896118164, 'postprocess': 0.9760856628417969},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[ 94, 100, 104],\n",
       "         [ 94, 100, 104],\n",
       "         [ 94, 100, 104],\n",
       "         ...,\n",
       "         [173, 179, 183],\n",
       "         [173, 179, 183],\n",
       "         [173, 179, 183]],\n",
       " \n",
       "        [[ 95, 101, 105],\n",
       "         [ 95, 101, 105],\n",
       "         [ 95, 101, 105],\n",
       "         ...,\n",
       "         [173, 179, 183],\n",
       "         [173, 179, 183],\n",
       "         [173, 179, 183]],\n",
       " \n",
       "        [[100, 106, 110],\n",
       "         [100, 106, 110],\n",
       "         [100, 106, 110],\n",
       "         ...,\n",
       "         [173, 179, 183],\n",
       "         [173, 179, 183],\n",
       "         [173, 179, 183]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[163, 167, 169],\n",
       "         [163, 167, 169],\n",
       "         [163, 167, 169],\n",
       "         ...,\n",
       "         [157, 165, 169],\n",
       "         [156, 164, 168],\n",
       "         [155, 163, 167]],\n",
       " \n",
       "        [[109, 111, 113],\n",
       "         [109, 111, 113],\n",
       "         [109, 111, 113],\n",
       "         ...,\n",
       "         [157, 165, 169],\n",
       "         [156, 164, 168],\n",
       "         [155, 163, 167]],\n",
       " \n",
       "        [[ 64,  66,  68],\n",
       "         [ 64,  66,  68],\n",
       "         [ 64,  66,  68],\n",
       "         ...,\n",
       "         [157, 165, 169],\n",
       "         [156, 164, 168],\n",
       "         [155, 163, 167]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 1.993417739868164, 'inference': 6.980180740356445, 'postprocess': 1.9898414611816406},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[ 94, 100, 104],\n",
       "         [ 94, 100, 104],\n",
       "         [ 94, 100, 104],\n",
       "         ...,\n",
       "         [173, 179, 183],\n",
       "         [173, 179, 183],\n",
       "         [173, 179, 183]],\n",
       " \n",
       "        [[ 95, 101, 105],\n",
       "         [ 95, 101, 105],\n",
       "         [ 95, 101, 105],\n",
       "         ...,\n",
       "         [173, 179, 183],\n",
       "         [173, 179, 183],\n",
       "         [173, 179, 183]],\n",
       " \n",
       "        [[ 98, 104, 108],\n",
       "         [ 98, 104, 108],\n",
       "         [ 98, 104, 108],\n",
       "         ...,\n",
       "         [173, 179, 183],\n",
       "         [173, 179, 183],\n",
       "         [173, 179, 183]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[149, 153, 155],\n",
       "         [149, 153, 155],\n",
       "         [155, 159, 161],\n",
       "         ...,\n",
       "         [158, 166, 170],\n",
       "         [156, 164, 168],\n",
       "         [156, 164, 168]],\n",
       " \n",
       "        [[101, 103, 105],\n",
       "         [101, 103, 105],\n",
       "         [107, 109, 111],\n",
       "         ...,\n",
       "         [158, 166, 170],\n",
       "         [156, 164, 168],\n",
       "         [155, 163, 167]],\n",
       " \n",
       "        [[ 49,  51,  53],\n",
       "         [ 49,  51,  53],\n",
       "         [ 55,  57,  59],\n",
       "         ...,\n",
       "         [158, 166, 170],\n",
       "         [156, 164, 168],\n",
       "         [155, 163, 167]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9901523590087891, 'inference': 3.986835479736328, 'postprocess': 0.9970664978027344},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[ 94, 100, 104],\n",
       "         [ 94, 100, 104],\n",
       "         [ 94, 100, 104],\n",
       "         ...,\n",
       "         [173, 179, 183],\n",
       "         [173, 179, 183],\n",
       "         [173, 179, 183]],\n",
       " \n",
       "        [[ 95, 101, 105],\n",
       "         [ 95, 101, 105],\n",
       "         [ 95, 101, 105],\n",
       "         ...,\n",
       "         [173, 179, 183],\n",
       "         [173, 179, 183],\n",
       "         [173, 179, 183]],\n",
       " \n",
       "        [[ 98, 104, 108],\n",
       "         [ 98, 104, 108],\n",
       "         [ 98, 104, 108],\n",
       "         ...,\n",
       "         [173, 179, 183],\n",
       "         [173, 179, 183],\n",
       "         [173, 179, 183]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[161, 165, 167],\n",
       "         [161, 165, 167],\n",
       "         [161, 165, 167],\n",
       "         ...,\n",
       "         [161, 169, 173],\n",
       "         [161, 169, 173],\n",
       "         [159, 167, 171]],\n",
       " \n",
       "        [[130, 132, 134],\n",
       "         [132, 134, 136],\n",
       "         [130, 132, 134],\n",
       "         ...,\n",
       "         [161, 169, 173],\n",
       "         [161, 169, 173],\n",
       "         [159, 167, 171]],\n",
       " \n",
       "        [[ 70,  72,  74],\n",
       "         [ 70,  72,  74],\n",
       "         [ 69,  71,  73],\n",
       "         ...,\n",
       "         [161, 169, 173],\n",
       "         [161, 169, 173],\n",
       "         [159, 167, 171]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 1.992940902709961, 'inference': 3.990650177001953, 'postprocess': 0.9965896606445312},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[ 94, 100, 104],\n",
       "         [ 94, 100, 104],\n",
       "         [ 94, 100, 104],\n",
       "         ...,\n",
       "         [173, 179, 183],\n",
       "         [173, 179, 183],\n",
       "         [173, 179, 183]],\n",
       " \n",
       "        [[ 95, 101, 105],\n",
       "         [ 95, 101, 105],\n",
       "         [ 95, 101, 105],\n",
       "         ...,\n",
       "         [173, 179, 183],\n",
       "         [173, 179, 183],\n",
       "         [173, 179, 183]],\n",
       " \n",
       "        [[ 98, 104, 108],\n",
       "         [ 98, 104, 108],\n",
       "         [ 98, 104, 108],\n",
       "         ...,\n",
       "         [173, 179, 183],\n",
       "         [173, 179, 183],\n",
       "         [173, 179, 183]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[176, 180, 182],\n",
       "         [190, 194, 196],\n",
       "         [217, 221, 223],\n",
       "         ...,\n",
       "         [158, 166, 170],\n",
       "         [161, 169, 173],\n",
       "         [161, 169, 173]],\n",
       " \n",
       "        [[136, 138, 140],\n",
       "         [150, 152, 154],\n",
       "         [177, 179, 181],\n",
       "         ...,\n",
       "         [158, 166, 170],\n",
       "         [161, 169, 173],\n",
       "         [161, 169, 173]],\n",
       " \n",
       "        [[104, 106, 108],\n",
       "         [118, 120, 122],\n",
       "         [146, 148, 150],\n",
       "         ...,\n",
       "         [158, 166, 170],\n",
       "         [161, 169, 173],\n",
       "         [161, 169, 173]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9961128234863281, 'inference': 4.9896240234375, 'postprocess': 0.9896755218505859},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[ 94, 100, 104],\n",
       "         [ 94, 100, 104],\n",
       "         [ 94, 100, 104],\n",
       "         ...,\n",
       "         [173, 179, 183],\n",
       "         [173, 179, 183],\n",
       "         [173, 179, 183]],\n",
       " \n",
       "        [[ 95, 101, 105],\n",
       "         [ 95, 101, 105],\n",
       "         [ 95, 101, 105],\n",
       "         ...,\n",
       "         [173, 179, 183],\n",
       "         [173, 179, 183],\n",
       "         [173, 179, 183]],\n",
       " \n",
       "        [[ 98, 104, 108],\n",
       "         [ 98, 104, 108],\n",
       "         [ 98, 104, 108],\n",
       "         ...,\n",
       "         [173, 179, 183],\n",
       "         [173, 179, 183],\n",
       "         [173, 179, 183]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[216, 220, 222],\n",
       "         [218, 222, 224],\n",
       "         [238, 242, 244],\n",
       "         ...,\n",
       "         [158, 166, 170],\n",
       "         [161, 169, 173],\n",
       "         [161, 169, 173]],\n",
       " \n",
       "        [[160, 162, 164],\n",
       "         [162, 164, 166],\n",
       "         [180, 182, 184],\n",
       "         ...,\n",
       "         [158, 166, 170],\n",
       "         [161, 169, 173],\n",
       "         [161, 169, 173]],\n",
       " \n",
       "        [[118, 120, 122],\n",
       "         [120, 122, 124],\n",
       "         [139, 141, 143],\n",
       "         ...,\n",
       "         [158, 166, 170],\n",
       "         [161, 169, 173],\n",
       "         [161, 169, 173]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9932518005371094, 'inference': 3.999471664428711, 'postprocess': 0.9927749633789062},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[ 94, 100, 104],\n",
       "         [ 94, 100, 104],\n",
       "         [ 94, 100, 104],\n",
       "         ...,\n",
       "         [171, 177, 181],\n",
       "         [171, 177, 181],\n",
       "         [171, 177, 181]],\n",
       " \n",
       "        [[ 95, 101, 105],\n",
       "         [ 95, 101, 105],\n",
       "         [ 95, 101, 105],\n",
       "         ...,\n",
       "         [171, 177, 181],\n",
       "         [171, 177, 181],\n",
       "         [171, 177, 181]],\n",
       " \n",
       "        [[ 98, 104, 108],\n",
       "         [ 98, 104, 108],\n",
       "         [ 98, 104, 108],\n",
       "         ...,\n",
       "         [171, 177, 181],\n",
       "         [171, 177, 181],\n",
       "         [171, 177, 181]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[222, 226, 228],\n",
       "         [245, 249, 251],\n",
       "         [254, 255, 255],\n",
       "         ...,\n",
       "         [156, 164, 168],\n",
       "         [156, 164, 168],\n",
       "         [158, 166, 170]],\n",
       " \n",
       "        [[160, 162, 164],\n",
       "         [184, 186, 188],\n",
       "         [210, 212, 214],\n",
       "         ...,\n",
       "         [156, 164, 168],\n",
       "         [156, 164, 168],\n",
       "         [158, 166, 170]],\n",
       " \n",
       "        [[132, 134, 136],\n",
       "         [155, 157, 159],\n",
       "         [176, 178, 180],\n",
       "         ...,\n",
       "         [157, 165, 169],\n",
       "         [156, 164, 168],\n",
       "         [158, 166, 170]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.0, 'inference': 3.9887428283691406, 'postprocess': 0.9965896606445312},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[ 94, 100, 104],\n",
       "         [ 94, 100, 104],\n",
       "         [ 94, 100, 104],\n",
       "         ...,\n",
       "         [171, 177, 181],\n",
       "         [171, 177, 181],\n",
       "         [171, 177, 181]],\n",
       " \n",
       "        [[ 95, 101, 105],\n",
       "         [ 95, 101, 105],\n",
       "         [ 95, 101, 105],\n",
       "         ...,\n",
       "         [171, 177, 181],\n",
       "         [171, 177, 181],\n",
       "         [171, 177, 181]],\n",
       " \n",
       "        [[ 98, 104, 108],\n",
       "         [ 98, 104, 108],\n",
       "         [ 98, 104, 108],\n",
       "         ...,\n",
       "         [171, 177, 181],\n",
       "         [171, 177, 181],\n",
       "         [171, 177, 181]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[185, 189, 191],\n",
       "         [170, 174, 176],\n",
       "         [201, 205, 207],\n",
       "         ...,\n",
       "         [156, 164, 168],\n",
       "         [156, 164, 168],\n",
       "         [158, 166, 170]],\n",
       " \n",
       "        [[151, 153, 155],\n",
       "         [116, 118, 120],\n",
       "         [144, 146, 148],\n",
       "         ...,\n",
       "         [157, 165, 169],\n",
       "         [156, 164, 168],\n",
       "         [158, 166, 170]],\n",
       " \n",
       "        [[139, 141, 143],\n",
       "         [112, 114, 116],\n",
       "         [141, 143, 145],\n",
       "         ...,\n",
       "         [157, 165, 169],\n",
       "         [156, 164, 168],\n",
       "         [158, 166, 170]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9965896606445312, 'inference': 4.982948303222656, 'postprocess': 0.9968280792236328},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[ 94, 100, 104],\n",
       "         [ 94, 100, 104],\n",
       "         [ 94, 100, 104],\n",
       "         ...,\n",
       "         [171, 177, 181],\n",
       "         [171, 177, 181],\n",
       "         [171, 177, 181]],\n",
       " \n",
       "        [[ 95, 101, 105],\n",
       "         [ 95, 101, 105],\n",
       "         [ 95, 101, 105],\n",
       "         ...,\n",
       "         [171, 177, 181],\n",
       "         [171, 177, 181],\n",
       "         [171, 177, 181]],\n",
       " \n",
       "        [[ 98, 104, 108],\n",
       "         [ 98, 104, 108],\n",
       "         [ 98, 104, 108],\n",
       "         ...,\n",
       "         [171, 177, 181],\n",
       "         [171, 177, 181],\n",
       "         [171, 177, 181]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[212, 215, 220],\n",
       "         [206, 209, 214],\n",
       "         [209, 212, 217],\n",
       "         ...,\n",
       "         [156, 164, 168],\n",
       "         [157, 165, 169],\n",
       "         [158, 166, 170]],\n",
       " \n",
       "        [[248, 252, 254],\n",
       "         [238, 242, 244],\n",
       "         [233, 237, 239],\n",
       "         ...,\n",
       "         [156, 164, 168],\n",
       "         [157, 165, 169],\n",
       "         [158, 166, 170]],\n",
       " \n",
       "        [[219, 223, 225],\n",
       "         [206, 210, 212],\n",
       "         [204, 208, 210],\n",
       "         ...,\n",
       "         [156, 164, 168],\n",
       "         [157, 165, 169],\n",
       "         [158, 166, 170]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9503364562988281, 'inference': 4.989385604858398, 'postprocess': 0.9999275207519531},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[ 94, 100, 104],\n",
       "         [ 94, 100, 104],\n",
       "         [ 94, 100, 104],\n",
       "         ...,\n",
       "         [171, 177, 181],\n",
       "         [171, 177, 181],\n",
       "         [171, 177, 181]],\n",
       " \n",
       "        [[ 95, 101, 105],\n",
       "         [ 95, 101, 105],\n",
       "         [ 95, 101, 105],\n",
       "         ...,\n",
       "         [171, 177, 181],\n",
       "         [171, 177, 181],\n",
       "         [171, 177, 181]],\n",
       " \n",
       "        [[ 98, 104, 108],\n",
       "         [ 98, 104, 108],\n",
       "         [ 98, 104, 108],\n",
       "         ...,\n",
       "         [171, 177, 181],\n",
       "         [171, 177, 181],\n",
       "         [171, 177, 181]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 59,  62,  67],\n",
       "         [ 56,  59,  64],\n",
       "         [105, 108, 113],\n",
       "         ...,\n",
       "         [156, 164, 168],\n",
       "         [157, 165, 169],\n",
       "         [158, 166, 170]],\n",
       " \n",
       "        [[151, 155, 157],\n",
       "         [154, 158, 160],\n",
       "         [171, 175, 177],\n",
       "         ...,\n",
       "         [156, 164, 168],\n",
       "         [157, 165, 169],\n",
       "         [158, 166, 170]],\n",
       " \n",
       "        [[243, 247, 249],\n",
       "         [234, 238, 240],\n",
       "         [215, 219, 221],\n",
       "         ...,\n",
       "         [156, 164, 168],\n",
       "         [157, 165, 169],\n",
       "         [158, 166, 170]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9992122650146484, 'inference': 6.976842880249023, 'postprocess': 1.9898414611816406},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[ 94, 100, 104],\n",
       "         [ 94, 100, 104],\n",
       "         [ 94, 100, 104],\n",
       "         ...,\n",
       "         [171, 177, 181],\n",
       "         [171, 177, 181],\n",
       "         [171, 177, 181]],\n",
       " \n",
       "        [[ 95, 101, 105],\n",
       "         [ 95, 101, 105],\n",
       "         [ 95, 101, 105],\n",
       "         ...,\n",
       "         [171, 177, 181],\n",
       "         [171, 177, 181],\n",
       "         [171, 177, 181]],\n",
       " \n",
       "        [[ 98, 104, 108],\n",
       "         [ 98, 104, 108],\n",
       "         [ 98, 104, 108],\n",
       "         ...,\n",
       "         [171, 177, 181],\n",
       "         [171, 177, 181],\n",
       "         [171, 177, 181]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 59,  61,  68],\n",
       "         [ 59,  61,  68],\n",
       "         [ 57,  59,  66],\n",
       "         ...,\n",
       "         [156, 164, 168],\n",
       "         [157, 165, 169],\n",
       "         [158, 166, 170]],\n",
       " \n",
       "        [[ 67,  70,  75],\n",
       "         [ 52,  55,  60],\n",
       "         [ 45,  48,  53],\n",
       "         ...,\n",
       "         [156, 164, 168],\n",
       "         [157, 165, 169],\n",
       "         [158, 166, 170]],\n",
       " \n",
       "        [[118, 121, 126],\n",
       "         [ 82,  85,  90],\n",
       "         [ 56,  59,  64],\n",
       "         ...,\n",
       "         [156, 164, 168],\n",
       "         [157, 165, 169],\n",
       "         [158, 166, 170]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9913444519042969, 'inference': 6.977081298828125, 'postprocess': 0.9968280792236328},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[ 89,  96,  97],\n",
       "         [ 89,  96,  97],\n",
       "         [ 90,  97,  98],\n",
       "         ...,\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179]],\n",
       " \n",
       "        [[ 94, 101, 102],\n",
       "         [ 94, 101, 102],\n",
       "         [ 95, 102, 103],\n",
       "         ...,\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179]],\n",
       " \n",
       "        [[102, 109, 110],\n",
       "         [102, 109, 110],\n",
       "         [103, 110, 111],\n",
       "         ...,\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 52,  55,  60],\n",
       "         [ 54,  57,  62],\n",
       "         [ 50,  53,  58],\n",
       "         ...,\n",
       "         [154, 163, 164],\n",
       "         [154, 163, 164],\n",
       "         [154, 163, 164]],\n",
       " \n",
       "        [[ 42,  45,  50],\n",
       "         [ 54,  57,  62],\n",
       "         [ 57,  60,  65],\n",
       "         ...,\n",
       "         [154, 163, 164],\n",
       "         [154, 163, 164],\n",
       "         [154, 163, 164]],\n",
       " \n",
       "        [[ 38,  41,  46],\n",
       "         [ 55,  58,  63],\n",
       "         [ 61,  64,  69],\n",
       "         ...,\n",
       "         [154, 163, 164],\n",
       "         [154, 163, 164],\n",
       "         [154, 163, 164]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.995635986328125, 'inference': 5.985498428344727, 'postprocess': 0.9925365447998047},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[ 89,  96,  97],\n",
       "         [ 89,  96,  97],\n",
       "         [ 90,  97,  98],\n",
       "         ...,\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179]],\n",
       " \n",
       "        [[ 94, 101, 102],\n",
       "         [ 94, 101, 102],\n",
       "         [ 95, 102, 103],\n",
       "         ...,\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179]],\n",
       " \n",
       "        [[102, 109, 110],\n",
       "         [102, 109, 110],\n",
       "         [103, 110, 111],\n",
       "         ...,\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 46,  49,  54],\n",
       "         [ 46,  49,  54],\n",
       "         [ 46,  49,  54],\n",
       "         ...,\n",
       "         [154, 163, 164],\n",
       "         [154, 163, 164],\n",
       "         [154, 163, 164]],\n",
       " \n",
       "        [[ 48,  51,  56],\n",
       "         [ 48,  51,  56],\n",
       "         [ 48,  51,  56],\n",
       "         ...,\n",
       "         [154, 163, 164],\n",
       "         [154, 163, 164],\n",
       "         [154, 163, 164]],\n",
       " \n",
       "        [[ 48,  51,  56],\n",
       "         [ 48,  51,  56],\n",
       "         [ 49,  52,  57],\n",
       "         ...,\n",
       "         [154, 163, 164],\n",
       "         [154, 163, 164],\n",
       "         [154, 163, 164]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 1.001119613647461, 'inference': 7.970571517944336, 'postprocess': 0.9973049163818359},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[ 89,  96,  97],\n",
       "         [ 89,  96,  97],\n",
       "         [ 90,  97,  98],\n",
       "         ...,\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179]],\n",
       " \n",
       "        [[ 94, 101, 102],\n",
       "         [ 94, 101, 102],\n",
       "         [ 95, 102, 103],\n",
       "         ...,\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179]],\n",
       " \n",
       "        [[102, 109, 110],\n",
       "         [102, 109, 110],\n",
       "         [103, 110, 111],\n",
       "         ...,\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 46,  49,  54],\n",
       "         [ 43,  46,  51],\n",
       "         [ 40,  43,  48],\n",
       "         ...,\n",
       "         [154, 163, 164],\n",
       "         [154, 163, 164],\n",
       "         [154, 163, 164]],\n",
       " \n",
       "        [[ 47,  50,  55],\n",
       "         [ 41,  44,  49],\n",
       "         [ 43,  46,  51],\n",
       "         ...,\n",
       "         [154, 163, 164],\n",
       "         [154, 163, 164],\n",
       "         [154, 163, 164]],\n",
       " \n",
       "        [[ 49,  52,  57],\n",
       "         [ 41,  44,  49],\n",
       "         [ 50,  53,  58],\n",
       "         ...,\n",
       "         [154, 163, 164],\n",
       "         [154, 163, 164],\n",
       "         [154, 163, 164]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 1.9936561584472656, 'inference': 3.9865970611572266, 'postprocess': 0.9961128234863281},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[ 95, 102, 103],\n",
       "         [ 95, 102, 103],\n",
       "         [ 95, 102, 103],\n",
       "         ...,\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179]],\n",
       " \n",
       "        [[ 97, 104, 105],\n",
       "         [ 97, 104, 105],\n",
       "         [ 97, 104, 105],\n",
       "         ...,\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179]],\n",
       " \n",
       "        [[100, 107, 108],\n",
       "         [100, 107, 108],\n",
       "         [101, 108, 109],\n",
       "         ...,\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 49,  52,  57],\n",
       "         [ 41,  44,  49],\n",
       "         [ 46,  49,  54],\n",
       "         ...,\n",
       "         [154, 163, 164],\n",
       "         [154, 163, 164],\n",
       "         [154, 163, 164]],\n",
       " \n",
       "        [[ 39,  42,  47],\n",
       "         [ 46,  49,  54],\n",
       "         [ 57,  60,  65],\n",
       "         ...,\n",
       "         [154, 163, 164],\n",
       "         [154, 163, 164],\n",
       "         [154, 163, 164]],\n",
       " \n",
       "        [[ 35,  38,  43],\n",
       "         [ 59,  62,  67],\n",
       "         [ 69,  72,  77],\n",
       "         ...,\n",
       "         [154, 163, 164],\n",
       "         [154, 163, 164],\n",
       "         [154, 163, 164]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9961128234863281, 'inference': 4.983663558959961, 'postprocess': 0.0},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[ 91,  98,  99],\n",
       "         [ 91,  98,  99],\n",
       "         [ 91,  98,  99],\n",
       "         ...,\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179]],\n",
       " \n",
       "        [[ 94, 101, 102],\n",
       "         [ 94, 101, 102],\n",
       "         [ 95, 102, 103],\n",
       "         ...,\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179]],\n",
       " \n",
       "        [[ 97, 104, 105],\n",
       "         [ 97, 104, 105],\n",
       "         [ 98, 105, 106],\n",
       "         ...,\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 48,  51,  56],\n",
       "         [ 40,  43,  48],\n",
       "         [ 55,  58,  63],\n",
       "         ...,\n",
       "         [154, 163, 164],\n",
       "         [154, 163, 164],\n",
       "         [154, 163, 164]],\n",
       " \n",
       "        [[ 41,  44,  49],\n",
       "         [ 48,  51,  56],\n",
       "         [ 61,  64,  69],\n",
       "         ...,\n",
       "         [154, 163, 164],\n",
       "         [154, 163, 164],\n",
       "         [154, 163, 164]],\n",
       " \n",
       "        [[ 43,  46,  51],\n",
       "         [ 67,  70,  75],\n",
       "         [ 60,  63,  68],\n",
       "         ...,\n",
       "         [154, 163, 164],\n",
       "         [154, 163, 164],\n",
       "         [154, 163, 164]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9961128234863281, 'inference': 3.986835479736328, 'postprocess': 0.9965896606445312},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[ 91,  98,  99],\n",
       "         [ 91,  98,  99],\n",
       "         [ 91,  98,  99],\n",
       "         ...,\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179]],\n",
       " \n",
       "        [[ 93, 100, 101],\n",
       "         [ 93, 100, 101],\n",
       "         [ 93, 100, 101],\n",
       "         ...,\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179]],\n",
       " \n",
       "        [[ 96, 103, 104],\n",
       "         [ 96, 103, 104],\n",
       "         [ 96, 103, 104],\n",
       "         ...,\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 55,  58,  63],\n",
       "         [ 45,  48,  53],\n",
       "         [ 45,  48,  53],\n",
       "         ...,\n",
       "         [155, 164, 165],\n",
       "         [154, 163, 164],\n",
       "         [154, 163, 164]],\n",
       " \n",
       "        [[ 41,  44,  49],\n",
       "         [ 48,  51,  56],\n",
       "         [ 60,  63,  68],\n",
       "         ...,\n",
       "         [155, 164, 165],\n",
       "         [154, 163, 164],\n",
       "         [154, 163, 164]],\n",
       " \n",
       "        [[ 38,  41,  46],\n",
       "         [ 53,  56,  61],\n",
       "         [ 68,  71,  76],\n",
       "         ...,\n",
       "         [155, 164, 165],\n",
       "         [154, 163, 164],\n",
       "         [154, 163, 164]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9965896606445312, 'inference': 5.980014801025391, 'postprocess': 0.9963512420654297},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[ 91,  98,  99],\n",
       "         [ 91,  98,  99],\n",
       "         [ 91,  98,  99],\n",
       "         ...,\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177]],\n",
       " \n",
       "        [[ 93, 100, 101],\n",
       "         [ 93, 100, 101],\n",
       "         [ 93, 100, 101],\n",
       "         ...,\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177]],\n",
       " \n",
       "        [[ 96, 103, 104],\n",
       "         [ 96, 103, 104],\n",
       "         [ 96, 103, 104],\n",
       "         ...,\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 21,  24,  29],\n",
       "         [ 32,  35,  40],\n",
       "         [ 64,  67,  72],\n",
       "         ...,\n",
       "         [155, 164, 165],\n",
       "         [155, 164, 165],\n",
       "         [154, 163, 164]],\n",
       " \n",
       "        [[ 29,  32,  37],\n",
       "         [ 49,  52,  57],\n",
       "         [ 77,  80,  85],\n",
       "         ...,\n",
       "         [155, 164, 165],\n",
       "         [155, 164, 165],\n",
       "         [154, 163, 164]],\n",
       " \n",
       "        [[ 54,  57,  62],\n",
       "         [ 66,  69,  74],\n",
       "         [ 69,  72,  77],\n",
       "         ...,\n",
       "         [155, 164, 165],\n",
       "         [155, 164, 165],\n",
       "         [154, 163, 164]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9965896606445312, 'inference': 4.984855651855469, 'postprocess': 0.9965896606445312},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[ 91,  98,  99],\n",
       "         [ 91,  98,  99],\n",
       "         [ 91,  98,  99],\n",
       "         ...,\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177]],\n",
       " \n",
       "        [[ 93, 100, 101],\n",
       "         [ 93, 100, 101],\n",
       "         [ 93, 100, 101],\n",
       "         ...,\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177]],\n",
       " \n",
       "        [[ 96, 103, 104],\n",
       "         [ 96, 103, 104],\n",
       "         [ 96, 103, 104],\n",
       "         ...,\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 80,  83,  88],\n",
       "         [ 81,  84,  89],\n",
       "         [ 90,  93,  98],\n",
       "         ...,\n",
       "         [155, 164, 165],\n",
       "         [155, 164, 165],\n",
       "         [155, 164, 165]],\n",
       " \n",
       "        [[165, 168, 173],\n",
       "         [131, 134, 139],\n",
       "         [ 74,  77,  82],\n",
       "         ...,\n",
       "         [155, 164, 165],\n",
       "         [155, 164, 165],\n",
       "         [155, 164, 165]],\n",
       " \n",
       "        [[191, 194, 199],\n",
       "         [188, 191, 196],\n",
       "         [190, 193, 198],\n",
       "         ...,\n",
       "         [155, 164, 165],\n",
       "         [155, 164, 165],\n",
       "         [155, 164, 165]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 2.500772476196289, 'inference': 3.986358642578125, 'postprocess': 0.9965896606445312},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[ 91,  98,  99],\n",
       "         [ 91,  98,  99],\n",
       "         [ 91,  98,  99],\n",
       "         ...,\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177]],\n",
       " \n",
       "        [[ 93, 100, 101],\n",
       "         [ 93, 100, 101],\n",
       "         [ 93, 100, 101],\n",
       "         ...,\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177]],\n",
       " \n",
       "        [[ 96, 103, 104],\n",
       "         [ 96, 103, 104],\n",
       "         [ 96, 103, 104],\n",
       "         ...,\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[224, 227, 232],\n",
       "         [224, 227, 232],\n",
       "         [223, 226, 231],\n",
       "         ...,\n",
       "         [156, 165, 166],\n",
       "         [155, 164, 165],\n",
       "         [155, 164, 165]],\n",
       " \n",
       "        [[224, 227, 232],\n",
       "         [224, 227, 232],\n",
       "         [223, 226, 231],\n",
       "         ...,\n",
       "         [156, 165, 166],\n",
       "         [155, 164, 165],\n",
       "         [155, 164, 165]],\n",
       " \n",
       "        [[191, 194, 199],\n",
       "         [191, 194, 199],\n",
       "         [190, 193, 198],\n",
       "         ...,\n",
       "         [156, 165, 166],\n",
       "         [155, 164, 165],\n",
       "         [155, 164, 165]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 1.0008811950683594, 'inference': 5.980968475341797, 'postprocess': 0.9930133819580078},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[ 91,  98,  99],\n",
       "         [ 91,  98,  99],\n",
       "         [ 91,  98,  99],\n",
       "         ...,\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177]],\n",
       " \n",
       "        [[ 93, 100, 101],\n",
       "         [ 93, 100, 101],\n",
       "         [ 93, 100, 101],\n",
       "         ...,\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177]],\n",
       " \n",
       "        [[ 95, 102, 103],\n",
       "         [ 95, 102, 103],\n",
       "         [ 95, 102, 103],\n",
       "         ...,\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[197, 200, 205],\n",
       "         [197, 200, 205],\n",
       "         [197, 200, 205],\n",
       "         ...,\n",
       "         [156, 165, 166],\n",
       "         [155, 164, 165],\n",
       "         [155, 164, 165]],\n",
       " \n",
       "        [[126, 129, 134],\n",
       "         [126, 129, 134],\n",
       "         [126, 129, 134],\n",
       "         ...,\n",
       "         [156, 165, 166],\n",
       "         [156, 165, 166],\n",
       "         [155, 164, 165]],\n",
       " \n",
       "        [[ 64,  67,  72],\n",
       "         [ 64,  67,  72],\n",
       "         [ 64,  67,  72],\n",
       "         ...,\n",
       "         [156, 165, 166],\n",
       "         [156, 165, 166],\n",
       "         [155, 164, 165]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9918212890625, 'inference': 3.985881805419922, 'postprocess': 0.9965896606445312},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[ 95, 102, 103],\n",
       "         [ 95, 102, 103],\n",
       "         [ 94, 101, 102],\n",
       "         ...,\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177]],\n",
       " \n",
       "        [[ 95, 102, 103],\n",
       "         [ 95, 102, 103],\n",
       "         [ 94, 101, 102],\n",
       "         ...,\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177]],\n",
       " \n",
       "        [[ 97, 104, 105],\n",
       "         [ 97, 104, 105],\n",
       "         [ 96, 103, 104],\n",
       "         ...,\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177],\n",
       "         [167, 176, 177]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 76,  79,  84],\n",
       "         [ 76,  79,  84],\n",
       "         [ 77,  80,  85],\n",
       "         ...,\n",
       "         [156, 165, 166],\n",
       "         [156, 165, 166],\n",
       "         [156, 165, 166]],\n",
       " \n",
       "        [[ 47,  50,  55],\n",
       "         [ 47,  50,  55],\n",
       "         [ 48,  51,  56],\n",
       "         ...,\n",
       "         [157, 166, 167],\n",
       "         [156, 165, 166],\n",
       "         [156, 165, 166]],\n",
       " \n",
       "        [[ 55,  58,  63],\n",
       "         [ 55,  58,  63],\n",
       "         [ 56,  59,  64],\n",
       "         ...,\n",
       "         [157, 166, 167],\n",
       "         [156, 165, 166],\n",
       "         [156, 165, 166]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9927749633789062, 'inference': 4.982709884643555, 'postprocess': 0.9965896606445312},\n",
       " ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'General', 1: 'Glass', 2: 'Metal', 3: 'Paper', 4: 'Plastic', 5: 'Styrofoam', 6: 'Vinyl'}\n",
       " obb: None\n",
       " orig_img: array([[[ 98, 105, 106],\n",
       "         [ 98, 105, 106],\n",
       "         [ 96, 103, 104],\n",
       "         ...,\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179]],\n",
       " \n",
       "        [[ 98, 105, 106],\n",
       "         [ 98, 105, 106],\n",
       "         [ 96, 103, 104],\n",
       "         ...,\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179]],\n",
       " \n",
       "        [[101, 108, 109],\n",
       "         [101, 108, 109],\n",
       "         [ 98, 105, 106],\n",
       "         ...,\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179],\n",
       "         [169, 178, 179]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 48,  51,  56],\n",
       "         [ 49,  52,  57],\n",
       "         [ 52,  55,  60],\n",
       "         ...,\n",
       "         [157, 166, 167],\n",
       "         [157, 166, 167],\n",
       "         [156, 165, 166]],\n",
       " \n",
       "        [[ 56,  59,  64],\n",
       "         [ 56,  59,  64],\n",
       "         [ 61,  64,  69],\n",
       "         ...,\n",
       "         [157, 166, 167],\n",
       "         [157, 166, 167],\n",
       "         [157, 166, 167]],\n",
       " \n",
       "        [[ 55,  58,  63],\n",
       "         [ 55,  58,  63],\n",
       "         [ 60,  63,  68],\n",
       "         ...,\n",
       "         [157, 166, 167],\n",
       "         [157, 166, 167],\n",
       "         [157, 166, 167]]], dtype=uint8)\n",
       " orig_shape: (720, 1280)\n",
       " path: 'c:\\\\Users\\\\HoJin\\\\Desktop\\\\python\\\\ML_project\\\\zreo_py\\\\DL_Project\\\\Trash-classification\\\\ecosort\\\\test2.mp4'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\predict4'\n",
       " speed: {'preprocess': 0.9963512420654297, 'inference': 4.983663558959961, 'postprocess': 0.9970664978027344}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "videoPath = 'test2.mp4'\n",
    "\n",
    "bestModel.predict(source=videoPath, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
